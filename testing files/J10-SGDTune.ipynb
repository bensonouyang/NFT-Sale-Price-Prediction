{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd329158-108f-4302-a226-6ab8e2960496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "Xtr = pd.read_csv('data/Xtr_tsvd.csv')\n",
    "Xte = pd.read_csv('data/Xte_tsvd.csv')\n",
    "y = pd.read_csv('data/Ytr1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0350b14a-a5a5-4b9b-9495-dc9159bc1705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "Xtr1 = scaler.fit_transform(Xtr)\n",
    "Xte1 = scaler.transform(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64852036-3f2c-41f8-951c-dac38b983245",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = ['huber','epsilon_insensitive','squared_epsilon_insensitive']\n",
    "penalty = ['l2','l1','elasticnet']\n",
    "alpha = [0, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "learning_rate = ['constant', 'optimal', 'invscaling', 'adaptive'] \n",
    "epsilon = [0, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "max_iter = [1000,2000,3000,4000, 5000]\n",
    "params = dict(loss = loss, penalty = penalty, alpha = alpha, learning_rate = learning_rate, epsilon = epsilon, max_iter = max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac0f93ee-4fc9-4376-904f-a49bad386c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n",
      "Best Score:  nan\n",
      "Best Params:  {'penalty': 'l2', 'max_iter': 3000, 'loss': 'huber', 'learning_rate': 'optimal', 'epsilon': 0.1, 'alpha': 1000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benson\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "120 fits failed out of a total of 5000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "120 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Benson\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Benson\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 1537, in fit\n",
      "    return self._fit(\n",
      "  File \"C:\\Users\\Benson\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 1472, in _fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Benson\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 151, in _validate_params\n",
      "    raise ValueError(\n",
      "ValueError: alpha must be > 0 since learning_rate is 'optimal'. alpha is used to compute the optimal learning rate.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Benson\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Benson\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd = SGDRegressor()\n",
    "random = RandomizedSearchCV(estimator=sgd, param_distributions=params, \n",
    "scoring='roc_auc', \n",
    "verbose=1, n_jobs=-1, \n",
    "n_iter=1000) \n",
    "\n",
    "random_result = random.fit(Xtr1,y)\n",
    "print('Best Score: ', random_result.best_score_) \n",
    "print('Best Params: ', random_result.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "881862f3-4f09-4365-a853-739599ceb2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 14580 candidates, totalling 72900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benson\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "2025 fits failed out of a total of 72900.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2025 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Benson\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Benson\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 1537, in fit\n",
      "    return self._fit(\n",
      "  File \"C:\\Users\\Benson\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 1472, in _fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Benson\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 151, in _validate_params\n",
      "    raise ValueError(\n",
      "ValueError: alpha must be > 0 since learning_rate is 'optimal'. alpha is used to compute the optimal learning rate.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Benson\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  nan\n",
      "Best Params:  {'alpha': 0, 'epsilon': 0, 'learning_rate': 'constant', 'loss': 'huber', 'max_iter': 1000, 'penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benson\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "loss = ['huber','epsilon_insensitive','squared_epsilon_insensitive']\n",
    "penalty = ['l2','l1','elasticnet']\n",
    "alpha = [0, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "learning_rate = ['constant', 'optimal', 'invscaling', 'adaptive'] \n",
    "epsilon = [0, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "max_iter = [1000,2000,3000,4000, 5000]\n",
    "params = dict(loss = loss, penalty = penalty, alpha = alpha, learning_rate = learning_rate, epsilon = epsilon, max_iter = max_iter)\n",
    "\n",
    "sgd = SGDRegressor()\n",
    "gs = GridSearchCV(estimator=sgd, param_grid=params, \n",
    "scoring='roc_auc', \n",
    "verbose=1, n_jobs=-1) \n",
    "\n",
    "gs_result = gs.fit(Xtr1,y['total'])\n",
    "print('Best Score: ', gs_result.best_score_) \n",
    "print('Best Params: ', gs_result.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "783ae89d-92aa-4476-a767-7d8c8c74f829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SGDRegressor(),\n",
       "             param_grid={'learning_rate': ['constant', 'optimal', 'invscaling',\n",
       "                                           'adaptive'],\n",
       "                         'loss': ['huber', 'epsilon_insensitive',\n",
       "                                  'squared_epsilon_insensitive']})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {'loss':['huber','epsilon_insensitive','squared_epsilon_insensitive'], 'learning_rate':['constant', 'optimal', 'invscaling', 'adaptive'] }\n",
    "sgd = SGDRegressor()\n",
    "gsearch1 = GridSearchCV(sgd,param_test1)\n",
    "gsearch1.fit(Xtr1,y['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c70044e-e67e-44b2-9102-ade44db6bbad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004700</td>\n",
       "      <td>1.434505e-03</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>3.160549e-04</td>\n",
       "      <td>constant</td>\n",
       "      <td>huber</td>\n",
       "      <td>{'learning_rate': 'constant', 'loss': 'huber'}</td>\n",
       "      <td>-1.500171e-02</td>\n",
       "      <td>-1.903127e-02</td>\n",
       "      <td>-1.289615e-02</td>\n",
       "      <td>-1.626671e-02</td>\n",
       "      <td>-1.877214e-02</td>\n",
       "      <td>-1.639360e-02</td>\n",
       "      <td>2.315183e-03</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005100</td>\n",
       "      <td>5.833476e-04</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>1.998448e-04</td>\n",
       "      <td>constant</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "      <td>{'learning_rate': 'constant', 'loss': 'epsilon...</td>\n",
       "      <td>-1.430723e-02</td>\n",
       "      <td>-1.854556e-02</td>\n",
       "      <td>-1.172814e-02</td>\n",
       "      <td>-1.570356e-02</td>\n",
       "      <td>-1.881113e-02</td>\n",
       "      <td>-1.581912e-02</td>\n",
       "      <td>2.661610e-03</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>6.810597e-07</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>8.869684e-07</td>\n",
       "      <td>constant</td>\n",
       "      <td>squared_epsilon_insensitive</td>\n",
       "      <td>{'learning_rate': 'constant', 'loss': 'squared...</td>\n",
       "      <td>-2.702684e+18</td>\n",
       "      <td>-3.290885e+18</td>\n",
       "      <td>-4.806838e+18</td>\n",
       "      <td>-5.353147e+18</td>\n",
       "      <td>-4.133609e+19</td>\n",
       "      <td>-1.149793e+19</td>\n",
       "      <td>1.495029e+19</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008300</td>\n",
       "      <td>2.450926e-04</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>2.449312e-04</td>\n",
       "      <td>optimal</td>\n",
       "      <td>huber</td>\n",
       "      <td>{'learning_rate': 'optimal', 'loss': 'huber'}</td>\n",
       "      <td>-1.447563e-02</td>\n",
       "      <td>-1.876776e-02</td>\n",
       "      <td>-1.169972e-02</td>\n",
       "      <td>-1.532572e-02</td>\n",
       "      <td>-1.855463e-02</td>\n",
       "      <td>-1.576469e-02</td>\n",
       "      <td>2.652566e-03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.049100</td>\n",
       "      <td>8.645173e-03</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>1.998193e-04</td>\n",
       "      <td>optimal</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "      <td>{'learning_rate': 'optimal', 'loss': 'epsilon_...</td>\n",
       "      <td>-1.432679e-02</td>\n",
       "      <td>-1.862491e-02</td>\n",
       "      <td>-1.157085e-02</td>\n",
       "      <td>-1.541850e-02</td>\n",
       "      <td>-1.824360e-02</td>\n",
       "      <td>-1.563693e-02</td>\n",
       "      <td>2.608444e-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.015800</td>\n",
       "      <td>3.042680e-03</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>2.449897e-04</td>\n",
       "      <td>optimal</td>\n",
       "      <td>squared_epsilon_insensitive</td>\n",
       "      <td>{'learning_rate': 'optimal', 'loss': 'squared_...</td>\n",
       "      <td>-1.621371e+21</td>\n",
       "      <td>-1.863779e+20</td>\n",
       "      <td>-1.223009e+19</td>\n",
       "      <td>-1.703712e+19</td>\n",
       "      <td>-1.018512e+20</td>\n",
       "      <td>-3.877735e+20</td>\n",
       "      <td>6.200892e+20</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003506</td>\n",
       "      <td>1.345019e-05</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>2.450091e-04</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>huber</td>\n",
       "      <td>{'learning_rate': 'invscaling', 'loss': 'huber'}</td>\n",
       "      <td>-1.536121e-02</td>\n",
       "      <td>-1.932943e-02</td>\n",
       "      <td>-1.327952e-02</td>\n",
       "      <td>-1.666147e-02</td>\n",
       "      <td>-1.887555e-02</td>\n",
       "      <td>-1.670144e-02</td>\n",
       "      <td>2.242339e-03</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.010394</td>\n",
       "      <td>3.811675e-04</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>6.106495e-07</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "      <td>{'learning_rate': 'invscaling', 'loss': 'epsil...</td>\n",
       "      <td>-1.446807e-02</td>\n",
       "      <td>-1.878375e-02</td>\n",
       "      <td>-1.199132e-02</td>\n",
       "      <td>-1.558421e-02</td>\n",
       "      <td>-1.878785e-02</td>\n",
       "      <td>-1.592304e-02</td>\n",
       "      <td>2.610784e-03</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003600</td>\n",
       "      <td>2.001062e-04</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>2.449313e-04</td>\n",
       "      <td>invscaling</td>\n",
       "      <td>squared_epsilon_insensitive</td>\n",
       "      <td>{'learning_rate': 'invscaling', 'loss': 'squar...</td>\n",
       "      <td>-3.152228e+15</td>\n",
       "      <td>-2.730101e+02</td>\n",
       "      <td>-1.029966e+05</td>\n",
       "      <td>-2.150748e+16</td>\n",
       "      <td>-2.704819e+12</td>\n",
       "      <td>-4.932483e+15</td>\n",
       "      <td>8.376890e+15</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.015000</td>\n",
       "      <td>6.975526e-07</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>huber</td>\n",
       "      <td>{'learning_rate': 'adaptive', 'loss': 'huber'}</td>\n",
       "      <td>-1.494730e-02</td>\n",
       "      <td>-1.908980e-02</td>\n",
       "      <td>-1.268334e-02</td>\n",
       "      <td>-1.619689e-02</td>\n",
       "      <td>-1.886558e-02</td>\n",
       "      <td>-1.635658e-02</td>\n",
       "      <td>2.419497e-03</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.016600</td>\n",
       "      <td>3.740622e-04</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>2.450091e-04</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>epsilon_insensitive</td>\n",
       "      <td>{'learning_rate': 'adaptive', 'loss': 'epsilon...</td>\n",
       "      <td>-1.431865e-02</td>\n",
       "      <td>-1.859830e-02</td>\n",
       "      <td>-1.172515e-02</td>\n",
       "      <td>-1.539892e-02</td>\n",
       "      <td>-1.879801e-02</td>\n",
       "      <td>-1.576781e-02</td>\n",
       "      <td>2.674809e-03</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.014400</td>\n",
       "      <td>1.997955e-04</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>2.448543e-04</td>\n",
       "      <td>adaptive</td>\n",
       "      <td>squared_epsilon_insensitive</td>\n",
       "      <td>{'learning_rate': 'adaptive', 'loss': 'squared...</td>\n",
       "      <td>-8.902478e+14</td>\n",
       "      <td>-1.911337e+16</td>\n",
       "      <td>-5.571385e+15</td>\n",
       "      <td>-4.153598e+12</td>\n",
       "      <td>-5.016098e+14</td>\n",
       "      <td>-5.216153e+15</td>\n",
       "      <td>7.229995e+15</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.004700  1.434505e-03           0.0005    3.160549e-04   \n",
       "1        0.005100  5.833476e-04           0.0004    1.998448e-04   \n",
       "2        0.003000  6.810597e-07           0.0005    8.869684e-07   \n",
       "3        0.008300  2.450926e-04           0.0003    2.449312e-04   \n",
       "4        0.049100  8.645173e-03           0.0004    1.998193e-04   \n",
       "5        0.015800  3.042680e-03           0.0002    2.449897e-04   \n",
       "6        0.003506  1.345019e-05           0.0003    2.450091e-04   \n",
       "7        0.010394  3.811675e-04           0.0005    6.106495e-07   \n",
       "8        0.003600  2.001062e-04           0.0002    2.449313e-04   \n",
       "9        0.015000  6.975526e-07           0.0000    0.000000e+00   \n",
       "10       0.016600  3.740622e-04           0.0003    2.450091e-04   \n",
       "11       0.014400  1.997955e-04           0.0003    2.448543e-04   \n",
       "\n",
       "   param_learning_rate                   param_loss  \\\n",
       "0             constant                        huber   \n",
       "1             constant          epsilon_insensitive   \n",
       "2             constant  squared_epsilon_insensitive   \n",
       "3              optimal                        huber   \n",
       "4              optimal          epsilon_insensitive   \n",
       "5              optimal  squared_epsilon_insensitive   \n",
       "6           invscaling                        huber   \n",
       "7           invscaling          epsilon_insensitive   \n",
       "8           invscaling  squared_epsilon_insensitive   \n",
       "9             adaptive                        huber   \n",
       "10            adaptive          epsilon_insensitive   \n",
       "11            adaptive  squared_epsilon_insensitive   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0      {'learning_rate': 'constant', 'loss': 'huber'}      -1.500171e-02   \n",
       "1   {'learning_rate': 'constant', 'loss': 'epsilon...      -1.430723e-02   \n",
       "2   {'learning_rate': 'constant', 'loss': 'squared...      -2.702684e+18   \n",
       "3       {'learning_rate': 'optimal', 'loss': 'huber'}      -1.447563e-02   \n",
       "4   {'learning_rate': 'optimal', 'loss': 'epsilon_...      -1.432679e-02   \n",
       "5   {'learning_rate': 'optimal', 'loss': 'squared_...      -1.621371e+21   \n",
       "6    {'learning_rate': 'invscaling', 'loss': 'huber'}      -1.536121e-02   \n",
       "7   {'learning_rate': 'invscaling', 'loss': 'epsil...      -1.446807e-02   \n",
       "8   {'learning_rate': 'invscaling', 'loss': 'squar...      -3.152228e+15   \n",
       "9      {'learning_rate': 'adaptive', 'loss': 'huber'}      -1.494730e-02   \n",
       "10  {'learning_rate': 'adaptive', 'loss': 'epsilon...      -1.431865e-02   \n",
       "11  {'learning_rate': 'adaptive', 'loss': 'squared...      -8.902478e+14   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0       -1.903127e-02      -1.289615e-02      -1.626671e-02   \n",
       "1       -1.854556e-02      -1.172814e-02      -1.570356e-02   \n",
       "2       -3.290885e+18      -4.806838e+18      -5.353147e+18   \n",
       "3       -1.876776e-02      -1.169972e-02      -1.532572e-02   \n",
       "4       -1.862491e-02      -1.157085e-02      -1.541850e-02   \n",
       "5       -1.863779e+20      -1.223009e+19      -1.703712e+19   \n",
       "6       -1.932943e-02      -1.327952e-02      -1.666147e-02   \n",
       "7       -1.878375e-02      -1.199132e-02      -1.558421e-02   \n",
       "8       -2.730101e+02      -1.029966e+05      -2.150748e+16   \n",
       "9       -1.908980e-02      -1.268334e-02      -1.619689e-02   \n",
       "10      -1.859830e-02      -1.172515e-02      -1.539892e-02   \n",
       "11      -1.911337e+16      -5.571385e+15      -4.153598e+12   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0       -1.877214e-02    -1.639360e-02    2.315183e-03                7  \n",
       "1       -1.881113e-02    -1.581912e-02    2.661610e-03                4  \n",
       "2       -4.133609e+19    -1.149793e+19    1.495029e+19               11  \n",
       "3       -1.855463e-02    -1.576469e-02    2.652566e-03                2  \n",
       "4       -1.824360e-02    -1.563693e-02    2.608444e-03                1  \n",
       "5       -1.018512e+20    -3.877735e+20    6.200892e+20               12  \n",
       "6       -1.887555e-02    -1.670144e-02    2.242339e-03                8  \n",
       "7       -1.878785e-02    -1.592304e-02    2.610784e-03                5  \n",
       "8       -2.704819e+12    -4.932483e+15    8.376890e+15                9  \n",
       "9       -1.886558e-02    -1.635658e-02    2.419497e-03                6  \n",
       "10      -1.879801e-02    -1.576781e-02    2.674809e-03                3  \n",
       "11      -5.016098e+14    -5.216153e+15    7.229995e+15               10  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = pd.DataFrame(gsearch1.cv_results_)\n",
    "gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "815ebd0d-241a-443e-8398-8e4f7e845950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SGDRegressor(learning_rate='optimal',\n",
       "                                    loss='epsilon_insensitive'),\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                         'penalty': ['l2', 'l1', 'elasticnet']})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {'penalty':['l2','l1','elasticnet'], 'alpha':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "sgd = SGDRegressor(loss = 'epsilon_insensitive', learning_rate = 'optimal')\n",
    "gsearch1 = GridSearchCV(sgd,param_test1)\n",
    "gsearch1.fit(Xtr1,y['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb20f9a7-10ea-4925-9535-2fb2d745b37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.043400</td>\n",
       "      <td>0.005894</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>2.000095e-04</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.0001, 'penalty': 'l2'}</td>\n",
       "      <td>-0.014045</td>\n",
       "      <td>-0.018375</td>\n",
       "      <td>-0.011642</td>\n",
       "      <td>-0.015818</td>\n",
       "      <td>-0.018520</td>\n",
       "      <td>-0.015680</td>\n",
       "      <td>0.002620</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.040602</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>2.438127e-04</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.0001, 'penalty': 'l1'}</td>\n",
       "      <td>-0.014408</td>\n",
       "      <td>-0.017876</td>\n",
       "      <td>-0.012553</td>\n",
       "      <td>-0.015565</td>\n",
       "      <td>-0.019286</td>\n",
       "      <td>-0.015937</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.051800</td>\n",
       "      <td>0.008021</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>2.000333e-04</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.0001, 'penalty': 'elasticnet'}</td>\n",
       "      <td>-0.014073</td>\n",
       "      <td>-0.018571</td>\n",
       "      <td>-0.011925</td>\n",
       "      <td>-0.014579</td>\n",
       "      <td>-0.019303</td>\n",
       "      <td>-0.015690</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>-0.014415</td>\n",
       "      <td>-0.018793</td>\n",
       "      <td>-0.011734</td>\n",
       "      <td>-0.015183</td>\n",
       "      <td>-0.018634</td>\n",
       "      <td>-0.015752</td>\n",
       "      <td>0.002676</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027600</td>\n",
       "      <td>0.006674</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.451650e-04</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>-0.014410</td>\n",
       "      <td>-0.018734</td>\n",
       "      <td>-0.011739</td>\n",
       "      <td>-0.015426</td>\n",
       "      <td>-0.018704</td>\n",
       "      <td>-0.015803</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.450091e-04</td>\n",
       "      <td>0.001</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.001, 'penalty': 'elasticnet'}</td>\n",
       "      <td>-0.014290</td>\n",
       "      <td>-0.018654</td>\n",
       "      <td>-0.011546</td>\n",
       "      <td>-0.015445</td>\n",
       "      <td>-0.018763</td>\n",
       "      <td>-0.015739</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.449312e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'penalty': 'l2'}</td>\n",
       "      <td>-0.014592</td>\n",
       "      <td>-0.018766</td>\n",
       "      <td>-0.012054</td>\n",
       "      <td>-0.015685</td>\n",
       "      <td>-0.018756</td>\n",
       "      <td>-0.015970</td>\n",
       "      <td>0.002565</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.448728e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'penalty': 'l1'}</td>\n",
       "      <td>-0.014677</td>\n",
       "      <td>-0.018939</td>\n",
       "      <td>-0.012285</td>\n",
       "      <td>-0.016592</td>\n",
       "      <td>-0.018782</td>\n",
       "      <td>-0.016255</td>\n",
       "      <td>0.002528</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.449702e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.01, 'penalty': 'elasticnet'}</td>\n",
       "      <td>-0.014523</td>\n",
       "      <td>-0.018812</td>\n",
       "      <td>-0.012072</td>\n",
       "      <td>-0.015655</td>\n",
       "      <td>-0.018746</td>\n",
       "      <td>-0.015962</td>\n",
       "      <td>0.002576</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>2.000572e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>-0.015171</td>\n",
       "      <td>-0.019197</td>\n",
       "      <td>-0.013083</td>\n",
       "      <td>-0.016453</td>\n",
       "      <td>-0.018759</td>\n",
       "      <td>-0.016533</td>\n",
       "      <td>0.002272</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>5.761645e-07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>-0.015296</td>\n",
       "      <td>-0.019192</td>\n",
       "      <td>-0.013255</td>\n",
       "      <td>-0.016597</td>\n",
       "      <td>-0.018783</td>\n",
       "      <td>-0.016625</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.998903e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.1, 'penalty': 'elasticnet'}</td>\n",
       "      <td>-0.015309</td>\n",
       "      <td>-0.019241</td>\n",
       "      <td>-0.013266</td>\n",
       "      <td>-0.016630</td>\n",
       "      <td>-0.018765</td>\n",
       "      <td>-0.016642</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.448728e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'penalty': 'l2'}</td>\n",
       "      <td>-0.015316</td>\n",
       "      <td>-0.019239</td>\n",
       "      <td>-0.013259</td>\n",
       "      <td>-0.016607</td>\n",
       "      <td>-0.018778</td>\n",
       "      <td>-0.016640</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>2.000095e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'penalty': 'l1'}</td>\n",
       "      <td>-0.015310</td>\n",
       "      <td>-0.019164</td>\n",
       "      <td>-0.013237</td>\n",
       "      <td>-0.016617</td>\n",
       "      <td>-0.018790</td>\n",
       "      <td>-0.016624</td>\n",
       "      <td>0.002206</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>2.000350e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1, 'penalty': 'elasticnet'}</td>\n",
       "      <td>-0.015307</td>\n",
       "      <td>-0.019164</td>\n",
       "      <td>-0.013236</td>\n",
       "      <td>-0.016614</td>\n",
       "      <td>-0.018782</td>\n",
       "      <td>-0.016621</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.452246e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 10, 'penalty': 'l2'}</td>\n",
       "      <td>-0.015347</td>\n",
       "      <td>-0.019221</td>\n",
       "      <td>-0.013271</td>\n",
       "      <td>-0.016640</td>\n",
       "      <td>-0.018812</td>\n",
       "      <td>-0.016658</td>\n",
       "      <td>0.002209</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>3.814697e-07</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 10, 'penalty': 'l1'}</td>\n",
       "      <td>-0.015308</td>\n",
       "      <td>-0.019165</td>\n",
       "      <td>-0.013248</td>\n",
       "      <td>-0.016615</td>\n",
       "      <td>-0.018727</td>\n",
       "      <td>-0.016613</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.001772</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>4.156970e-07</td>\n",
       "      <td>10</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 10, 'penalty': 'elasticnet'}</td>\n",
       "      <td>-0.015293</td>\n",
       "      <td>-0.019165</td>\n",
       "      <td>-0.013243</td>\n",
       "      <td>-0.016385</td>\n",
       "      <td>-0.018586</td>\n",
       "      <td>-0.016534</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>2.001054e-04</td>\n",
       "      <td>100</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 100, 'penalty': 'l2'}</td>\n",
       "      <td>-0.014864</td>\n",
       "      <td>-0.018781</td>\n",
       "      <td>-0.012853</td>\n",
       "      <td>-0.016136</td>\n",
       "      <td>-0.019156</td>\n",
       "      <td>-0.016358</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.450483e-04</td>\n",
       "      <td>100</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 100, 'penalty': 'l1'}</td>\n",
       "      <td>-0.014861</td>\n",
       "      <td>-0.019522</td>\n",
       "      <td>-0.013551</td>\n",
       "      <td>-0.016135</td>\n",
       "      <td>-0.018242</td>\n",
       "      <td>-0.016462</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.449709e-04</td>\n",
       "      <td>100</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 100, 'penalty': 'elasticnet'}</td>\n",
       "      <td>-0.014809</td>\n",
       "      <td>-0.018651</td>\n",
       "      <td>-0.012837</td>\n",
       "      <td>-0.016957</td>\n",
       "      <td>-0.019166</td>\n",
       "      <td>-0.016484</td>\n",
       "      <td>0.002376</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.999381e-04</td>\n",
       "      <td>1000</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1000, 'penalty': 'l2'}</td>\n",
       "      <td>-0.015223</td>\n",
       "      <td>-0.019677</td>\n",
       "      <td>-0.013161</td>\n",
       "      <td>-0.017131</td>\n",
       "      <td>-0.018698</td>\n",
       "      <td>-0.016778</td>\n",
       "      <td>0.002354</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.449318e-04</td>\n",
       "      <td>1000</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1000, 'penalty': 'l1'}</td>\n",
       "      <td>-0.015844</td>\n",
       "      <td>-0.019670</td>\n",
       "      <td>-0.013166</td>\n",
       "      <td>-0.017131</td>\n",
       "      <td>-0.019321</td>\n",
       "      <td>-0.017026</td>\n",
       "      <td>0.002390</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.452434e-04</td>\n",
       "      <td>1000</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1000, 'penalty': 'elasticnet'}</td>\n",
       "      <td>-0.015846</td>\n",
       "      <td>-0.019073</td>\n",
       "      <td>-0.013711</td>\n",
       "      <td>-0.017130</td>\n",
       "      <td>-0.019316</td>\n",
       "      <td>-0.017015</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.043400      0.005894         0.000400    2.000095e-04      0.0001   \n",
       "1        0.040602      0.003380         0.000299    2.438127e-04      0.0001   \n",
       "2        0.051800      0.008021         0.000400    2.000333e-04      0.0001   \n",
       "3        0.017200      0.002581         0.000000    0.000000e+00       0.001   \n",
       "4        0.027600      0.006674         0.000300    2.451650e-04       0.001   \n",
       "5        0.028000      0.002168         0.000300    2.450091e-04       0.001   \n",
       "6        0.007500      0.000548         0.000200    2.449312e-04        0.01   \n",
       "7        0.018600      0.005142         0.000200    2.448728e-04        0.01   \n",
       "8        0.011200      0.001029         0.000300    2.449702e-04        0.01   \n",
       "9        0.003800      0.000400         0.000400    2.000572e-04         0.1   \n",
       "10       0.006100      0.000734         0.000500    5.761645e-07         0.1   \n",
       "11       0.005800      0.000400         0.000400    1.998903e-04         0.1   \n",
       "12       0.003300      0.000245         0.000200    2.448728e-04           1   \n",
       "13       0.005000      0.000316         0.000400    2.000095e-04           1   \n",
       "14       0.005700      0.000400         0.000400    2.000350e-04           1   \n",
       "15       0.002998      0.000307         0.000200    2.452246e-04          10   \n",
       "16       0.004900      0.000374         0.000500    3.814697e-07          10   \n",
       "17       0.006100      0.001772         0.000500    4.156970e-07          10   \n",
       "18       0.003200      0.000245         0.000400    2.001054e-04         100   \n",
       "19       0.005800      0.000245         0.000300    2.450483e-04         100   \n",
       "20       0.005900      0.000490         0.000300    2.449709e-04         100   \n",
       "21       0.002600      0.000200         0.000400    1.999381e-04        1000   \n",
       "22       0.004500      0.000316         0.000300    2.449318e-04        1000   \n",
       "23       0.004300      0.000400         0.000300    2.452434e-04        1000   \n",
       "\n",
       "   param_penalty                                      params  \\\n",
       "0             l2          {'alpha': 0.0001, 'penalty': 'l2'}   \n",
       "1             l1          {'alpha': 0.0001, 'penalty': 'l1'}   \n",
       "2     elasticnet  {'alpha': 0.0001, 'penalty': 'elasticnet'}   \n",
       "3             l2           {'alpha': 0.001, 'penalty': 'l2'}   \n",
       "4             l1           {'alpha': 0.001, 'penalty': 'l1'}   \n",
       "5     elasticnet   {'alpha': 0.001, 'penalty': 'elasticnet'}   \n",
       "6             l2            {'alpha': 0.01, 'penalty': 'l2'}   \n",
       "7             l1            {'alpha': 0.01, 'penalty': 'l1'}   \n",
       "8     elasticnet    {'alpha': 0.01, 'penalty': 'elasticnet'}   \n",
       "9             l2             {'alpha': 0.1, 'penalty': 'l2'}   \n",
       "10            l1             {'alpha': 0.1, 'penalty': 'l1'}   \n",
       "11    elasticnet     {'alpha': 0.1, 'penalty': 'elasticnet'}   \n",
       "12            l2               {'alpha': 1, 'penalty': 'l2'}   \n",
       "13            l1               {'alpha': 1, 'penalty': 'l1'}   \n",
       "14    elasticnet       {'alpha': 1, 'penalty': 'elasticnet'}   \n",
       "15            l2              {'alpha': 10, 'penalty': 'l2'}   \n",
       "16            l1              {'alpha': 10, 'penalty': 'l1'}   \n",
       "17    elasticnet      {'alpha': 10, 'penalty': 'elasticnet'}   \n",
       "18            l2             {'alpha': 100, 'penalty': 'l2'}   \n",
       "19            l1             {'alpha': 100, 'penalty': 'l1'}   \n",
       "20    elasticnet     {'alpha': 100, 'penalty': 'elasticnet'}   \n",
       "21            l2            {'alpha': 1000, 'penalty': 'l2'}   \n",
       "22            l1            {'alpha': 1000, 'penalty': 'l1'}   \n",
       "23    elasticnet    {'alpha': 1000, 'penalty': 'elasticnet'}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0           -0.014045          -0.018375          -0.011642   \n",
       "1           -0.014408          -0.017876          -0.012553   \n",
       "2           -0.014073          -0.018571          -0.011925   \n",
       "3           -0.014415          -0.018793          -0.011734   \n",
       "4           -0.014410          -0.018734          -0.011739   \n",
       "5           -0.014290          -0.018654          -0.011546   \n",
       "6           -0.014592          -0.018766          -0.012054   \n",
       "7           -0.014677          -0.018939          -0.012285   \n",
       "8           -0.014523          -0.018812          -0.012072   \n",
       "9           -0.015171          -0.019197          -0.013083   \n",
       "10          -0.015296          -0.019192          -0.013255   \n",
       "11          -0.015309          -0.019241          -0.013266   \n",
       "12          -0.015316          -0.019239          -0.013259   \n",
       "13          -0.015310          -0.019164          -0.013237   \n",
       "14          -0.015307          -0.019164          -0.013236   \n",
       "15          -0.015347          -0.019221          -0.013271   \n",
       "16          -0.015308          -0.019165          -0.013248   \n",
       "17          -0.015293          -0.019165          -0.013243   \n",
       "18          -0.014864          -0.018781          -0.012853   \n",
       "19          -0.014861          -0.019522          -0.013551   \n",
       "20          -0.014809          -0.018651          -0.012837   \n",
       "21          -0.015223          -0.019677          -0.013161   \n",
       "22          -0.015844          -0.019670          -0.013166   \n",
       "23          -0.015846          -0.019073          -0.013711   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0           -0.015818          -0.018520        -0.015680        0.002620   \n",
       "1           -0.015565          -0.019286        -0.015937        0.002404   \n",
       "2           -0.014579          -0.019303        -0.015690        0.002806   \n",
       "3           -0.015183          -0.018634        -0.015752        0.002676   \n",
       "4           -0.015426          -0.018704        -0.015803        0.002669   \n",
       "5           -0.015445          -0.018763        -0.015739        0.002735   \n",
       "6           -0.015685          -0.018756        -0.015970        0.002565   \n",
       "7           -0.016592          -0.018782        -0.016255        0.002528   \n",
       "8           -0.015655          -0.018746        -0.015962        0.002576   \n",
       "9           -0.016453          -0.018759        -0.016533        0.002272   \n",
       "10          -0.016597          -0.018783        -0.016625        0.002208   \n",
       "11          -0.016630          -0.018765        -0.016642        0.002211   \n",
       "12          -0.016607          -0.018778        -0.016640        0.002214   \n",
       "13          -0.016617          -0.018790        -0.016624        0.002206   \n",
       "14          -0.016614          -0.018782        -0.016621        0.002205   \n",
       "15          -0.016640          -0.018812        -0.016658        0.002209   \n",
       "16          -0.016615          -0.018727        -0.016613        0.002191   \n",
       "17          -0.016385          -0.018586        -0.016534        0.002169   \n",
       "18          -0.016136          -0.019156        -0.016358        0.002378   \n",
       "19          -0.016135          -0.018242        -0.016462        0.002176   \n",
       "20          -0.016957          -0.019166        -0.016484        0.002376   \n",
       "21          -0.017131          -0.018698        -0.016778        0.002354   \n",
       "22          -0.017131          -0.019321        -0.017026        0.002390   \n",
       "23          -0.017130          -0.019316        -0.017015        0.002089   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 1  \n",
       "1                 6  \n",
       "2                 2  \n",
       "3                 4  \n",
       "4                 5  \n",
       "5                 3  \n",
       "6                 8  \n",
       "7                 9  \n",
       "8                 7  \n",
       "9                13  \n",
       "10               18  \n",
       "11               20  \n",
       "12               19  \n",
       "13               17  \n",
       "14               16  \n",
       "15               21  \n",
       "16               15  \n",
       "17               14  \n",
       "18               10  \n",
       "19               11  \n",
       "20               12  \n",
       "21               22  \n",
       "22               24  \n",
       "23               23  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = pd.DataFrame(gsearch1.cv_results_)\n",
    "gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "970f4261-b397-4449-9b43-ff919d31548a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SGDRegressor(learning_rate='optimal',\n",
       "                                    loss='epsilon_insensitive'),\n",
       "             param_grid={'epsilon': [0, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100,\n",
       "                                     1000],\n",
       "                         'max_iter': [1000, 2000, 3000, 4000, 5000]})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {'epsilon': [0, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], 'max_iter':[1000,2000,3000,4000, 5000]}\n",
    "sgd = SGDRegressor(loss = 'epsilon_insensitive', learning_rate = 'optimal', alpha = 0.0001, penalty = 'l2')\n",
    "gsearch1 = GridSearchCV(sgd,param_test1)\n",
    "gsearch1.fit(Xtr1,y['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aeb2b1e0-fbf6-45ef-a1e9-8b6b4c68580f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_epsilon</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059163</td>\n",
       "      <td>0.006466</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>2.002719e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'epsilon': 0, 'max_iter': 1000}</td>\n",
       "      <td>-0.014262</td>\n",
       "      <td>-0.018358</td>\n",
       "      <td>-0.011165</td>\n",
       "      <td>-0.015247</td>\n",
       "      <td>-0.019080</td>\n",
       "      <td>-0.015622</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.054700</td>\n",
       "      <td>0.005610</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.450872e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'epsilon': 0, 'max_iter': 2000}</td>\n",
       "      <td>-0.014311</td>\n",
       "      <td>-0.019006</td>\n",
       "      <td>-0.012861</td>\n",
       "      <td>-0.015404</td>\n",
       "      <td>-0.018227</td>\n",
       "      <td>-0.015962</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.055600</td>\n",
       "      <td>0.005248</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>5.309834e-07</td>\n",
       "      <td>0</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'epsilon': 0, 'max_iter': 3000}</td>\n",
       "      <td>-0.014029</td>\n",
       "      <td>-0.018548</td>\n",
       "      <td>-0.011167</td>\n",
       "      <td>-0.015321</td>\n",
       "      <td>-0.018651</td>\n",
       "      <td>-0.015543</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058700</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>2.001293e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>4000</td>\n",
       "      <td>{'epsilon': 0, 'max_iter': 4000}</td>\n",
       "      <td>-0.014677</td>\n",
       "      <td>-0.018675</td>\n",
       "      <td>-0.011126</td>\n",
       "      <td>-0.015776</td>\n",
       "      <td>-0.019070</td>\n",
       "      <td>-0.015865</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.044200</td>\n",
       "      <td>0.003970</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.999617e-04</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'epsilon': 0, 'max_iter': 5000}</td>\n",
       "      <td>-0.014820</td>\n",
       "      <td>-0.018744</td>\n",
       "      <td>-0.011319</td>\n",
       "      <td>-0.015471</td>\n",
       "      <td>-0.018655</td>\n",
       "      <td>-0.015802</td>\n",
       "      <td>0.002756</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.049700</td>\n",
       "      <td>0.002732</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>2.001052e-04</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'epsilon': 0.0001, 'max_iter': 1000}</td>\n",
       "      <td>-0.014015</td>\n",
       "      <td>-0.018637</td>\n",
       "      <td>-0.011787</td>\n",
       "      <td>-0.014973</td>\n",
       "      <td>-0.018761</td>\n",
       "      <td>-0.015635</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.048800</td>\n",
       "      <td>0.004718</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.450091e-04</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'epsilon': 0.0001, 'max_iter': 2000}</td>\n",
       "      <td>-0.014147</td>\n",
       "      <td>-0.018003</td>\n",
       "      <td>-0.012052</td>\n",
       "      <td>-0.015488</td>\n",
       "      <td>-0.018350</td>\n",
       "      <td>-0.015608</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.052400</td>\n",
       "      <td>0.005380</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>4.101908e-07</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'epsilon': 0.0001, 'max_iter': 3000}</td>\n",
       "      <td>-0.013846</td>\n",
       "      <td>-0.019368</td>\n",
       "      <td>-0.012286</td>\n",
       "      <td>-0.015538</td>\n",
       "      <td>-0.019425</td>\n",
       "      <td>-0.016092</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.050900</td>\n",
       "      <td>0.007625</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.447758e-04</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>4000</td>\n",
       "      <td>{'epsilon': 0.0001, 'max_iter': 4000}</td>\n",
       "      <td>-0.014521</td>\n",
       "      <td>-0.018508</td>\n",
       "      <td>-0.011690</td>\n",
       "      <td>-0.014030</td>\n",
       "      <td>-0.018684</td>\n",
       "      <td>-0.015486</td>\n",
       "      <td>0.002713</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.055300</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>2.000099e-04</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'epsilon': 0.0001, 'max_iter': 5000}</td>\n",
       "      <td>-0.013599</td>\n",
       "      <td>-0.018469</td>\n",
       "      <td>-0.011402</td>\n",
       "      <td>-0.015057</td>\n",
       "      <td>-0.018874</td>\n",
       "      <td>-0.015480</td>\n",
       "      <td>0.002856</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.051200</td>\n",
       "      <td>0.004445</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>4.264961e-07</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'epsilon': 0.001, 'max_iter': 1000}</td>\n",
       "      <td>-0.014488</td>\n",
       "      <td>-0.018249</td>\n",
       "      <td>-0.012270</td>\n",
       "      <td>-0.015252</td>\n",
       "      <td>-0.018858</td>\n",
       "      <td>-0.015823</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.050400</td>\n",
       "      <td>0.004790</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.451064e-04</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'epsilon': 0.001, 'max_iter': 2000}</td>\n",
       "      <td>-0.014243</td>\n",
       "      <td>-0.018898</td>\n",
       "      <td>-0.011855</td>\n",
       "      <td>-0.015237</td>\n",
       "      <td>-0.019243</td>\n",
       "      <td>-0.015895</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.051900</td>\n",
       "      <td>0.009687</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.450480e-04</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'epsilon': 0.001, 'max_iter': 3000}</td>\n",
       "      <td>-0.014252</td>\n",
       "      <td>-0.018750</td>\n",
       "      <td>-0.011234</td>\n",
       "      <td>-0.015505</td>\n",
       "      <td>-0.018998</td>\n",
       "      <td>-0.015748</td>\n",
       "      <td>0.002907</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.048299</td>\n",
       "      <td>0.007718</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.999859e-04</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4000</td>\n",
       "      <td>{'epsilon': 0.001, 'max_iter': 4000}</td>\n",
       "      <td>-0.014137</td>\n",
       "      <td>-0.018883</td>\n",
       "      <td>-0.011928</td>\n",
       "      <td>-0.015659</td>\n",
       "      <td>-0.018131</td>\n",
       "      <td>-0.015748</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.048500</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.049042e-06</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'epsilon': 0.001, 'max_iter': 5000}</td>\n",
       "      <td>-0.013869</td>\n",
       "      <td>-0.018464</td>\n",
       "      <td>-0.012049</td>\n",
       "      <td>-0.015210</td>\n",
       "      <td>-0.017446</td>\n",
       "      <td>-0.015408</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.008099</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.992467e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'epsilon': 0.01, 'max_iter': 1000}</td>\n",
       "      <td>-0.014261</td>\n",
       "      <td>-0.018644</td>\n",
       "      <td>-0.012362</td>\n",
       "      <td>-0.014722</td>\n",
       "      <td>-0.018487</td>\n",
       "      <td>-0.015695</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.048800</td>\n",
       "      <td>0.003586</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>6.910027e-07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'epsilon': 0.01, 'max_iter': 2000}</td>\n",
       "      <td>-0.014475</td>\n",
       "      <td>-0.018731</td>\n",
       "      <td>-0.012287</td>\n",
       "      <td>-0.014739</td>\n",
       "      <td>-0.019088</td>\n",
       "      <td>-0.015864</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.054699</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.450872e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'epsilon': 0.01, 'max_iter': 3000}</td>\n",
       "      <td>-0.014802</td>\n",
       "      <td>-0.018748</td>\n",
       "      <td>-0.011955</td>\n",
       "      <td>-0.014500</td>\n",
       "      <td>-0.018831</td>\n",
       "      <td>-0.015767</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.003826</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.449314e-04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4000</td>\n",
       "      <td>{'epsilon': 0.01, 'max_iter': 4000}</td>\n",
       "      <td>-0.014434</td>\n",
       "      <td>-0.017776</td>\n",
       "      <td>-0.011689</td>\n",
       "      <td>-0.015431</td>\n",
       "      <td>-0.018854</td>\n",
       "      <td>-0.015637</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.052400</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>3.989506e-07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'epsilon': 0.01, 'max_iter': 5000}</td>\n",
       "      <td>-0.014469</td>\n",
       "      <td>-0.018152</td>\n",
       "      <td>-0.011096</td>\n",
       "      <td>-0.014805</td>\n",
       "      <td>-0.018459</td>\n",
       "      <td>-0.015396</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.042600</td>\n",
       "      <td>0.003336</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>2.453596e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'epsilon': 0.1, 'max_iter': 1000}</td>\n",
       "      <td>-0.013953</td>\n",
       "      <td>-0.017931</td>\n",
       "      <td>-0.011454</td>\n",
       "      <td>-0.015297</td>\n",
       "      <td>-0.018966</td>\n",
       "      <td>-0.015520</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.040299</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>5.722046e-07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'epsilon': 0.1, 'max_iter': 2000}</td>\n",
       "      <td>-0.014656</td>\n",
       "      <td>-0.018827</td>\n",
       "      <td>-0.011745</td>\n",
       "      <td>-0.015005</td>\n",
       "      <td>-0.018090</td>\n",
       "      <td>-0.015665</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.043000</td>\n",
       "      <td>0.007943</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.449703e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'epsilon': 0.1, 'max_iter': 3000}</td>\n",
       "      <td>-0.014303</td>\n",
       "      <td>-0.017504</td>\n",
       "      <td>-0.011872</td>\n",
       "      <td>-0.015334</td>\n",
       "      <td>-0.018279</td>\n",
       "      <td>-0.015458</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.005591</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.999859e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4000</td>\n",
       "      <td>{'epsilon': 0.1, 'max_iter': 4000}</td>\n",
       "      <td>-0.014090</td>\n",
       "      <td>-0.018253</td>\n",
       "      <td>-0.011124</td>\n",
       "      <td>-0.015610</td>\n",
       "      <td>-0.018203</td>\n",
       "      <td>-0.015456</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.045300</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>2.000813e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'epsilon': 0.1, 'max_iter': 5000}</td>\n",
       "      <td>-0.013556</td>\n",
       "      <td>-0.018814</td>\n",
       "      <td>-0.012184</td>\n",
       "      <td>-0.015599</td>\n",
       "      <td>-0.018912</td>\n",
       "      <td>-0.015813</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.444076e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'epsilon': 1, 'max_iter': 1000}</td>\n",
       "      <td>-0.012591</td>\n",
       "      <td>-0.016881</td>\n",
       "      <td>-0.009328</td>\n",
       "      <td>-0.013260</td>\n",
       "      <td>-0.016444</td>\n",
       "      <td>-0.013701</td>\n",
       "      <td>0.002763</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.446999e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'epsilon': 1, 'max_iter': 2000}</td>\n",
       "      <td>-0.012772</td>\n",
       "      <td>-0.016703</td>\n",
       "      <td>-0.011851</td>\n",
       "      <td>-0.013574</td>\n",
       "      <td>-0.016768</td>\n",
       "      <td>-0.014334</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.003281</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.446979e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'epsilon': 1, 'max_iter': 3000}</td>\n",
       "      <td>-0.011375</td>\n",
       "      <td>-0.017780</td>\n",
       "      <td>-0.010987</td>\n",
       "      <td>-0.012478</td>\n",
       "      <td>-0.016802</td>\n",
       "      <td>-0.013884</td>\n",
       "      <td>0.002841</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.022302</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>2.000574e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>{'epsilon': 1, 'max_iter': 4000}</td>\n",
       "      <td>-0.012354</td>\n",
       "      <td>-0.016430</td>\n",
       "      <td>-0.008482</td>\n",
       "      <td>-0.013113</td>\n",
       "      <td>-0.016428</td>\n",
       "      <td>-0.013361</td>\n",
       "      <td>0.002957</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.450870e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'epsilon': 1, 'max_iter': 5000}</td>\n",
       "      <td>-0.012044</td>\n",
       "      <td>-0.016157</td>\n",
       "      <td>-0.009304</td>\n",
       "      <td>-0.013436</td>\n",
       "      <td>-0.016745</td>\n",
       "      <td>-0.013537</td>\n",
       "      <td>0.002732</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.449314e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'epsilon': 10, 'max_iter': 1000}</td>\n",
       "      <td>0.002562</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.001373</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>0.002138</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.007400</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.999855e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'epsilon': 10, 'max_iter': 2000}</td>\n",
       "      <td>0.003076</td>\n",
       "      <td>0.003473</td>\n",
       "      <td>0.004930</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.002839</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.999857e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'epsilon': 10, 'max_iter': 3000}</td>\n",
       "      <td>0.005422</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>0.005370</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0.002135</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.010100</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>2.000810e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>4000</td>\n",
       "      <td>{'epsilon': 10, 'max_iter': 4000}</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.004145</td>\n",
       "      <td>0.001877</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.006501</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.999382e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'epsilon': 10, 'max_iter': 5000}</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>0.004065</td>\n",
       "      <td>0.008122</td>\n",
       "      <td>0.004802</td>\n",
       "      <td>-0.000921</td>\n",
       "      <td>0.004207</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.009400</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.450484e-04</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'epsilon': 100, 'max_iter': 1000}</td>\n",
       "      <td>-1.742504</td>\n",
       "      <td>-1.176085</td>\n",
       "      <td>-1.492839</td>\n",
       "      <td>-1.476666</td>\n",
       "      <td>-1.359047</td>\n",
       "      <td>-1.449428</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.008599</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>2.455165e-04</td>\n",
       "      <td>100</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'epsilon': 100, 'max_iter': 2000}</td>\n",
       "      <td>-1.722650</td>\n",
       "      <td>-1.192454</td>\n",
       "      <td>-1.487744</td>\n",
       "      <td>-1.457803</td>\n",
       "      <td>-1.364752</td>\n",
       "      <td>-1.445081</td>\n",
       "      <td>0.172800</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.009007</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>2.394129e-04</td>\n",
       "      <td>100</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'epsilon': 100, 'max_iter': 3000}</td>\n",
       "      <td>-1.723278</td>\n",
       "      <td>-1.199414</td>\n",
       "      <td>-1.488415</td>\n",
       "      <td>-1.468240</td>\n",
       "      <td>-1.357974</td>\n",
       "      <td>-1.447464</td>\n",
       "      <td>0.171883</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>2.000099e-04</td>\n",
       "      <td>100</td>\n",
       "      <td>4000</td>\n",
       "      <td>{'epsilon': 100, 'max_iter': 4000}</td>\n",
       "      <td>-1.739773</td>\n",
       "      <td>-1.184074</td>\n",
       "      <td>-1.486941</td>\n",
       "      <td>-1.441344</td>\n",
       "      <td>-1.370316</td>\n",
       "      <td>-1.444490</td>\n",
       "      <td>0.180179</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.997948e-04</td>\n",
       "      <td>100</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'epsilon': 100, 'max_iter': 5000}</td>\n",
       "      <td>-1.718686</td>\n",
       "      <td>-1.203984</td>\n",
       "      <td>-1.496578</td>\n",
       "      <td>-1.469499</td>\n",
       "      <td>-1.369338</td>\n",
       "      <td>-1.451617</td>\n",
       "      <td>0.168380</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.999858e-04</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'epsilon': 1000, 'max_iter': 1000}</td>\n",
       "      <td>-0.140075</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.011597</td>\n",
       "      <td>-0.038745</td>\n",
       "      <td>-0.059363</td>\n",
       "      <td>-0.045202</td>\n",
       "      <td>0.053972</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.450093e-04</td>\n",
       "      <td>1000</td>\n",
       "      <td>2000</td>\n",
       "      <td>{'epsilon': 1000, 'max_iter': 2000}</td>\n",
       "      <td>-0.058555</td>\n",
       "      <td>0.005366</td>\n",
       "      <td>-0.004423</td>\n",
       "      <td>-0.063248</td>\n",
       "      <td>-0.054975</td>\n",
       "      <td>-0.035167</td>\n",
       "      <td>0.029380</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.450091e-04</td>\n",
       "      <td>1000</td>\n",
       "      <td>3000</td>\n",
       "      <td>{'epsilon': 1000, 'max_iter': 3000}</td>\n",
       "      <td>-0.068699</td>\n",
       "      <td>-0.009309</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>-0.040839</td>\n",
       "      <td>-0.077533</td>\n",
       "      <td>-0.036856</td>\n",
       "      <td>0.034176</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.999142e-04</td>\n",
       "      <td>1000</td>\n",
       "      <td>4000</td>\n",
       "      <td>{'epsilon': 1000, 'max_iter': 4000}</td>\n",
       "      <td>-0.097786</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.011743</td>\n",
       "      <td>-0.080551</td>\n",
       "      <td>-0.092052</td>\n",
       "      <td>-0.051704</td>\n",
       "      <td>0.047530</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.450482e-04</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'epsilon': 1000, 'max_iter': 5000}</td>\n",
       "      <td>-0.134519</td>\n",
       "      <td>-0.005490</td>\n",
       "      <td>0.010005</td>\n",
       "      <td>-0.049760</td>\n",
       "      <td>-0.062287</td>\n",
       "      <td>-0.048410</td>\n",
       "      <td>0.050722</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.059163      0.006466         0.000401    2.002719e-04   \n",
       "1        0.054700      0.005610         0.000300    2.450872e-04   \n",
       "2        0.055600      0.005248         0.000500    5.309834e-07   \n",
       "3        0.058700      0.005076         0.000400    2.001293e-04   \n",
       "4        0.044200      0.003970         0.000400    1.999617e-04   \n",
       "5        0.049700      0.002732         0.000400    2.001052e-04   \n",
       "6        0.048800      0.004718         0.000300    2.450091e-04   \n",
       "7        0.052400      0.005380         0.000500    4.101908e-07   \n",
       "8        0.050900      0.007625         0.000300    2.447758e-04   \n",
       "9        0.055300      0.002502         0.000400    2.000099e-04   \n",
       "10       0.051200      0.004445         0.000500    4.264961e-07   \n",
       "11       0.050400      0.004790         0.000200    2.451064e-04   \n",
       "12       0.051900      0.009687         0.000300    2.450480e-04   \n",
       "13       0.048299      0.007718         0.000400    1.999859e-04   \n",
       "14       0.048500      0.004723         0.000500    1.049042e-06   \n",
       "15       0.050000      0.008099         0.000600    1.992467e-04   \n",
       "16       0.048800      0.003586         0.000500    6.910027e-07   \n",
       "17       0.054699      0.004399         0.000300    2.450872e-04   \n",
       "18       0.046400      0.003826         0.000200    2.449314e-04   \n",
       "19       0.052400      0.002989         0.000500    3.989506e-07   \n",
       "20       0.042600      0.003336         0.000301    2.453596e-04   \n",
       "21       0.040299      0.004057         0.000500    5.722046e-07   \n",
       "22       0.043000      0.007943         0.000300    2.449703e-04   \n",
       "23       0.047300      0.005591         0.000400    1.999859e-04   \n",
       "24       0.045300      0.003311         0.000400    2.000813e-04   \n",
       "25       0.021400      0.003353         0.000200    2.444076e-04   \n",
       "26       0.016900      0.001841         0.000300    2.446999e-04   \n",
       "27       0.017300      0.003281         0.000300    2.446979e-04   \n",
       "28       0.022302      0.002167         0.000400    2.000574e-04   \n",
       "29       0.020900      0.002746         0.000300    2.450870e-04   \n",
       "30       0.007900      0.002268         0.000300    2.449314e-04   \n",
       "31       0.007400      0.001800         0.000100    1.999855e-04   \n",
       "32       0.007300      0.001939         0.000400    1.999857e-04   \n",
       "33       0.010100      0.002800         0.000400    2.000810e-04   \n",
       "34       0.006501      0.000836         0.000400    1.999382e-04   \n",
       "35       0.009400      0.000860         0.000200    2.450484e-04   \n",
       "36       0.008599      0.000583         0.000301    2.455165e-04   \n",
       "37       0.009007      0.001088         0.000293    2.394129e-04   \n",
       "38       0.008600      0.000374         0.000400    2.000099e-04   \n",
       "39       0.009900      0.001200         0.000100    1.997948e-04   \n",
       "40       0.002700      0.000400         0.000400    1.999858e-04   \n",
       "41       0.003000      0.000447         0.000300    2.450093e-04   \n",
       "42       0.002900      0.000583         0.000300    2.450091e-04   \n",
       "43       0.003300      0.000812         0.000400    1.999142e-04   \n",
       "44       0.002800      0.000678         0.000300    2.450482e-04   \n",
       "\n",
       "   param_epsilon param_max_iter                                 params  \\\n",
       "0              0           1000       {'epsilon': 0, 'max_iter': 1000}   \n",
       "1              0           2000       {'epsilon': 0, 'max_iter': 2000}   \n",
       "2              0           3000       {'epsilon': 0, 'max_iter': 3000}   \n",
       "3              0           4000       {'epsilon': 0, 'max_iter': 4000}   \n",
       "4              0           5000       {'epsilon': 0, 'max_iter': 5000}   \n",
       "5         0.0001           1000  {'epsilon': 0.0001, 'max_iter': 1000}   \n",
       "6         0.0001           2000  {'epsilon': 0.0001, 'max_iter': 2000}   \n",
       "7         0.0001           3000  {'epsilon': 0.0001, 'max_iter': 3000}   \n",
       "8         0.0001           4000  {'epsilon': 0.0001, 'max_iter': 4000}   \n",
       "9         0.0001           5000  {'epsilon': 0.0001, 'max_iter': 5000}   \n",
       "10         0.001           1000   {'epsilon': 0.001, 'max_iter': 1000}   \n",
       "11         0.001           2000   {'epsilon': 0.001, 'max_iter': 2000}   \n",
       "12         0.001           3000   {'epsilon': 0.001, 'max_iter': 3000}   \n",
       "13         0.001           4000   {'epsilon': 0.001, 'max_iter': 4000}   \n",
       "14         0.001           5000   {'epsilon': 0.001, 'max_iter': 5000}   \n",
       "15          0.01           1000    {'epsilon': 0.01, 'max_iter': 1000}   \n",
       "16          0.01           2000    {'epsilon': 0.01, 'max_iter': 2000}   \n",
       "17          0.01           3000    {'epsilon': 0.01, 'max_iter': 3000}   \n",
       "18          0.01           4000    {'epsilon': 0.01, 'max_iter': 4000}   \n",
       "19          0.01           5000    {'epsilon': 0.01, 'max_iter': 5000}   \n",
       "20           0.1           1000     {'epsilon': 0.1, 'max_iter': 1000}   \n",
       "21           0.1           2000     {'epsilon': 0.1, 'max_iter': 2000}   \n",
       "22           0.1           3000     {'epsilon': 0.1, 'max_iter': 3000}   \n",
       "23           0.1           4000     {'epsilon': 0.1, 'max_iter': 4000}   \n",
       "24           0.1           5000     {'epsilon': 0.1, 'max_iter': 5000}   \n",
       "25             1           1000       {'epsilon': 1, 'max_iter': 1000}   \n",
       "26             1           2000       {'epsilon': 1, 'max_iter': 2000}   \n",
       "27             1           3000       {'epsilon': 1, 'max_iter': 3000}   \n",
       "28             1           4000       {'epsilon': 1, 'max_iter': 4000}   \n",
       "29             1           5000       {'epsilon': 1, 'max_iter': 5000}   \n",
       "30            10           1000      {'epsilon': 10, 'max_iter': 1000}   \n",
       "31            10           2000      {'epsilon': 10, 'max_iter': 2000}   \n",
       "32            10           3000      {'epsilon': 10, 'max_iter': 3000}   \n",
       "33            10           4000      {'epsilon': 10, 'max_iter': 4000}   \n",
       "34            10           5000      {'epsilon': 10, 'max_iter': 5000}   \n",
       "35           100           1000     {'epsilon': 100, 'max_iter': 1000}   \n",
       "36           100           2000     {'epsilon': 100, 'max_iter': 2000}   \n",
       "37           100           3000     {'epsilon': 100, 'max_iter': 3000}   \n",
       "38           100           4000     {'epsilon': 100, 'max_iter': 4000}   \n",
       "39           100           5000     {'epsilon': 100, 'max_iter': 5000}   \n",
       "40          1000           1000    {'epsilon': 1000, 'max_iter': 1000}   \n",
       "41          1000           2000    {'epsilon': 1000, 'max_iter': 2000}   \n",
       "42          1000           3000    {'epsilon': 1000, 'max_iter': 3000}   \n",
       "43          1000           4000    {'epsilon': 1000, 'max_iter': 4000}   \n",
       "44          1000           5000    {'epsilon': 1000, 'max_iter': 5000}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0           -0.014262          -0.018358          -0.011165   \n",
       "1           -0.014311          -0.019006          -0.012861   \n",
       "2           -0.014029          -0.018548          -0.011167   \n",
       "3           -0.014677          -0.018675          -0.011126   \n",
       "4           -0.014820          -0.018744          -0.011319   \n",
       "5           -0.014015          -0.018637          -0.011787   \n",
       "6           -0.014147          -0.018003          -0.012052   \n",
       "7           -0.013846          -0.019368          -0.012286   \n",
       "8           -0.014521          -0.018508          -0.011690   \n",
       "9           -0.013599          -0.018469          -0.011402   \n",
       "10          -0.014488          -0.018249          -0.012270   \n",
       "11          -0.014243          -0.018898          -0.011855   \n",
       "12          -0.014252          -0.018750          -0.011234   \n",
       "13          -0.014137          -0.018883          -0.011928   \n",
       "14          -0.013869          -0.018464          -0.012049   \n",
       "15          -0.014261          -0.018644          -0.012362   \n",
       "16          -0.014475          -0.018731          -0.012287   \n",
       "17          -0.014802          -0.018748          -0.011955   \n",
       "18          -0.014434          -0.017776          -0.011689   \n",
       "19          -0.014469          -0.018152          -0.011096   \n",
       "20          -0.013953          -0.017931          -0.011454   \n",
       "21          -0.014656          -0.018827          -0.011745   \n",
       "22          -0.014303          -0.017504          -0.011872   \n",
       "23          -0.014090          -0.018253          -0.011124   \n",
       "24          -0.013556          -0.018814          -0.012184   \n",
       "25          -0.012591          -0.016881          -0.009328   \n",
       "26          -0.012772          -0.016703          -0.011851   \n",
       "27          -0.011375          -0.017780          -0.010987   \n",
       "28          -0.012354          -0.016430          -0.008482   \n",
       "29          -0.012044          -0.016157          -0.009304   \n",
       "30           0.002562           0.002124           0.001373   \n",
       "31           0.003076           0.003473           0.004930   \n",
       "32           0.005422           0.002945           0.005370   \n",
       "33           0.002392           0.004165           0.000547   \n",
       "34           0.004966           0.004065           0.008122   \n",
       "35          -1.742504          -1.176085          -1.492839   \n",
       "36          -1.722650          -1.192454          -1.487744   \n",
       "37          -1.723278          -1.199414          -1.488415   \n",
       "38          -1.739773          -1.184074          -1.486941   \n",
       "39          -1.718686          -1.203984          -1.496578   \n",
       "40          -0.140075           0.000578           0.011597   \n",
       "41          -0.058555           0.005366          -0.004423   \n",
       "42          -0.068699          -0.009309           0.012100   \n",
       "43          -0.097786           0.000126           0.011743   \n",
       "44          -0.134519          -0.005490           0.010005   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0           -0.015247          -0.019080        -0.015622        0.002874   \n",
       "1           -0.015404          -0.018227        -0.015962        0.002326   \n",
       "2           -0.015321          -0.018651        -0.015543        0.002835   \n",
       "3           -0.015776          -0.019070        -0.015865        0.002900   \n",
       "4           -0.015471          -0.018655        -0.015802        0.002756   \n",
       "5           -0.014973          -0.018761        -0.015635        0.002708   \n",
       "6           -0.015488          -0.018350        -0.015608        0.002369   \n",
       "7           -0.015538          -0.019425        -0.016092        0.002887   \n",
       "8           -0.014030          -0.018684        -0.015486        0.002713   \n",
       "9           -0.015057          -0.018874        -0.015480        0.002856   \n",
       "10          -0.015252          -0.018858        -0.015823        0.002443   \n",
       "11          -0.015237          -0.019243        -0.015895        0.002818   \n",
       "12          -0.015505          -0.018998        -0.015748        0.002907   \n",
       "13          -0.015659          -0.018131        -0.015748        0.002558   \n",
       "14          -0.015210          -0.017446        -0.015408        0.002332   \n",
       "15          -0.014722          -0.018487        -0.015695        0.002474   \n",
       "16          -0.014739          -0.019088        -0.015864        0.002631   \n",
       "17          -0.014500          -0.018831        -0.015767        0.002659   \n",
       "18          -0.015431          -0.018854        -0.015637        0.002530   \n",
       "19          -0.014805          -0.018459        -0.015396        0.002709   \n",
       "20          -0.015297          -0.018966        -0.015520        0.002710   \n",
       "21          -0.015005          -0.018090        -0.015665        0.002557   \n",
       "22          -0.015334          -0.018279        -0.015458        0.002296   \n",
       "23          -0.015610          -0.018203        -0.015456        0.002684   \n",
       "24          -0.015599          -0.018912        -0.015813        0.002717   \n",
       "25          -0.013260          -0.016444        -0.013701        0.002763   \n",
       "26          -0.013574          -0.016768        -0.014334        0.002036   \n",
       "27          -0.012478          -0.016802        -0.013884        0.002841   \n",
       "28          -0.013113          -0.016428        -0.013361        0.002957   \n",
       "29          -0.013436          -0.016745        -0.013537        0.002732   \n",
       "30           0.003121           0.001511         0.002138        0.000652   \n",
       "31           0.000831           0.001887         0.002839        0.001398   \n",
       "32           0.005338          -0.000021         0.003811        0.002135   \n",
       "33           0.004145           0.001877         0.002625        0.001387   \n",
       "34           0.004802          -0.000921         0.004207        0.002918   \n",
       "35          -1.476666          -1.359047        -1.449428        0.185151   \n",
       "36          -1.457803          -1.364752        -1.445081        0.172800   \n",
       "37          -1.468240          -1.357974        -1.447464        0.171883   \n",
       "38          -1.441344          -1.370316        -1.444490        0.180179   \n",
       "39          -1.469499          -1.369338        -1.451617        0.168380   \n",
       "40          -0.038745          -0.059363        -0.045202        0.053972   \n",
       "41          -0.063248          -0.054975        -0.035167        0.029380   \n",
       "42          -0.040839          -0.077533        -0.036856        0.034176   \n",
       "43          -0.080551          -0.092052        -0.051704        0.047530   \n",
       "44          -0.049760          -0.062287        -0.048410        0.050722   \n",
       "\n",
       "    rank_test_score  \n",
       "0                20  \n",
       "1                34  \n",
       "2                18  \n",
       "3                32  \n",
       "4                28  \n",
       "5                21  \n",
       "6                19  \n",
       "7                35  \n",
       "8                16  \n",
       "9                15  \n",
       "10               30  \n",
       "11               33  \n",
       "12               25  \n",
       "13               26  \n",
       "14               12  \n",
       "15               24  \n",
       "16               31  \n",
       "17               27  \n",
       "18               22  \n",
       "19               11  \n",
       "20               17  \n",
       "21               23  \n",
       "22               14  \n",
       "23               13  \n",
       "24               29  \n",
       "25                8  \n",
       "26               10  \n",
       "27                9  \n",
       "28                6  \n",
       "29                7  \n",
       "30                5  \n",
       "31                3  \n",
       "32                2  \n",
       "33                4  \n",
       "34                1  \n",
       "35               44  \n",
       "36               42  \n",
       "37               43  \n",
       "38               41  \n",
       "39               45  \n",
       "40               38  \n",
       "41               36  \n",
       "42               37  \n",
       "43               40  \n",
       "44               39  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = pd.DataFrame(gsearch1.cv_results_)\n",
    "gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5f903f41-aa38-4df8-8445-86cc7c8aa6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SGDRegressor(epsilon=10, learning_rate='optimal',\n",
       "                                    loss='epsilon_insensitive'),\n",
       "             param_grid={'max_iter': [5000, 6000, 7000, 8000, 9000, 10000]})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {'max_iter':[5000,6000,7000,8000,9000,10000]}\n",
    "sgd = SGDRegressor(loss = 'epsilon_insensitive', learning_rate = 'optimal', alpha = 0.0001, penalty = 'l2', epsilon = 10)\n",
    "gsearch1 = GridSearchCV(sgd,param_test1)\n",
    "gsearch1.fit(Xtr1,y['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c120db86-4235-4524-857a-fa4f47ae1ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007784</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'max_iter': 5000}</td>\n",
       "      <td>0.003375</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>-0.000551</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008102</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>6000</td>\n",
       "      <td>{'max_iter': 6000}</td>\n",
       "      <td>0.005039</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>0.005831</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.000860</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>7000</td>\n",
       "      <td>{'max_iter': 7000}</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.005684</td>\n",
       "      <td>0.004430</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.003852</td>\n",
       "      <td>0.002132</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>8000</td>\n",
       "      <td>{'max_iter': 8000}</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>0.001813</td>\n",
       "      <td>0.005812</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.002953</td>\n",
       "      <td>0.001769</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>9000</td>\n",
       "      <td>{'max_iter': 9000}</td>\n",
       "      <td>0.003723</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.005953</td>\n",
       "      <td>0.004734</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.003413</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.008200</td>\n",
       "      <td>0.001469</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>10000</td>\n",
       "      <td>{'max_iter': 10000}</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.003015</td>\n",
       "      <td>0.006464</td>\n",
       "      <td>0.003387</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.003561</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.007784      0.000744         0.000400        0.000200   \n",
       "1       0.008102      0.001015         0.000401        0.000201   \n",
       "2       0.005600      0.000860         0.000300        0.000245   \n",
       "3       0.009600      0.001020         0.000200        0.000245   \n",
       "4       0.008000      0.002073         0.000200        0.000245   \n",
       "5       0.008200      0.001469         0.000300        0.000245   \n",
       "\n",
       "  param_max_iter               params  split0_test_score  split1_test_score  \\\n",
       "0           5000   {'max_iter': 5000}           0.003375           0.002485   \n",
       "1           6000   {'max_iter': 6000}           0.005039           0.002205   \n",
       "2           7000   {'max_iter': 7000}           0.006228           0.002446   \n",
       "3           8000   {'max_iter': 8000}           0.002196           0.001813   \n",
       "4           9000   {'max_iter': 9000}           0.003723           0.001297   \n",
       "5          10000  {'max_iter': 10000}           0.003787           0.003015   \n",
       "\n",
       "   split2_test_score  split3_test_score  split4_test_score  mean_test_score  \\\n",
       "0           0.003098           0.003261          -0.000551         0.002334   \n",
       "1           0.005831           0.005155           0.001282         0.003903   \n",
       "2           0.005684           0.004430           0.000474         0.003852   \n",
       "3           0.005812           0.004076           0.000869         0.002953   \n",
       "4           0.005953           0.004734           0.001360         0.003413   \n",
       "5           0.006464           0.003387           0.001152         0.003561   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.001475                6  \n",
       "1        0.001807                1  \n",
       "2        0.002132                2  \n",
       "3        0.001769                5  \n",
       "4        0.001843                4  \n",
       "5        0.001709                3  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = pd.DataFrame(gsearch1.cv_results_)\n",
    "gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c0de9094-0be9-4db3-b258-4cec0cc87f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07386261, -0.78120744, -0.5305535 , ..., -0.14448096,\n",
       "         0.79727015,  0.12485495],\n",
       "       [ 0.27845913,  1.08654395, -0.5305535 , ...,  0.00290046,\n",
       "         0.58118974, -0.52520478],\n",
       "       [-0.05667618, -0.78120744,  0.9514467 , ...,  0.55335765,\n",
       "         0.28185355,  0.34104807],\n",
       "       ...,\n",
       "       [-0.06526939, -0.74038228, -1.2715536 , ..., -2.47736979,\n",
       "        -1.51084229, -2.4782593 ],\n",
       "       [-0.06526939,  1.86562422, -0.67875352, ..., -0.57411267,\n",
       "        -0.06834325,  0.16919357],\n",
       "       [-0.04808297,  1.02870829,  1.6924468 , ..., -0.0308921 ,\n",
       "         0.04288096,  0.00858043]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1e5cb2b7-a10b-42e0-a7e8-cea560570fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.005840565451846924\n",
      "Best Params:  {'alpha': 0.01, 'epsilon': 100, 'max_iter': 4000, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "loss = ['huber','epsilon_insensitive','squared_epsilon_insensitive']\n",
    "penalty = ['l2','l1','elasticnet']\n",
    "alpha = [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "learning_rate = ['constant', 'optimal', 'invscaling', 'adaptive'] \n",
    "epsilon = [0.1, 1, 10, 100]\n",
    "max_iter = [3000,4000,5000,6000,7000]\n",
    "params = dict(loss = loss, penalty = penalty, alpha = alpha, learning_rate = learning_rate, epsilon = epsilon, max_iter = max_iter)\n",
    "params = dict(penalty = penalty, alpha = alpha,epsilon = epsilon, max_iter = max_iter)\n",
    "sgd = SGDRegressor(loss = 'epsilon_insensitive', learning_rate = 'optimal')\n",
    "gs = GridSearchCV(estimator=sgd, param_grid=params) \n",
    "\n",
    "gs_result = gs.fit(Xtr1,y['total'])\n",
    "print('Best Score: ', gs_result.best_score_) \n",
    "print('Best Params: ', gs_result.best_params_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a87588a5-02d1-4dfb-a0fd-32ef3b8d317f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.788392\n",
       "1       0.845625\n",
       "2       0.755946\n",
       "3       0.745529\n",
       "4       0.853022\n",
       "          ...   \n",
       "6909    0.512253\n",
       "6910    0.729406\n",
       "6911    0.704026\n",
       "6912    0.785122\n",
       "6913    0.621492\n",
       "Name: total, Length: 6914, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred5['total'] = (gs_result.predict(Xte1)-min(gs_result.predict(Xte1)))/(max(gs_result.predict(Xte1)) - min(gs_result.predict(Xte1)))\n",
    "pred5.to_csv('data/pred_sgdtune_tsvd.csv', index = False)\n",
    "pred5['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e5675d9d-6268-44b9-aeba-35d6c4efd311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.133693\n",
       "1       0.044873\n",
       "2       0.057252\n",
       "3       0.022393\n",
       "4       0.085195\n",
       "          ...   \n",
       "6909    0.704945\n",
       "6910    0.049396\n",
       "6911    0.169028\n",
       "6912   -0.014695\n",
       "6913    0.291392\n",
       "Name: total, Length: 6914, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = pd.read_csv('data/pred.csv')\n",
    "model5 = SGDRegressor(loss = 'epsilon_insensitive', alpha = 0.0001, penalty = 'l2', epsilon = 0, max_iter = 6000).fit(Xtr1, y['total'])\n",
    "pred5 = pred.copy()\n",
    "pred5['total'] = model5.predict(Xte1)\n",
    "pred5.to_csv('data/pred_sgdtune_tsvd.csv', index = False)\n",
    "pred5['total']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
