{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "bd24a36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: pip in /Users/tanlu/Library/Python/3.9/lib/python/site-packages (21.3.1)\r\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path \n",
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install -q -U keras-tuner\n",
    "import keras_tuner as kt\n",
    "\n",
    "\n",
    "\n",
    "tr = pd.read_csv('/Users/tanlu/Desktop/~/2021 Fall/Stat 440/project2/stat440-21-project2/XYtr.csv')\n",
    "tr1 =tr.copy() \n",
    "tr1['cdate'] = pd.to_datetime(tr1['cdate']).values.astype(np.float64)/8.64e+13\n",
    "tr1 = tr1.fillna(0)\n",
    "\n",
    "\n",
    "pred = pd.read_csv('/Users/tanlu/Desktop/~/2021 Fall/Stat 440/project2/stat440-21-project2/pred.csv')\n",
    "\n",
    "te = pd.read_csv('/Users/tanlu/Desktop/~/2021 Fall/Stat 440/project2/stat440-21-project2/Xte.csv')\n",
    "te1 = te.copy()\n",
    "te1['cdate'] = pd.to_datetime(te1['cdate']).values.astype(np.float64)/8.64e+13\n",
    "te1 = te1.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f05ae667",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = np.zeros([tr1.shape[0],28,28])\n",
    "yy = pd.qcut(tr1['total'], 10, labels = range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "50c34b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 6914\n",
      "100 / 6914\n",
      "200 / 6914\n",
      "300 / 6914\n",
      "400 / 6914\n",
      "500 / 6914\n",
      "600 / 6914\n",
      "700 / 6914\n",
      "800 / 6914\n",
      "900 / 6914\n",
      "1000 / 6914\n",
      "1100 / 6914\n",
      "1200 / 6914\n",
      "1300 / 6914\n",
      "1400 / 6914\n",
      "1500 / 6914\n",
      "1600 / 6914\n",
      "1700 / 6914\n",
      "1800 / 6914\n",
      "1900 / 6914\n",
      "2000 / 6914\n",
      "2100 / 6914\n",
      "2200 / 6914\n",
      "2300 / 6914\n",
      "2400 / 6914\n",
      "2500 / 6914\n",
      "2600 / 6914\n",
      "2700 / 6914\n",
      "2800 / 6914\n",
      "2900 / 6914\n",
      "3000 / 6914\n",
      "3100 / 6914\n",
      "3200 / 6914\n",
      "3300 / 6914\n",
      "3400 / 6914\n",
      "3500 / 6914\n",
      "3600 / 6914\n",
      "3700 / 6914\n",
      "3800 / 6914\n",
      "3900 / 6914\n",
      "4000 / 6914\n",
      "4100 / 6914\n",
      "4200 / 6914\n",
      "4300 / 6914\n",
      "4400 / 6914\n",
      "4500 / 6914\n",
      "4600 / 6914\n",
      "4700 / 6914\n",
      "4800 / 6914\n",
      "4900 / 6914\n",
      "5000 / 6914\n",
      "5100 / 6914\n",
      "5200 / 6914\n",
      "5300 / 6914\n",
      "5400 / 6914\n",
      "5500 / 6914\n",
      "5600 / 6914\n",
      "5700 / 6914\n",
      "5800 / 6914\n",
      "5900 / 6914\n",
      "6000 / 6914\n",
      "6100 / 6914\n",
      "6200 / 6914\n",
      "6300 / 6914\n",
      "6400 / 6914\n",
      "6500 / 6914\n",
      "6600 / 6914\n",
      "6700 / 6914\n",
      "6800 / 6914\n",
      "6900 / 6914\n"
     ]
    }
   ],
   "source": [
    "found = list()\n",
    "for ii in range(tr1.shape[0]):\n",
    "    if ii % 100 == 0:\n",
    "        print('%d / %d' % (ii, tr1.shape[0]))\n",
    "    if tr1['ext'][ii] == '.png':\n",
    "        id = tr1.loc[ii,'id']\n",
    "        ff = tr1.loc[ii, 'id'] + tr1.loc[ii, 'ext']\n",
    "        path = '/Users/tanlu/Desktop/~/2021 Fall/Stat 440/project2/stat440-21-project2/images/images/' + ff\n",
    "        if not os.path.isfile(path):\n",
    "            continue\n",
    "        \n",
    "        pic = imageio.imread(path)\n",
    "        pic = Image.fromarray(pic).resize((28,28))\n",
    "        \n",
    "        try:\n",
    "            pic = np.mean(pic,axis = 2)\n",
    "        except:\n",
    "            pic = np.array(pic)\n",
    "        \n",
    "        found.append(ii)\n",
    "        # print(pic.shape)\n",
    "        zz[ii,:,:] = pic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "465552b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = zz/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "bf9a15a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 6914\n",
      "100 / 6914\n",
      "200 / 6914\n",
      "300 / 6914\n",
      "400 / 6914\n",
      "500 / 6914\n",
      "600 / 6914\n",
      "700 / 6914\n",
      "800 / 6914\n",
      "900 / 6914\n",
      "1000 / 6914\n",
      "1100 / 6914\n",
      "1200 / 6914\n",
      "1300 / 6914\n",
      "1400 / 6914\n",
      "1500 / 6914\n",
      "1600 / 6914\n",
      "1700 / 6914\n",
      "1800 / 6914\n",
      "1900 / 6914\n",
      "2000 / 6914\n",
      "2100 / 6914\n",
      "2200 / 6914\n",
      "2300 / 6914\n",
      "2400 / 6914\n",
      "2500 / 6914\n",
      "2600 / 6914\n",
      "2700 / 6914\n",
      "2800 / 6914\n",
      "2900 / 6914\n",
      "3000 / 6914\n",
      "3100 / 6914\n",
      "3200 / 6914\n",
      "3300 / 6914\n",
      "3400 / 6914\n",
      "3500 / 6914\n",
      "3600 / 6914\n",
      "3700 / 6914\n",
      "3800 / 6914\n",
      "3900 / 6914\n",
      "4000 / 6914\n",
      "4100 / 6914\n",
      "4200 / 6914\n",
      "4300 / 6914\n",
      "4400 / 6914\n",
      "4500 / 6914\n",
      "4600 / 6914\n",
      "4700 / 6914\n",
      "4800 / 6914\n",
      "4900 / 6914\n",
      "5000 / 6914\n",
      "5100 / 6914\n",
      "5200 / 6914\n",
      "5300 / 6914\n",
      "5400 / 6914\n",
      "5500 / 6914\n",
      "5600 / 6914\n",
      "5700 / 6914\n",
      "5800 / 6914\n",
      "5900 / 6914\n",
      "6000 / 6914\n",
      "6100 / 6914\n",
      "6200 / 6914\n",
      "6300 / 6914\n",
      "6400 / 6914\n",
      "6500 / 6914\n",
      "6600 / 6914\n",
      "6700 / 6914\n",
      "6800 / 6914\n",
      "6900 / 6914\n"
     ]
    }
   ],
   "source": [
    "zzte = np.zeros([tr1.shape[0],28,28])\n",
    "found = list()\n",
    "for ii in range(te1.shape[0]):\n",
    "    if ii % 100 == 0:\n",
    "        print('%d / %d' % (ii, te1.shape[0]))\n",
    "    if te1['ext'][ii] == '.png':\n",
    "        id = te1.loc[ii,'id']\n",
    "        ff = te1.loc[ii, 'id'] + te1.loc[ii, 'ext']\n",
    "        path = '/Users/tanlu/Desktop/~/2021 Fall/Stat 440/project2/stat440-21-project2/images/images/' + ff\n",
    "        if not os.path.isfile(path):\n",
    "            continue\n",
    "        \n",
    "        pic = imageio.imread(path)\n",
    "        pic = Image.fromarray(pic).resize((28,28))\n",
    "        \n",
    "        try:\n",
    "            pic = np.mean(pic,axis = 2)\n",
    "        except:\n",
    "            pic = np.array(pic)\n",
    "        \n",
    "        found.append(ii)\n",
    "        # print(pic.shape)\n",
    "        zzte[ii,:,:] = pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "fa12b6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "zzte = zzte/255\n",
    "#zzte = pd.DataFrame(np.row_stack(zzte)) # https://www.codenong.com/49540922/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "23b9cdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "217/217 [==============================] - 0s 737us/step - loss: 2.3057 - accuracy: 0.1174\n",
      "Epoch 2/100\n",
      "217/217 [==============================] - 0s 712us/step - loss: 2.2757 - accuracy: 0.1339\n",
      "Epoch 3/100\n",
      "217/217 [==============================] - 0s 707us/step - loss: 2.2677 - accuracy: 0.1377\n",
      "Epoch 4/100\n",
      "217/217 [==============================] - 0s 708us/step - loss: 2.2545 - accuracy: 0.1438\n",
      "Epoch 5/100\n",
      "217/217 [==============================] - 0s 716us/step - loss: 2.2486 - accuracy: 0.1464\n",
      "Epoch 6/100\n",
      "217/217 [==============================] - 0s 713us/step - loss: 2.2373 - accuracy: 0.1530\n",
      "Epoch 7/100\n",
      "217/217 [==============================] - 0s 712us/step - loss: 2.2321 - accuracy: 0.1540\n",
      "Epoch 8/100\n",
      "217/217 [==============================] - 0s 711us/step - loss: 2.2242 - accuracy: 0.1561\n",
      "Epoch 9/100\n",
      "217/217 [==============================] - 0s 709us/step - loss: 2.2142 - accuracy: 0.1630\n",
      "Epoch 10/100\n",
      "217/217 [==============================] - 0s 707us/step - loss: 2.2130 - accuracy: 0.1646\n",
      "Epoch 11/100\n",
      "217/217 [==============================] - 0s 713us/step - loss: 2.2016 - accuracy: 0.1689\n",
      "Epoch 12/100\n",
      "217/217 [==============================] - 0s 714us/step - loss: 2.1933 - accuracy: 0.1708\n",
      "Epoch 13/100\n",
      "217/217 [==============================] - 0s 712us/step - loss: 2.1873 - accuracy: 0.1685\n",
      "Epoch 14/100\n",
      "217/217 [==============================] - 0s 706us/step - loss: 2.1767 - accuracy: 0.1798\n",
      "Epoch 15/100\n",
      "217/217 [==============================] - 0s 706us/step - loss: 2.1730 - accuracy: 0.1808\n",
      "Epoch 16/100\n",
      "217/217 [==============================] - 0s 709us/step - loss: 2.1629 - accuracy: 0.1880\n",
      "Epoch 17/100\n",
      "217/217 [==============================] - 0s 705us/step - loss: 2.1559 - accuracy: 0.1916\n",
      "Epoch 18/100\n",
      "217/217 [==============================] - 0s 709us/step - loss: 2.1547 - accuracy: 0.1893\n",
      "Epoch 19/100\n",
      "217/217 [==============================] - 0s 706us/step - loss: 2.1461 - accuracy: 0.1916\n",
      "Epoch 20/100\n",
      "217/217 [==============================] - 0s 708us/step - loss: 2.1477 - accuracy: 0.1912\n",
      "Epoch 21/100\n",
      "217/217 [==============================] - 0s 708us/step - loss: 2.1344 - accuracy: 0.1996\n",
      "Epoch 22/100\n",
      "217/217 [==============================] - 0s 708us/step - loss: 2.1326 - accuracy: 0.1993\n",
      "Epoch 23/100\n",
      "217/217 [==============================] - 0s 709us/step - loss: 2.1271 - accuracy: 0.2023\n",
      "Epoch 24/100\n",
      "217/217 [==============================] - 0s 703us/step - loss: 2.1233 - accuracy: 0.2018\n",
      "Epoch 25/100\n",
      "217/217 [==============================] - 0s 712us/step - loss: 2.1150 - accuracy: 0.2065\n",
      "Epoch 26/100\n",
      "217/217 [==============================] - 0s 702us/step - loss: 2.1085 - accuracy: 0.2110\n",
      "Epoch 27/100\n",
      "217/217 [==============================] - 0s 709us/step - loss: 2.1036 - accuracy: 0.2100\n",
      "Epoch 28/100\n",
      "217/217 [==============================] - 0s 707us/step - loss: 2.1025 - accuracy: 0.2065\n",
      "Epoch 29/100\n",
      "217/217 [==============================] - 0s 706us/step - loss: 2.0992 - accuracy: 0.2104\n",
      "Epoch 30/100\n",
      "217/217 [==============================] - 0s 711us/step - loss: 2.0934 - accuracy: 0.2133\n",
      "Epoch 31/100\n",
      "217/217 [==============================] - 0s 715us/step - loss: 2.0867 - accuracy: 0.2190\n",
      "Epoch 32/100\n",
      "217/217 [==============================] - 0s 711us/step - loss: 2.0830 - accuracy: 0.2213\n",
      "Epoch 33/100\n",
      "217/217 [==============================] - 0s 708us/step - loss: 2.0808 - accuracy: 0.2138\n",
      "Epoch 34/100\n",
      "217/217 [==============================] - 0s 743us/step - loss: 2.0806 - accuracy: 0.2099\n",
      "Epoch 35/100\n",
      "217/217 [==============================] - 0s 732us/step - loss: 2.0726 - accuracy: 0.2223\n",
      "Epoch 36/100\n",
      "217/217 [==============================] - 0s 712us/step - loss: 2.0695 - accuracy: 0.2242\n",
      "Epoch 37/100\n",
      "217/217 [==============================] - 0s 707us/step - loss: 2.0670 - accuracy: 0.2217\n",
      "Epoch 38/100\n",
      "217/217 [==============================] - 0s 707us/step - loss: 2.0612 - accuracy: 0.2256\n",
      "Epoch 39/100\n",
      "217/217 [==============================] - 0s 707us/step - loss: 2.0570 - accuracy: 0.2266\n",
      "Epoch 40/100\n",
      "217/217 [==============================] - 0s 716us/step - loss: 2.0696 - accuracy: 0.2216\n",
      "Epoch 41/100\n",
      "217/217 [==============================] - 0s 714us/step - loss: 2.0528 - accuracy: 0.2278\n",
      "Epoch 42/100\n",
      "217/217 [==============================] - 0s 711us/step - loss: 2.0505 - accuracy: 0.2236\n",
      "Epoch 43/100\n",
      "217/217 [==============================] - 0s 708us/step - loss: 2.0463 - accuracy: 0.2300\n",
      "Epoch 44/100\n",
      "217/217 [==============================] - 0s 708us/step - loss: 2.0461 - accuracy: 0.2281\n",
      "Epoch 45/100\n",
      "217/217 [==============================] - 0s 716us/step - loss: 2.0452 - accuracy: 0.2237\n",
      "Epoch 46/100\n",
      "217/217 [==============================] - 0s 711us/step - loss: 2.0432 - accuracy: 0.2288\n",
      "Epoch 47/100\n",
      "217/217 [==============================] - 0s 711us/step - loss: 2.0383 - accuracy: 0.2295\n",
      "Epoch 48/100\n",
      "217/217 [==============================] - 0s 732us/step - loss: 2.0356 - accuracy: 0.2317\n",
      "Epoch 49/100\n",
      "217/217 [==============================] - 0s 713us/step - loss: 2.0374 - accuracy: 0.2346\n",
      "Epoch 50/100\n",
      "217/217 [==============================] - 0s 713us/step - loss: 2.0327 - accuracy: 0.2384\n",
      "Epoch 51/100\n",
      "217/217 [==============================] - 0s 708us/step - loss: 2.0297 - accuracy: 0.2353\n",
      "Epoch 52/100\n",
      "217/217 [==============================] - 0s 714us/step - loss: 2.0323 - accuracy: 0.2324\n",
      "Epoch 53/100\n",
      "217/217 [==============================] - 0s 735us/step - loss: 2.0201 - accuracy: 0.2388\n",
      "Epoch 54/100\n",
      "217/217 [==============================] - 0s 709us/step - loss: 2.0414 - accuracy: 0.2339\n",
      "Epoch 55/100\n",
      "217/217 [==============================] - 0s 705us/step - loss: 2.0237 - accuracy: 0.2329\n",
      "Epoch 56/100\n",
      "217/217 [==============================] - 0s 707us/step - loss: 2.0267 - accuracy: 0.2356\n",
      "Epoch 57/100\n",
      "217/217 [==============================] - 0s 711us/step - loss: 2.0115 - accuracy: 0.2428\n",
      "Epoch 58/100\n",
      "217/217 [==============================] - 0s 713us/step - loss: 2.0150 - accuracy: 0.2381\n",
      "Epoch 59/100\n",
      "217/217 [==============================] - 0s 709us/step - loss: 2.0141 - accuracy: 0.2410\n",
      "Epoch 60/100\n",
      "217/217 [==============================] - 0s 709us/step - loss: 2.0135 - accuracy: 0.2394\n",
      "Epoch 61/100\n",
      "217/217 [==============================] - 0s 710us/step - loss: 2.0045 - accuracy: 0.2427\n",
      "Epoch 62/100\n",
      "217/217 [==============================] - 0s 709us/step - loss: 2.0084 - accuracy: 0.2437\n",
      "Epoch 63/100\n",
      "217/217 [==============================] - 0s 706us/step - loss: 2.0052 - accuracy: 0.2415\n",
      "Epoch 64/100\n",
      "217/217 [==============================] - 0s 712us/step - loss: 2.0023 - accuracy: 0.2423\n",
      "Epoch 65/100\n",
      "217/217 [==============================] - 0s 707us/step - loss: 2.0017 - accuracy: 0.2436\n",
      "Epoch 66/100\n",
      "217/217 [==============================] - 0s 712us/step - loss: 2.0029 - accuracy: 0.2453\n",
      "Epoch 67/100\n",
      "217/217 [==============================] - 0s 711us/step - loss: 2.0072 - accuracy: 0.2434\n",
      "Epoch 68/100\n",
      "217/217 [==============================] - 0s 717us/step - loss: 1.9949 - accuracy: 0.2450\n",
      "Epoch 69/100\n",
      "217/217 [==============================] - 0s 710us/step - loss: 1.9942 - accuracy: 0.2482\n",
      "Epoch 70/100\n",
      "217/217 [==============================] - 0s 718us/step - loss: 2.0032 - accuracy: 0.2402\n",
      "Epoch 71/100\n",
      "217/217 [==============================] - 0s 708us/step - loss: 1.9923 - accuracy: 0.2475\n",
      "Epoch 72/100\n",
      "217/217 [==============================] - 0s 710us/step - loss: 1.9880 - accuracy: 0.2495\n",
      "Epoch 73/100\n",
      "217/217 [==============================] - 0s 725us/step - loss: 1.9916 - accuracy: 0.2450\n",
      "Epoch 74/100\n",
      "217/217 [==============================] - 0s 711us/step - loss: 1.9893 - accuracy: 0.2439\n",
      "Epoch 75/100\n",
      "217/217 [==============================] - 0s 716us/step - loss: 1.9855 - accuracy: 0.2479\n",
      "Epoch 76/100\n",
      "217/217 [==============================] - 0s 709us/step - loss: 1.9845 - accuracy: 0.2470\n",
      "Epoch 77/100\n",
      "217/217 [==============================] - 0s 713us/step - loss: 1.9825 - accuracy: 0.2453\n",
      "Epoch 78/100\n",
      "217/217 [==============================] - 0s 714us/step - loss: 1.9797 - accuracy: 0.2460\n",
      "Epoch 79/100\n",
      "217/217 [==============================] - 0s 711us/step - loss: 1.9829 - accuracy: 0.2482\n",
      "Epoch 80/100\n",
      "217/217 [==============================] - 0s 702us/step - loss: 1.9803 - accuracy: 0.2489\n",
      "Epoch 81/100\n",
      "217/217 [==============================] - 0s 702us/step - loss: 1.9833 - accuracy: 0.2492\n",
      "Epoch 82/100\n",
      "217/217 [==============================] - 0s 704us/step - loss: 1.9745 - accuracy: 0.2534\n",
      "Epoch 83/100\n",
      "217/217 [==============================] - 0s 698us/step - loss: 1.9727 - accuracy: 0.2559\n",
      "Epoch 84/100\n",
      "217/217 [==============================] - 0s 697us/step - loss: 1.9770 - accuracy: 0.2498\n",
      "Epoch 85/100\n",
      "217/217 [==============================] - 0s 702us/step - loss: 1.9760 - accuracy: 0.2534\n",
      "Epoch 86/100\n",
      "217/217 [==============================] - 0s 722us/step - loss: 1.9692 - accuracy: 0.2485\n",
      "Epoch 87/100\n",
      "217/217 [==============================] - 0s 706us/step - loss: 1.9750 - accuracy: 0.2489\n",
      "Epoch 88/100\n",
      "217/217 [==============================] - 0s 703us/step - loss: 1.9689 - accuracy: 0.2534\n",
      "Epoch 89/100\n",
      "217/217 [==============================] - 0s 708us/step - loss: 1.9809 - accuracy: 0.2469\n",
      "Epoch 90/100\n",
      "217/217 [==============================] - 0s 697us/step - loss: 1.9642 - accuracy: 0.2582\n",
      "Epoch 91/100\n",
      "217/217 [==============================] - 0s 698us/step - loss: 1.9672 - accuracy: 0.2564\n",
      "Epoch 92/100\n",
      "217/217 [==============================] - 0s 706us/step - loss: 1.9701 - accuracy: 0.2547\n",
      "Epoch 93/100\n",
      "217/217 [==============================] - 0s 698us/step - loss: 1.9685 - accuracy: 0.2514\n",
      "Epoch 94/100\n",
      "217/217 [==============================] - 0s 697us/step - loss: 1.9651 - accuracy: 0.2561\n",
      "Epoch 95/100\n",
      "217/217 [==============================] - 0s 715us/step - loss: 1.9659 - accuracy: 0.2579\n",
      "Epoch 96/100\n",
      "217/217 [==============================] - 0s 704us/step - loss: 1.9650 - accuracy: 0.2576\n",
      "Epoch 97/100\n",
      "217/217 [==============================] - 0s 700us/step - loss: 1.9609 - accuracy: 0.2554\n",
      "Epoch 98/100\n",
      "217/217 [==============================] - 0s 698us/step - loss: 1.9638 - accuracy: 0.2525\n",
      "Epoch 99/100\n",
      "217/217 [==============================] - 0s 697us/step - loss: 1.9618 - accuracy: 0.2557\n",
      "Epoch 100/100\n",
      "217/217 [==============================] - 0s 715us/step - loss: 1.9598 - accuracy: 0.2540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9670bc6af0>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28,28)),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu',kernel_initializer=\"lecun_normal\"),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "model.compile(optimizer = 'adam', loss= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics = ['accuracy'])\n",
    "model.fit(zz, yy, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "22a80536",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "pred_i = pred.copy()\n",
    "pred_i['total'] = probability_model.predict(zzte)\n",
    "pred_i.to_csv('/Users/tanlu/Desktop/~/2021 Fall/Stat 440/project2/stat440-21-project2/pred_image.csv', index = False)\n",
    "#probability_model.save_weights('/Users/tanlu/Desktop/~/2021 Fall/Stat 440/project2/stat440-21-project2/tensor_text_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "33411616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read data\n",
    "\n",
    "XYtr = pd.read_csv('/Users/tanlu/Desktop/~/2021 Fall/Stat 440/project2/stat440-21-project2/XYtr.csv')\n",
    "\n",
    "\n",
    "XYtr1 = XYtr.copy() # from stackoverflow\n",
    "XYtr1['cdate'] = pd.to_datetime(XYtr1['cdate']).values.astype(np.float64)/8.64e+13\n",
    "\n",
    "Ytr1 = XYtr1['total'].copy()\n",
    "Xtr1 = XYtr1[['X.sales', 'cdate', 'fee1', 'fee2']].copy()\n",
    "\n",
    "Xtr1 = Xtr1.astype(np.float64)\n",
    "\n",
    "Xtr1 = Xtr1.fillna(0)\n",
    "\n",
    "pred = pd.read_csv('/Users/tanlu/Desktop/~/2021 Fall/Stat 440/project2/stat440-21-project2/pred.csv')\n",
    "\n",
    "Xte = pd.read_csv('/Users/tanlu/Desktop/~/2021 Fall/Stat 440/project2/stat440-21-project2/Xte.csv')\n",
    "\n",
    "Xte1 = Xte.copy()\n",
    "Xte1['cdate'] = pd.to_datetime(Xte1['cdate']).values.astype(np.float64)/8.64e+13\n",
    "Xte1 = Xte1[['X.sales', 'cdate', 'fee1', 'fee2']].copy()\n",
    "Xte1 = Xte1.astype(np.float64)\n",
    "Xte1 = Xte1.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e6a97b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Make corpus and vocab\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "K = 10\n",
    "XYtr['description'] = XYtr['description'].fillna(\"NAN\")\n",
    "Xte['description'] = Xte['description'].fillna(\"NAN\")\n",
    "corpus = list(XYtr['description'])+list(Xte['description'])\n",
    "vectorizer = CountVectorizer()\n",
    "bow = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# https://stackoverflow.com/questions/62777131/how-to-remove-frequent-infrequent-features-from-sklearn-countvectorizer \n",
    "# Code to remove top X% most frequent words (use this to remove stop words).\n",
    "\n",
    "total_features = len(vectorizer.vocabulary_)\n",
    "top_vect = CountVectorizer(max_features=int(total_features * 0.1))\n",
    "top_bow = top_vect.fit_transform(corpus)\n",
    "\n",
    "# Create a list of (term, frequency) tuples sorted by their frequency\n",
    "sum_words = bow.sum(axis=0) \n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
    "words_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# Keep only the terms in a list\n",
    "vocabulary, _ = zip(*words_freq[:int(total_features*0.9)])\n",
    "vocabulary = list(vocabulary)\n",
    "\n",
    "bottom_vect = CountVectorizer(vocabulary=vocabulary)\n",
    "corpus = bottom_vect.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a1b3ad97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42000882, 0.05564238, 0.00416762, ..., 0.0041674 , 0.0483719 ,\n",
       "        0.00416805],\n",
       "       [0.01428615, 0.01428686, 0.01429063, ..., 0.01428675, 0.01428655,\n",
       "        0.01428775],\n",
       "       [0.00357157, 0.00357209, 0.00357156, ..., 0.00357164, 0.00357181,\n",
       "        0.00357162],\n",
       "       ...,\n",
       "       [0.00303045, 0.97272401, 0.00303043, ..., 0.00303081, 0.00303068,\n",
       "        0.0030309 ],\n",
       "       [0.72915337, 0.00322662, 0.00322672, ..., 0.00322625, 0.00322624,\n",
       "        0.00322662],\n",
       "       [0.00357157, 0.00357209, 0.00357156, ..., 0.00357164, 0.00357182,\n",
       "        0.00357162]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components = K)\n",
    "lda.fit(corpus)\n",
    "topics = lda.transform(corpus)\n",
    "N = XYtr.shape[0]\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f9bea83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open('/Users/tanlu/Desktop/~/2021 Fall/Stat 440/project2/stat440-21-project2/XYtr_ft.csv', 'w')\n",
    "fp.write('id')\n",
    "for k in range(K):\n",
    "    fp.write(',FT%04d' % k)\n",
    "\n",
    "fp.write('\\n')\n",
    "for i in range(N):\n",
    "    id = XYtr.loc[i,'id']\n",
    "    fp.write('%s' % id)\n",
    "    for k in range(K):\n",
    "        fp.write(',%f' % topics[i, k])\n",
    "    \n",
    "    fp.write('\\n')\n",
    "\n",
    "fp.close()    \n",
    "\n",
    "fp = open('/Users/tanlu/Desktop/~/2021 Fall/Stat 440/project2/stat440-21-project2/Xte_ft.csv', 'w')\n",
    "fp.write('id')\n",
    "for k in range(K):\n",
    "    fp.write(',FT%04d' % k)\n",
    "\n",
    "fp.write('\\n')\n",
    "for i in range(N):\n",
    "    id = Xte.loc[i,'id']\n",
    "    fp.write('%s' % id)\n",
    "    for k in range(K):\n",
    "        fp.write(',%f' % topics[i + N, k])\n",
    "    \n",
    "    fp.write('\\n')\n",
    "\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f02440bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text\n",
    "Xtr_ft = pd.read_csv('/Users/tanlu/Desktop/~/2021 Fall/Stat 440/project2/stat440-21-project2/XYtr_ft.csv')\n",
    "Xtr_ft1 = Xtr_ft.copy()\n",
    "Xtr_ft1.drop('id',1, inplace = True)\n",
    "Xtr_ft1 = Xtr_ft1.fillna(0)\n",
    "\n",
    "Xte_ft = pd.read_csv('/Users/tanlu/Desktop/~/2021 Fall/Stat 440/project2/stat440-21-project2/Xte_ft.csv')\n",
    "Xte_ft1 = Xte_ft.copy()\n",
    "Xte_ft1.drop('id',1, inplace = True)\n",
    "Xte_ft1 = Xte_ft1.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9f789990",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 15 features, but StandardScaler is expecting 42 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zk/fnlmhq6s03z80vqlhybv8d940000gn/T/ipykernel_49179/2898568041.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Xte5 = scaler.transform(Xte5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mXte5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXte5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mXtr5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtr5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSGDRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m         X = self._validate_data(X, reset=False,\n\u001b[0m\u001b[1;32m    884\u001b[0m                                 \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ensure_2d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    366\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n",
      "\u001b[0;31mValueError\u001b[0m: X has 15 features, but StandardScaler is expecting 42 features as input."
     ]
    }
   ],
   "source": [
    "Xtr_fi3 = pd.read_csv('/Users/tanlu/Desktop/~/2021 Fall/Stat 440/project2/stat440-21-project2/pred.csv')\n",
    "\n",
    "\n",
    "Xtr5 = pd.concat([Xtr1, Xtr_fi3, Xtr_ft1], axis = 1)\n",
    "Xtr5.drop('id',1, inplace = True)\n",
    "Xte5 = pd.concat([Xte1, zzte, Xte_ft1], axis = 1)\n",
    "Xte5 = Xte5.fillna(0)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "Xtr5 = scaler.fit_transform(Xtr5)\n",
    "Xte5 = scaler.transform(Xte5)\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "model5 = SGDRegressor(loss = 'epsilon_insensitive', alpha = 0, epsilon = 0).fit(Xtr5, Ytr1)\n",
    "pred5 = pred.copy()\n",
    "pred5['total'] = model5.predict(Xte5)\n",
    "Xtr_fi3 = pd.read_csv('/Users/tanlu/Desktop/~/2021 Fall/Stat 440/project2/stat440-21-project2/pred.csv')\n",
    "\n",
    "pred5.to_csv('/Users/tanlu/Desktop/~/2021 Fall/Stat 440/project2/stat440-21-project2/pred5.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcdd99d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd4a8db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
