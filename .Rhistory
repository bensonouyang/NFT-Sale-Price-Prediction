pred.nat.5 = predict(fit.nat.5, data.temp)
pred.nat.7 = predict(fit.nat.7, data.temp)
pred.nat.9 = predict(fit.nat.9, data.temp)
### Construct plot
with(AQ, plot(Temp, Ozone, xlab = "Temperature"))
lines(data.temp$Temp, pred.nat.5, col = 2, lwd = 2)
lines(data.temp$Temp, pred.nat.7, col = 3, lwd = 2)
lines(data.temp$Temp, pred.nat.9, col = 4, lwd = 2)
### Add legend
legend("topleft", legend = c("Natural Spline - 5", "Natural Spline - 7", "Natural Spline - 9"), col = 2)
plot(AQ$Temp, AQ$Ozone, xlab = "Temperature")
lines(data.temp$Temp, pred.nat.5, col = 2, lwd = 2)
lines(data.temp$Temp, pred.nat.7, col = 3, lwd = 2)
lines(data.temp$Temp, pred.nat.9, col = 4, lwd = 2)
legend("topleft", legend = c("Natural Spline - 5", "Natural Spline - 7", "Natural Spline - 9"), col = 2)
source("C:/Users/Benson/Downloads/STAT452/L6 Selection bias and shrinkage (HWK Version).R", echo=TRUE)
source("C:/Users/Benson/Downloads/STAT452/L6 Selection bias and shrinkage (HWK Version).R", echo=TRUE)
source("C:/Users/Benson/Downloads/STAT452/L6 Selection bias and shrinkage (HWK Version).R", echo=TRUE)
source("C:/Users/Benson/Downloads/STAT452/L6 Selection bias and shrinkage (HWK Version).R", echo=TRUE)
source("C:/Users/Benson/Downloads/STAT452/L6 Selection bias and shrinkage (HWK Version).R", echo=TRUE)
source("C:/Users/Benson/Downloads/STAT452/L6 Selection bias and shrinkage (HWK Version).R", echo=TRUE)
data = read.csv("midterm.csv")
data = na.omit(data)
head(data)
mdl = lm(Y~X1+X2+I(2*X1*X2)+3*(X2/X3))
mdl = lm(Y~X1+X2+I(2*X1*X2)+3*(X2/X3), data = data)
mdl = lm(Y~X1+X2+I(2*X1:X2)+3*(X2/X3), data = data)
mdl = lm(Y~X1+X2+I(2*X1*X2)+I(3*(X2/X3)), data = data)
summary(mdl)
mdl$coefficients[[3]]
mdl$coefficients[[5]]
mdl$coefficients[[3]]+(3/maxx3)*(mdl$coefficients[[5]])
maxx3 = max(data$X3)
mdl$coefficients[[3]]+(3/maxx3)*(mdl$coefficients[[5]])
data = read.csv("midterm.csv")
data = na.omit(data)
x12cp = data$X1*data$X2
x23rat = data$X2/data$X3
newdf = cbind(data,c(x12cp,x23rat))
head(newdf)
newdf = cbind(data,x12cp,x23rat)
head(newdf)
head(newdf[,-1])
library(pls)
fit.PCA = prcomp(newdf[,-1], scale. = T)
data = read.csv("midterm.csv")
data = na.omit(data)
x12cp = data$X1*data$X2
x23rat = data$X2/data$X3
newdf = cbind(data,x12cp,x23rat)
library(pls)
fit.PCA = prcomp(newdf[,-1], scale. = T)
### Compute proportion of variance explained
vars = fit.PCA$sdev^2
### Get number of PCs with variance explained >= 1
n.keep = sum(vars >= 1)
n.comps = length(vars) # Total number of PCs, for reference
plot(1:length(vars), vars,
xlab = "Principal Component", ylab = "Variance Explained")
abline(h = 1)
n.keep
n.comps
n.keep
c.vars
data = read.csv("midterm.csv")
data = na.omit(data)
x12cp = data$X1*data$X2
x23rat = data$X2/data$X3
newdf = cbind(data,x12cp,x23rat)
library(pls)
fit.PCA = prcomp(newdf[,-1], scale. = T)
### Compute proportion of variance explained
vars = fit.PCA$sdev^2
### Get number of PCs with variance explained >= 1
n.keep = sum(vars >= 1)
n.comps = length(vars) # Total number of PCs, for reference
c.vars = cumsum(vars) ### Cumulative variance explained
c.vars
rel.c.vars
rel.c.vars = c.vars / max(c.vars)
rel.c.vars
data = read.csv("midterm.csv")
data = na.omit(data)
x12cp = data$X1*data$X2
x23rat = data$X2/data$X3
newdf = cbind(data,x12cp,x23rat)
library(pls)
fit.PCA = prcomp(newdf[,-1], scale. = T)
### Compute proportion of variance explained
vars = fit.PCA$sdev^2
### Get number of PCs with variance explained >= 1
n.keep = sum(vars >= 1)
n.comps = length(vars) # Total number of PCs, for reference
c.vars = cumsum(vars) ### Cumulative variance explained
rel.c.vars = c.vars / max(c.vars)
plot(0:length(rel.c.vars), c(0,rel.c.vars), ylim = c(0,1),
xlab = "Number of Components", ylab = "Proportion of Variance Explained")
18*0.9
data = read.csv("midterm.csv")
data = na.omit(data)
x12cp = data$X1*data$X2
x23rat = data$X2/data$X3
data = cbind(data,x12cp,x23rat)
########################
### Helper Functions ###
########################
### Create function to compute MSPEs
get.MSPE = function(Y, Y.hat){
return(mean((Y - Y.hat)^2))
}
### Create function which constructs folds for CV
### n is the number of observations, K is the number of folds
get.folds = function(n, K) {
### Get the appropriate number of fold labels
n.fold = ceiling(n / K) # Number of observations per fold (rounded up)
fold.ids.raw = rep(1:K, times = n.fold)
fold.ids = fold.ids.raw[1:n]
### Shuffle the fold labels
folds.rand = fold.ids[sample.int(n)]
return(folds.rand)
}
K = 15 #Number of folds
set.seed(123)
### Container for CV MSPEs
all.models = c( "LAS-Min", "LAS-1se")
CV.MSPEs = array(0, dim = c(length(all.models), K))
rownames(CV.MSPEs) = all.models
colnames(CV.MSPEs) = 1:K
### Construct candidate lambda values (outside loop to save time)
lambda.vals = seq(from = 0, to = 100, by = 0.05)
### Get CV fold labels
n = nrow(data)
folds = get.folds(n, K)
### Perform cross-validation
for(i in 1:K){
### Get training and validation sets
# data.train = na.omit(AQ[folds != i, ])
# data.valid = na.omit(AQ[folds == i, ])
data.train = data[folds != i, ]
data.testing = data[folds == i, ]
Y.train = data.train$Y
Y.valid = data.valid$Y
### We need the data matrix to have an intercept for ridge, and to not have an intercept for LASSO. Best to just
# construct both.
mat.train.int = model.matrix(Y ~ ., data = data.train)
mat.train = mat.train.int[,-1]
mat.valid.int = model.matrix(Y ~ ., data = data.valid)
mat.valid = mat.valid.int[,-1]
#############
### LASSO ###
#############
### Fit model
fit.LASSO = cv.glmnet(mat.train, Y.train)
### Get optimal lambda values
lambda.min = fit.LASSO$lambda.min
lambda.1se = fit.LASSO$lambda.1se
### Get predictions
pred.min = predict(fit.LASSO, mat.valid, lambda.min)
pred.1se = predict(fit.LASSO, mat.valid, lambda.1se)
### Get and store MSPEs
MSPE.min = get.MSPE(Y.valid, pred.min)
MSPE.1se = get.MSPE(Y.valid, pred.1se)
CV.MSPEs["LAS-Min", i] = MSPE.min
CV.MSPEs["LAS-1se", i] = MSPE.1se
}
data = read.csv("midterm.csv")
data = na.omit(data)
x12cp = data$X1*data$X2
x23rat = data$X2/data$X3
data = cbind(data,x12cp,x23rat)
########################
### Helper Functions ###
########################
### Create function to compute MSPEs
get.MSPE = function(Y, Y.hat){
return(mean((Y - Y.hat)^2))
}
### Create function which constructs folds for CV
### n is the number of observations, K is the number of folds
get.folds = function(n, K) {
### Get the appropriate number of fold labels
n.fold = ceiling(n / K) # Number of observations per fold (rounded up)
fold.ids.raw = rep(1:K, times = n.fold)
fold.ids = fold.ids.raw[1:n]
### Shuffle the fold labels
folds.rand = fold.ids[sample.int(n)]
return(folds.rand)
}
K = 15 #Number of folds
set.seed(123)
### Container for CV MSPEs
all.models = c( "LAS-Min", "LAS-1se")
CV.MSPEs = array(0, dim = c(length(all.models), K))
rownames(CV.MSPEs) = all.models
colnames(CV.MSPEs) = 1:K
### Construct candidate lambda values (outside loop to save time)
lambda.vals = seq(from = 0, to = 100, by = 0.05)
### Get CV fold labels
n = nrow(data)
folds = get.folds(n, K)
### Perform cross-validation
for(i in 1:K){
### Get training and validation sets
# data.train = na.omit(AQ[folds != i, ])
# data.valid = na.omit(AQ[folds == i, ])
data.train = data[folds != i, ]
data.valid = data[folds == i, ]
Y.train = data.train$Y
Y.valid = data.valid$Y
### We need the data matrix to have an intercept for ridge, and to not have an intercept for LASSO. Best to just
# construct both.
mat.train.int = model.matrix(Y ~ ., data = data.train)
mat.train = mat.train.int[,-1]
mat.valid.int = model.matrix(Y ~ ., data = data.valid)
mat.valid = mat.valid.int[,-1]
#############
### LASSO ###
#############
### Fit model
fit.LASSO = cv.glmnet(mat.train, Y.train)
### Get optimal lambda values
lambda.min = fit.LASSO$lambda.min
lambda.1se = fit.LASSO$lambda.1se
### Get predictions
pred.min = predict(fit.LASSO, mat.valid, lambda.min)
pred.1se = predict(fit.LASSO, mat.valid, lambda.1se)
### Get and store MSPEs
MSPE.min = get.MSPE(Y.valid, pred.min)
MSPE.1se = get.MSPE(Y.valid, pred.1se)
CV.MSPEs["LAS-Min", i] = MSPE.min
CV.MSPEs["LAS-1se", i] = MSPE.1se
}
### Get full-data MSPEs
full.MSPEs = apply(CV.MSPEs, 1, mean)
full.MSPEs
CV.MSPEs
library(glmnet)
data = read.csv("midterm.csv")
data = na.omit(data)
x12cp = data$X1*data$X2
x23rat = data$X2/data$X3
data = cbind(data,x12cp,x23rat)
########################
### Helper Functions ###
########################
### Create function to compute MSPEs
get.MSPE = function(Y, Y.hat){
return(mean((Y - Y.hat)^2))
}
### Create function which constructs folds for CV
### n is the number of observations, K is the number of folds
get.folds = function(n, K) {
### Get the appropriate number of fold labels
n.fold = ceiling(n / K) # Number of observations per fold (rounded up)
fold.ids.raw = rep(1:K, times = n.fold)
fold.ids = fold.ids.raw[1:n]
### Shuffle the fold labels
folds.rand = fold.ids[sample.int(n)]
return(folds.rand)
}
K = 15 #Number of folds
set.seed(123)
### Container for CV MSPEs
all.models = c( "LAS-Min", "LAS-1se")
CV.MSPEs = array(0, dim = c(length(all.models), K))
rownames(CV.MSPEs) = all.models
colnames(CV.MSPEs) = 1:K
### Construct candidate lambda values (outside loop to save time)
lambda.vals = seq(from = 0, to = 100, by = 0.05)
### Get CV fold labels
n = nrow(data)
folds = get.folds(n, K)
### Perform cross-validation
for(i in 1:K){
### Get training and validation sets
# data.train = na.omit(AQ[folds != i, ])
# data.valid = na.omit(AQ[folds == i, ])
data.train = data[folds != i, ]
data.valid = data[folds == i, ]
Y.train = data.train$Y
Y.valid = data.valid$Y
### We need the data matrix to have an intercept for ridge, and to not have an intercept for LASSO. Best to just
# construct both.
mat.train.int = model.matrix(Y ~ ., data = data.train)
mat.train = mat.train.int[,-1]
mat.valid.int = model.matrix(Y ~ ., data = data.valid)
mat.valid = mat.valid.int[,-1]
#############
### LASSO ###
#############
### Fit model
fit.LASSO = cv.glmnet(mat.train, Y.train)
### Get optimal lambda values
lambda.min = fit.LASSO$lambda.min
lambda.1se = fit.LASSO$lambda.1se
### Get predictions
pred.min = predict(fit.LASSO, mat.valid, lambda.min)
pred.1se = predict(fit.LASSO, mat.valid, lambda.1se)
### Get and store MSPEs
MSPE.min = get.MSPE(Y.valid, pred.min)
MSPE.1se = get.MSPE(Y.valid, pred.1se)
CV.MSPEs["LAS-Min", i] = MSPE.min
CV.MSPEs["LAS-1se", i] = MSPE.1se
}
### Get full-data MSPEs
full.MSPEs = apply(CV.MSPEs, 1, mean)
### MSPE Boxplot
plot.MSPEs = t(CV.MSPEs)
### Compute RMSPEs
plot.RMSPEs = apply(CV.MSPEs, 2, function(W){
best = min(W)
return(W/best)
})
plot.RMSPEs = t(plot.RMSPEs)
### RMSPE Boxplot
boxplot(plot.RMSPEs)
sample.int(1e10, 12)
sample.int(1e10)
sample.int(12)
### n is the number of observations, K is the number of folds
get.folds = function(n, K) {
### Get the appropriate number of fold labels
n.fold = ceiling(n / K) # Number of observations per fold (rounded up)
fold.ids.raw = rep(1:K, times = n.fold)
fold.ids = fold.ids.raw[1:n]
### Shuffle the fold labels
folds.rand = fold.ids[sample.int(n)]
return(folds.rand)
}
get.folds(10,5)
get.folds(10,5)
get.folds(10,5)
get.folds(10,5)
get.folds(10,5)
get.folds(10,5)
get.folds(10,5)
get.folds(10,5)
get.folds(10,5)
get.folds(10,5)
get.folds(10,5)
get.folds(10,5)
knitr::kable(c(c("count","mean","std","min","25%","50%","75%","max"),c(6914,9.66,73.85,0,0.029,0.12,0.45,1195)),
format = "markdown", caption = "", col.names = c("","Total"))
ff = data.frame(total = c(6914,9.66,73.85,0,0.029,0.12,0.45,1195)))
ff = data.frame(total = c(6914,9.66,73.85,0,0.029,0.12,0.45,1195))
ff
names(ff)
row.names(ff)
row.names(ff) = c("count","mean","std","min","25%","50%","75%","max")
ff
setwd("C:/Users/Benson/Downloads/NFT-Price-Prediction")
library(tidyr)
rm(list = ls())
library(readxl)
library(stringr)
library(readr)
library(tidyr)
library(ggplot2)
library(dplyr)
XYtr = read.csv("data/XYtr.csv")
Xte = as.data.frame(read_csv( "data/Xte.csv"))
Xtr = XYtr[,c(2,3,8,9,10)]
Xtr$cdate = as.numeric(as.POSIXct(x = Xtr$cdate,tz = "UTC"))/(60*60*24)
pairs(Xtr)
boxplot(total~fee1,data = Xtr)
range = range(Xtr$total) #0  1195
interval.length = ceiling(max(range/10)) # int: 120
Xtr$label = 0
j=0
for (i in 1:nrow(Xtr)) {
if (i<=120) {
Xtr[i,6] = 1
}
else if (i<=240) {
Xtr[i,6] = 2
}
else if (i<=360) {
Xtr[i,6] = 3
}
else if (i<=480) {
Xtr[i,6] = 4
}
else if (i<=600) {
Xtr[i,6] = 5
}
else if (i<=720) {
Xtr[i,6] = 6
}
else if (i<=840) {
Xtr[i,6] = 7
}
else if (i<=960) {
Xtr[i,6] = 8
}
else if (i<=1080) {
Xtr[i,6] = 9
}
else {
Xtr[i,6] = 10
}
}
Xtr$label = as.factor(Xtr$label)
fee1.label = cut(Xtr$fee1, breaks = c(0, 250, 500, 750,1000,1300),
labels = c("1","2","3","4","5"))
Xtr$fee1.label = fee1.label
fee2.label = cut(Xtr$fee2, breaks = c(0, 250, 500, 750,1000,1300),
labels = c("1","2","3","4","5"))
Xtr$fee2.label = fee2.label
pairs(Xtr)
pairs(Xtr,   panel = function(x, y) {
panel.smooth(x, y)
abline(lsfit(x, y), lty = 2)
})
Xtr[is.na(Xtr)]
Xtr[is.na(Xtr),]
nrow(Xtr)
head(Xtr)
tail(Xtr)
which(is.na(Xtr))
Xtr[is.na(Xtr),]
rownames(Xtr)
Xtr[is.na(Xtr),] = 0
Xtr[is.na(Xtr)] = 0
Xtr[is.na(Xtr)]
which(is.na(Xtr))
str(Xtr)
XYtr
Xtr = XYtr[,c(2,3,8,9,10)]
Xtr
Xtr$cdate = as.numeric(as.POSIXct(x = Xtr$cdate,tz = "UTC"))/(60*60*24)
head(Xtr)
str(Xtr)
Xtr[is.na(Xtr)]
Xtr[is.na(Xtr)] = 0
range = range(Xtr$total) #0  1195
interval.length = ceiling(max(range/10)) # int: 120
Xtr$label = 0
j=0
for (i in 1:nrow(Xtr)) {
if (i<=120) {
Xtr[i,6] = 1
}
else if (i<=240) {
Xtr[i,6] = 2
}
else if (i<=360) {
Xtr[i,6] = 3
}
else if (i<=480) {
Xtr[i,6] = 4
}
else if (i<=600) {
Xtr[i,6] = 5
}
else if (i<=720) {
Xtr[i,6] = 6
}
else if (i<=840) {
Xtr[i,6] = 7
}
else if (i<=960) {
Xtr[i,6] = 8
}
else if (i<=1080) {
Xtr[i,6] = 9
}
else {
Xtr[i,6] = 10
}
}
Xtr$label = as.factor(Xtr$label)
fee1.label = cut(Xtr$fee1, breaks = c(0, 250, 500, 750,1000,1300),
labels = c("1","2","3","4","5"))
Xtr$fee1.label = fee1.label
fee2.label = cut(Xtr$fee2, breaks = c(0, 250, 500, 750,1000,1300),
labels = c("1","2","3","4","5"))
Xtr$fee2.label = fee2.label
pairs(Xtr,   panel = function(x, y) {
panel.smooth(x, y)
abline(lsfit(x, y), lty = 2)
})
Xtr$fee1.label
Xtr[is.na(Xtr),1]
Xtr$X.sales
plot(Xtr$X.sales,Xtr$total)
summary(Xtr$X.sales)
plot(Xtr$X.sales,Xtr$total, xlim = c(0,1))
plot(Xtr$X.sales,Xtr$total, xlim = c(0,2))
plot(Xtr$X.sales,Xtr$total, xlim = c(0,3))
plot(Xtr$X.sales,Xtr$total, xlim = c(0,4))
plot(Xtr$X.sales,Xtr$total, xlim = c(0,5))
plot(Xtr$X.sales,Xtr$total, xlim = c(0,6))
plot(Xtr$X.sales,Xtr$total, xlim = c(0,7))
plot(Xtr$X.sales,Xtr$total, xlim = c(0,8))
plot(Xtr$X.sales,Xtr$total, xlim = c(0,9))
plot(Xtr$X.sales,Xtr$total, xlim = c(0,100))
plot(Xtr$X.sales,Xtr$total, xlim = c(0,10))
colnames(Xtr)
XYtr = read.csv("data/XYtr.csv")
Xtr = XYtr[,c(2,3,8,9,10)]
Xtr$cdate = as.numeric(as.POSIXct(x = Xtr$cdate,tz = "UTC"))/(60*60*24)
Xtr[is.na(Xtr)] = 0
pairs(Xtr, panel = function(x, y) {
panel.smooth(x, y)
abline(lsfit(x, y), lty = 2)
})
plot(Xtr$X.sales)
plot(Xtr$X.sales,Xtr$total)
plot(Xtr$X.sales,Xtr$total, xlim = c(0,10))
library(reticulate)
install.packages("reticulate")
library(reticulate)
