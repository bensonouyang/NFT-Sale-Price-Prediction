{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "167eb9bf-a2b6-423d-950b-c0414d070625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9a807d8-a39c-4100-98b8-77b503b67e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29cd8f19-5031-4d4a-98cb-40d562ad8ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15526b38-3250-4c58-a738-885a3f6795e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "220e27d3-368e-446b-b251-4ea05a6644c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = pd.read_csv('data/XYtr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2e7c361-56b5-4d35-bcc5-f34cacf0747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "te = pd.read_csv('data/Xte.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16779414-5d1f-4d94-a32f-ef5f10537380",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels),(test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b18e35a1-9502-425e-ba87-32196a59d815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4429132d-e826-429d-a52c-a371cce72f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c8229d2-f0ce-4efa-8509-318d6de08a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = np.zeros([tr.shape[0],28,28])\n",
    "yy = pd.qcut(tr['total'], 10, labels = range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab43227a-3aaf-4a8f-a992-14f11227689f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.055\n",
       "1       75.000\n",
       "2        0.158\n",
       "3        1.990\n",
       "4        1.000\n",
       "         ...  \n",
       "6909     0.550\n",
       "6910     0.100\n",
       "6911     0.966\n",
       "6912     0.170\n",
       "6913     0.100\n",
       "Name: total, Length: 6914, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a378825-9b85-4c5e-a139-8684c604b13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6914, 28, 28)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a63563d8-049c-43f9-b9b8-7eb5323b78d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "id = tr.loc[i,'id']\n",
    "ff = tr.loc[i,'id'] + tr.loc[i, 'ext']\n",
    "path = 'data/images/images/' + ff\n",
    "pic = imageio.imread(path)\n",
    "pic = Image.fromarray(pic).resize((28,28))\n",
    "pic = np.mean(pic,axis = 2)\n",
    "pic = np.array(pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a8dc8abf-67b3-48b5-8869-82f2bdabad87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a55c94a2-bfe6-4f8c-9b22-a809998828cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 6914\n",
      "100 / 6914\n",
      "200 / 6914\n",
      "300 / 6914\n",
      "400 / 6914\n",
      "500 / 6914\n",
      "600 / 6914\n",
      "700 / 6914\n",
      "800 / 6914\n",
      "900 / 6914\n",
      "1000 / 6914\n",
      "1100 / 6914\n",
      "1200 / 6914\n",
      "1300 / 6914\n",
      "1400 / 6914\n",
      "1500 / 6914\n",
      "1600 / 6914\n",
      "1700 / 6914\n",
      "1800 / 6914\n",
      "1900 / 6914\n",
      "2000 / 6914\n",
      "2100 / 6914\n",
      "2200 / 6914\n",
      "2300 / 6914\n",
      "2400 / 6914\n",
      "2500 / 6914\n",
      "2600 / 6914\n",
      "2700 / 6914\n",
      "2800 / 6914\n",
      "2900 / 6914\n",
      "3000 / 6914\n",
      "3100 / 6914\n",
      "3200 / 6914\n",
      "3300 / 6914\n",
      "3400 / 6914\n",
      "3500 / 6914\n",
      "3600 / 6914\n",
      "3700 / 6914\n",
      "3800 / 6914\n",
      "3900 / 6914\n",
      "4000 / 6914\n",
      "4100 / 6914\n",
      "4200 / 6914\n",
      "4300 / 6914\n",
      "4400 / 6914\n",
      "4500 / 6914\n",
      "4600 / 6914\n",
      "4700 / 6914\n",
      "4800 / 6914\n",
      "4900 / 6914\n",
      "5000 / 6914\n",
      "5100 / 6914\n",
      "5200 / 6914\n",
      "5300 / 6914\n",
      "5400 / 6914\n",
      "5500 / 6914\n",
      "5600 / 6914\n",
      "5700 / 6914\n",
      "5800 / 6914\n",
      "5900 / 6914\n",
      "6000 / 6914\n",
      "6100 / 6914\n",
      "6200 / 6914\n",
      "6300 / 6914\n",
      "6400 / 6914\n",
      "6500 / 6914\n",
      "6600 / 6914\n",
      "6700 / 6914\n",
      "6800 / 6914\n",
      "6900 / 6914\n"
     ]
    }
   ],
   "source": [
    "found = list()\n",
    "for ii in range(tr.shape[0]):\n",
    "    if ii % 100 == 0:\n",
    "        print('%d / %d' % (ii, tr.shape[0]))\n",
    "    if tr['ext'][ii] == '.png':\n",
    "        id = tr.loc[ii,'id']\n",
    "        ff = tr.loc[ii, 'id'] + tr.loc[ii, 'ext']\n",
    "        path = 'data/images/images/' + ff\n",
    "        if not os.path.isfile(path):\n",
    "            continue\n",
    "        \n",
    "        pic = imageio.imread(path)\n",
    "        pic = Image.fromarray(pic).resize((28,28))\n",
    "        \n",
    "        try:\n",
    "            pic = np.mean(pic,axis = 2)\n",
    "        except:\n",
    "            pic = np.array(pic)\n",
    "        \n",
    "        found.append(ii)\n",
    "        # print(pic.shape)\n",
    "        zz[ii,:,:] = pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "551d5303-1fc5-453a-b840-ce8ebde64d24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.57941176, 0.60784314, 0.66372549, ..., 0.66372549,\n",
       "         0.61078431, 0.58039216],\n",
       "        [0.57843137, 0.58039216, 0.59607843, ..., 0.59803922,\n",
       "         0.58137255, 0.57647059],\n",
       "        [0.59411765, 0.55294118, 0.49215686, ..., 0.5       ,\n",
       "         0.55588235, 0.59411765],\n",
       "        ...,\n",
       "        [0.56568627, 0.51764706, 0.44607843, ..., 0.45294118,\n",
       "         0.51960784, 0.56568627],\n",
       "        [0.49411765, 0.47843137, 0.46764706, ..., 0.46960784,\n",
       "         0.47843137, 0.49509804],\n",
       "        [0.45196078, 0.45686275, 0.48235294, ..., 0.48333333,\n",
       "         0.45784314, 0.45196078]],\n",
       "\n",
       "       [[0.98823529, 0.95816993, 0.89281046, ..., 0.89281046,\n",
       "         0.95816993, 0.98823529],\n",
       "        [0.93333333, 0.87843137, 0.77254902, ..., 0.77254902,\n",
       "         0.87712418, 0.93071895],\n",
       "        [0.83921569, 0.78823529, 0.68888889, ..., 0.68627451,\n",
       "         0.78823529, 0.84313725],\n",
       "        ...,\n",
       "        [0.85620915, 0.8       , 0.69150327, ..., 0.68888889,\n",
       "         0.80130719, 0.86013072],\n",
       "        [0.94640523, 0.89150327, 0.78823529, ..., 0.79084967,\n",
       "         0.89019608, 0.94379085],\n",
       "        [0.99477124, 0.9751634 , 0.93333333, ..., 0.93202614,\n",
       "         0.97385621, 0.99477124]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.68137255, 0.68235294, 0.68921569, ..., 0.55392157,\n",
       "         0.54803922, 0.54607843],\n",
       "        [0.68235294, 0.68333333, 0.69019608, ..., 0.55588235,\n",
       "         0.55098039, 0.54803922],\n",
       "        [0.68627451, 0.68823529, 0.69019608, ..., 0.56176471,\n",
       "         0.55686275, 0.55588235],\n",
       "        ...,\n",
       "        [0.71176471, 0.7127451 , 0.71568627, ..., 0.65686275,\n",
       "         0.65294118, 0.65294118],\n",
       "        [0.7127451 , 0.71372549, 0.71764706, ..., 0.66078431,\n",
       "         0.65686275, 0.65588235],\n",
       "        [0.7127451 , 0.71372549, 0.71764706, ..., 0.66176471,\n",
       "         0.65686275, 0.65588235]],\n",
       "\n",
       "       [[0.6       , 0.6       , 0.6       , ..., 0.6       ,\n",
       "         0.6       , 0.6       ],\n",
       "        [0.6       , 0.6       , 0.6       , ..., 0.6       ,\n",
       "         0.6       , 0.6       ],\n",
       "        [0.6       , 0.6       , 0.6       , ..., 0.6       ,\n",
       "         0.6       , 0.6       ],\n",
       "        ...,\n",
       "        [0.6       , 0.6       , 0.6       , ..., 0.6       ,\n",
       "         0.6       , 0.6       ],\n",
       "        [0.6       , 0.6       , 0.6       , ..., 0.6       ,\n",
       "         0.6       , 0.6       ],\n",
       "        [0.6       , 0.6       , 0.6       , ..., 0.6       ,\n",
       "         0.6       , 0.6       ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz = zz/255\n",
    "zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3aecca9f-d3c0-4945-b859-10a95bf2d627",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28,28)),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a4432cc-4eaf-4f5b-ab71-994d2841dadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss= tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d9c1db8-053b-4015-8f4d-2ba0443708d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X.sales</th>\n",
       "      <th>cdate</th>\n",
       "      <th>fee1</th>\n",
       "      <th>fee2</th>\n",
       "      <th>fi1</th>\n",
       "      <th>fi2</th>\n",
       "      <th>fi3</th>\n",
       "      <th>fi4</th>\n",
       "      <th>fi5</th>\n",
       "      <th>fi6</th>\n",
       "      <th>...</th>\n",
       "      <th>FT0000</th>\n",
       "      <th>FT0001</th>\n",
       "      <th>FT0002</th>\n",
       "      <th>FT0003</th>\n",
       "      <th>FT0004</th>\n",
       "      <th>FT0005</th>\n",
       "      <th>FT0006</th>\n",
       "      <th>FT0007</th>\n",
       "      <th>FT0008</th>\n",
       "      <th>FT0009</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18012.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>140.476667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.377778</td>\n",
       "      <td>118.466667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.653869</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.312793</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.0</td>\n",
       "      <td>18561.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>167.661376</td>\n",
       "      <td>3.0</td>\n",
       "      <td>205.847619</td>\n",
       "      <td>156.717460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014289</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.871419</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>18012.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.967856</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.003572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>18012.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.897519</td>\n",
       "      <td>0.077479</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18012.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>174.823704</td>\n",
       "      <td>17.0</td>\n",
       "      <td>127.768889</td>\n",
       "      <td>195.306667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6909</th>\n",
       "      <td>3.0</td>\n",
       "      <td>18593.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.988606</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.001266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6910</th>\n",
       "      <td>2.0</td>\n",
       "      <td>18012.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.971874</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6911</th>\n",
       "      <td>2.0</td>\n",
       "      <td>18024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>169.058333</td>\n",
       "      <td>32.0</td>\n",
       "      <td>47.142857</td>\n",
       "      <td>155.347619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.981631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6912</th>\n",
       "      <td>2.0</td>\n",
       "      <td>18790.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>139.563333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>188.173333</td>\n",
       "      <td>89.848889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005557</td>\n",
       "      <td>0.005558</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.297603</td>\n",
       "      <td>0.292359</td>\n",
       "      <td>0.005557</td>\n",
       "      <td>0.005557</td>\n",
       "      <td>0.371141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6913</th>\n",
       "      <td>4.0</td>\n",
       "      <td>18544.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>93.733333</td>\n",
       "      <td>14.0</td>\n",
       "      <td>39.481159</td>\n",
       "      <td>40.939130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6914 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      X.sales    cdate    fee1    fee2   fi1   fi2         fi3   fi4  \\\n",
       "0         1.0  18012.0   250.0   500.0  15.0  15.0  140.476667   1.0   \n",
       "1        42.0  18561.0   250.0   500.0  21.0  15.0  167.661376   3.0   \n",
       "2         3.0  18012.0   750.0  1000.0   0.0   0.0    0.000000   0.0   \n",
       "3         4.0  18012.0   750.0  1000.0   0.0   0.0    0.000000   0.0   \n",
       "4         1.0  18012.0   300.0   550.0  15.0  15.0  174.823704  17.0   \n",
       "...       ...      ...     ...     ...   ...   ...         ...   ...   \n",
       "6909      3.0  18593.0   750.0  1000.0   0.0   0.0    0.000000   0.0   \n",
       "6910      2.0  18012.0   750.0  1000.0   0.0   0.0    0.000000   0.0   \n",
       "6911      2.0  18024.0     0.0   250.0  14.0  15.0  169.058333  32.0   \n",
       "6912      2.0  18790.0   200.0   450.0  15.0  15.0  139.563333   0.0   \n",
       "6913      4.0  18544.0  1000.0  1250.0  23.0  15.0   93.733333  14.0   \n",
       "\n",
       "             fi5         fi6  ...    FT0000    FT0001    FT0002    FT0003  \\\n",
       "0      77.377778  118.466667  ...  0.004168  0.004167  0.653869  0.004167   \n",
       "1     205.847619  156.717460  ...  0.014289  0.014286  0.871419  0.014286   \n",
       "2       0.000000    0.000000  ...  0.003572  0.003572  0.003572  0.967856   \n",
       "3       0.000000    0.000000  ...  0.003126  0.003125  0.003125  0.003125   \n",
       "4     127.768889  195.306667  ...  0.050000  0.050000  0.050000  0.050000   \n",
       "...          ...         ...  ...       ...       ...       ...       ...   \n",
       "6909    0.000000    0.000000  ...  0.001266  0.001266  0.001266  0.001266   \n",
       "6910    0.000000    0.000000  ...  0.003125  0.003125  0.003125  0.971874   \n",
       "6911   47.142857  155.347619  ...  0.002041  0.002041  0.002041  0.002041   \n",
       "6912  188.173333   89.848889  ...  0.005556  0.005556  0.005557  0.005558   \n",
       "6913   39.481159   40.939130  ...  0.050000  0.050000  0.050000  0.050000   \n",
       "\n",
       "        FT0004    FT0005    FT0006    FT0007    FT0008    FT0009  \n",
       "0     0.312793  0.004167  0.004167  0.004167  0.004167  0.004167  \n",
       "1     0.014286  0.014288  0.014286  0.014287  0.014286  0.014286  \n",
       "2     0.003572  0.003572  0.003572  0.003572  0.003572  0.003572  \n",
       "3     0.003125  0.897519  0.077479  0.003125  0.003125  0.003125  \n",
       "4     0.050000  0.050000  0.050000  0.050000  0.550000  0.050000  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "6909  0.001266  0.001266  0.001266  0.988606  0.001266  0.001266  \n",
       "6910  0.003125  0.003125  0.003125  0.003125  0.003125  0.003125  \n",
       "6911  0.002041  0.002041  0.002041  0.002041  0.002041  0.981631  \n",
       "6912  0.005556  0.297603  0.292359  0.005557  0.005557  0.371141  \n",
       "6913  0.050000  0.050000  0.050000  0.050000  0.550000  0.050000  \n",
       "\n",
       "[6914 rows x 21 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr6 = pd.read_csv('data/Xtr6.csv')\n",
    "Xte6 = pd.read_csv('data/Xte6.csv')\n",
    "Xtr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4efa1920-7499-43a7-b322-bbcbbc31dad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "217/217 [==============================] - 0s 701us/step - loss: 2.3122 - accuracy: 0.1251\n",
      "Epoch 2/10\n",
      "217/217 [==============================] - 0s 771us/step - loss: 2.2767 - accuracy: 0.1406\n",
      "Epoch 3/10\n",
      "217/217 [==============================] - 0s 711us/step - loss: 2.2640 - accuracy: 0.1374\n",
      "Epoch 4/10\n",
      "217/217 [==============================] - 0s 713us/step - loss: 2.2562 - accuracy: 0.1439\n",
      "Epoch 5/10\n",
      "217/217 [==============================] - 0s 759us/step - loss: 2.2476 - accuracy: 0.1478\n",
      "Epoch 6/10\n",
      "217/217 [==============================] - 0s 759us/step - loss: 2.2358 - accuracy: 0.1520\n",
      "Epoch 7/10\n",
      "217/217 [==============================] - 0s 731us/step - loss: 2.2267 - accuracy: 0.1584\n",
      "Epoch 8/10\n",
      "217/217 [==============================] - 0s 736us/step - loss: 2.2209 - accuracy: 0.1587\n",
      "Epoch 9/10\n",
      "217/217 [==============================] - 0s 762us/step - loss: 2.2102 - accuracy: 0.1617\n",
      "Epoch 10/10\n",
      "217/217 [==============================] - 0s 789us/step - loss: 2.2025 - accuracy: 0.1629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2233eabdd00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(zz, yy, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9427d8b4-c73e-4448-b8f0-e78a91c23632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 6914\n",
      "100 / 6914\n",
      "200 / 6914\n",
      "300 / 6914\n",
      "400 / 6914\n",
      "500 / 6914\n",
      "600 / 6914\n",
      "700 / 6914\n",
      "800 / 6914\n",
      "900 / 6914\n",
      "1000 / 6914\n",
      "1100 / 6914\n",
      "1200 / 6914\n",
      "1300 / 6914\n",
      "1400 / 6914\n",
      "1500 / 6914\n",
      "1600 / 6914\n",
      "1700 / 6914\n",
      "1800 / 6914\n",
      "1900 / 6914\n",
      "2000 / 6914\n",
      "2100 / 6914\n",
      "2200 / 6914\n",
      "2300 / 6914\n",
      "2400 / 6914\n",
      "2500 / 6914\n",
      "2600 / 6914\n",
      "2700 / 6914\n",
      "2800 / 6914\n",
      "2900 / 6914\n",
      "3000 / 6914\n",
      "3100 / 6914\n",
      "3200 / 6914\n",
      "3300 / 6914\n",
      "3400 / 6914\n",
      "3500 / 6914\n",
      "3600 / 6914\n",
      "3700 / 6914\n",
      "3800 / 6914\n",
      "3900 / 6914\n",
      "4000 / 6914\n",
      "4100 / 6914\n",
      "4200 / 6914\n",
      "4300 / 6914\n",
      "4400 / 6914\n",
      "4500 / 6914\n",
      "4600 / 6914\n",
      "4700 / 6914\n",
      "4800 / 6914\n",
      "4900 / 6914\n",
      "5000 / 6914\n",
      "5100 / 6914\n",
      "5200 / 6914\n",
      "5300 / 6914\n",
      "5400 / 6914\n",
      "5500 / 6914\n",
      "5600 / 6914\n",
      "5700 / 6914\n",
      "5800 / 6914\n",
      "5900 / 6914\n",
      "6000 / 6914\n",
      "6100 / 6914\n",
      "6200 / 6914\n",
      "6300 / 6914\n",
      "6400 / 6914\n",
      "6500 / 6914\n",
      "6600 / 6914\n",
      "6700 / 6914\n",
      "6800 / 6914\n",
      "6900 / 6914\n"
     ]
    }
   ],
   "source": [
    "zzte = np.zeros([tr.shape[0],28,28])\n",
    "found = list()\n",
    "for ii in range(te.shape[0]):\n",
    "    if ii % 100 == 0:\n",
    "        print('%d / %d' % (ii, te.shape[0]))\n",
    "    if te['ext'][ii] == '.png':\n",
    "        id = te.loc[ii,'id']\n",
    "        ff = te.loc[ii, 'id'] + te.loc[ii, 'ext']\n",
    "        path = 'data/images/images/' + ff\n",
    "        if not os.path.isfile(path):\n",
    "            continue\n",
    "        \n",
    "        pic = imageio.imread(path)\n",
    "        pic = Image.fromarray(pic).resize((28,28))\n",
    "        \n",
    "        try:\n",
    "            pic = np.mean(pic,axis = 2)\n",
    "        except:\n",
    "            pic = np.array(pic)\n",
    "        \n",
    "        found.append(ii)\n",
    "        # print(pic.shape)\n",
    "        zzte[ii,:,:] = pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6547a94b-f472-4bd8-8d13-c45680eb49b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "zzte = zzte/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8d147df5-9a98-47df-82aa-c71063585b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred = pd.read_csv('data/pred.csv')\n",
    "predrf = pred.copy()\n",
    "predrf['total'] = model.predict(zzte)\n",
    "#predrf.to_csv('data/pred_image_dnn.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "776c467a-0a7e-4c35-898a-c049ad67ad3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7e79f1a9cb10504dd2fc569d84f2a346</td>\n",
       "      <td>-1.870343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4a2f52a31466509462042dacd3d66de7</td>\n",
       "      <td>0.166571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f22f6ec19360a7bcc7e0f6c76912c88b</td>\n",
       "      <td>-0.037065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6382e9933644b1751511264ec8194ef5</td>\n",
       "      <td>-0.037065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>638c2f2961777b10009d7fdebae561bc</td>\n",
       "      <td>0.586136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6909</th>\n",
       "      <td>62eb6ce056e943070967d8835a204551</td>\n",
       "      <td>-2.648161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6910</th>\n",
       "      <td>6a5a9ef25ea4889cef2b14a272ba958c</td>\n",
       "      <td>2.291949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6911</th>\n",
       "      <td>6c8edfdb7aec834d73e4b8d36ec0736d</td>\n",
       "      <td>-0.037066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6912</th>\n",
       "      <td>c4618bb91765903dad4451933ee396ea</td>\n",
       "      <td>0.003993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6913</th>\n",
       "      <td>3b665129694904b2024dc7cd8230babe</td>\n",
       "      <td>-0.037066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6914 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id     total\n",
       "0     7e79f1a9cb10504dd2fc569d84f2a346 -1.870343\n",
       "1     4a2f52a31466509462042dacd3d66de7  0.166571\n",
       "2     f22f6ec19360a7bcc7e0f6c76912c88b -0.037065\n",
       "3     6382e9933644b1751511264ec8194ef5 -0.037065\n",
       "4     638c2f2961777b10009d7fdebae561bc  0.586136\n",
       "...                                ...       ...\n",
       "6909  62eb6ce056e943070967d8835a204551 -2.648161\n",
       "6910  6a5a9ef25ea4889cef2b14a272ba958c  2.291949\n",
       "6911  6c8edfdb7aec834d73e4b8d36ec0736d -0.037066\n",
       "6912  c4618bb91765903dad4451933ee396ea  0.003993\n",
       "6913  3b665129694904b2024dc7cd8230babe -0.037066\n",
       "\n",
       "[6914 rows x 2 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74c7644d-6b81-421c-b513-6f12ccf82a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qq = np.quantile(tr['total'], q = np.array(range(1,11))/11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0506b397-2308-4de4-b726-2318e7c16922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.007     , 0.015     , 0.03007238, 0.05766364, 0.1       ,\n",
       "       0.15      , 0.25      , 0.39      , 0.76035361, 2.        ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c00b6b0b-b52f-4ff5-a416-9b88cb0834b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp(dim, regress = False):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(8, input_dim = dim, activation = \"relu\"))\n",
    "    model.add(tf.keras.layers.Dense(8, activation = \"relu\"))\n",
    "    \n",
    "    if regress:\n",
    "        model.add(tf.keras.layers.Dense(1,activation = \"linear\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99aae72-0c36-4a7d-8ab6-08c03048f971",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "9387530d-061f-454d-9aae-7ecd7c69c901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(width, height, filters = (16,32,64), regress = False):\n",
    "    inputShape = (height, width)\n",
    "    # chanDim = -1\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=inputShape)\n",
    "    \n",
    "    for (i,f) in enumerate(filters):\n",
    "        \n",
    "        if i==0:\n",
    "            x = inputs\n",
    "        \n",
    "        x = tf.keras.layers.Conv2D(f,(3,3) ,input_shape = inputShape,padding = \"same\")\n",
    "        x = tf.keras.layers.Activation(\"relu\")\n",
    "        x = tf.keras.layers.BatchNormalization(axis = 1)\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size = (2,2))\n",
    "    # flatten the volume, then FC => RELU => BN => DROPOUT\n",
    "    x = tf.keras.layers.Flatten()\n",
    "    x = tf.keras.layers.Dense(16)\n",
    "    x = tf.keras.layers.Activation(\"relu\")\n",
    "    x = tf.keras.layers.BatchNormalization(axis=1)\n",
    "    x = tf.keras.layers.Dropout(0.5)\n",
    "    # apply another FC layer, this one to match the number of nodes\n",
    "    # coming out of the MLP\n",
    "    x = tf.keras.layers.Dense(4)\n",
    "    x = tf.keras.layers.Activation(\"relu\")\n",
    "    # check to see if the regression node should be added\n",
    "    if regress:\n",
    "        x = tf.keras.layers.Dense(1, activation=\"linear\")\n",
    "        # construct the CNN\n",
    "    model = tf.keras.Model(height,width, x)\n",
    "    # return the CNN\n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5dde9959-0d12-4740-9862-e1651417b679",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputShape = (28,28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "4a73f840-38b6-4023-a4cf-bb3128a199d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(width = 28, height = 28, regress = True):\n",
    "    inputShape = (height,width)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters = 64,kernel_size = 7 ,activation = 'relu',input_shape = (28,28),padding = \"same\")\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size = 2)\n",
    "    x = tf.keras.layers.Conv2D(filters = 128,kernel_size = 3 ,activation = 'relu',padding = \"same\")\n",
    "    x = tf.keras.layers.Conv2D(filters = 128,kernel_size = 3 ,activation = 'relu',padding = \"same\")\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size = 2)\n",
    "    x = tf.keras.layers.Conv2D(filters = 256,kernel_size = 3 ,activation = 'relu',padding = \"same\")\n",
    "    x = tf.keras.layers.Conv2D(filters = 256,kernel_size = 3 ,activation = 'relu',padding = \"same\")\n",
    "    x = tf.keras.layers.MaxPooling2D(pool_size = 2)\n",
    "    # flatten the volume, then FC => RELU => BN => DROPOUT\n",
    "    x = tf.keras.layers.Flatten()\n",
    "    x = tf.keras.layers.Dense(128, activation = 'relu')\n",
    "    x = tf.keras.layers.Dropout(0.5)\n",
    "    x = tf.keras.layers.Dense(64, activation = 'relu')\n",
    "    x = tf.keras.layers.Dropout(0.5)\n",
    "    # apply another FC layer, this one to match the number of nodes\n",
    "    # coming out of the MLP\n",
    "    x = tf.keras.layers.Dense(10, activation = 'softmax')\n",
    "    if regress:\n",
    "        x = tf.keras.layers.Dense(1, activation=\"linear\")\n",
    "    model = tf.keras.Model(height,width, x)\n",
    "    # return the CNN\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "6aa29929-0b9b-4a49-93da-a1cc2f84ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(width = 28, height = 28, regress = False):\n",
    "    inputShape = (height,width)\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(filters = 64,kernel_size = 7 ,activation = 'relu',input_shape = (28,28,1),padding = \"same\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size = 2))\n",
    "    model.add(tf.keras.layers.Conv2D(filters = 128,kernel_size = 3 ,activation = 'relu',padding = \"same\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size = 2))\n",
    "    model.add(tf.keras.layers.Conv2D(filters = 256,kernel_size = 3 ,activation = 'relu',padding = \"same\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size = 2))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128, activation = 'relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(64, activation = 'relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(10, activation = 'softmax'))\n",
    "    if regress:\n",
    "        model.add(tf.keras.layers.Dense(1, activation=\"linear\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55afb0e4-ec45-40a9-89cb-dd29a910e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(width = 28, height = 28, regress = False):\n",
    "    inputShape = (height,width)\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(filters = 64,kernel_size = 7 ,activation = 'relu',input_shape = (28,28,1),padding = \"same\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size = 2))\n",
    "    model.add(tf.keras.layers.Conv2D(filters = 128,kernel_size = 3 ,activation = 'relu',padding = \"same\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size = 2))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(64, activation = 'relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(10, activation = 'softmax'))\n",
    "    if regress:\n",
    "        model.add(tf.keras.layers.Dense(1, activation=\"linear\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "9f1efe9e-88d3-4b32-9754-521602358cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr6 = pd.read_csv('data/Xtr6.csv')\n",
    "Xte6 = pd.read_csv('data/Xte6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "530318a4-d10a-4d20-8f6a-814a7a6fe43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.000046\n",
       "1       0.062762\n",
       "2       0.000132\n",
       "3       0.001665\n",
       "4       0.000837\n",
       "          ...   \n",
       "6909    0.000460\n",
       "6910    0.000084\n",
       "6911    0.000808\n",
       "6912    0.000142\n",
       "6913    0.000084\n",
       "Name: total, Length: 6914, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = tr['total']/max(tr['total'])\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0419edb-f6df-477c-8f59-3ec32be3560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "Xtr6 = scaler.fit_transform(Xtr6)\n",
    "Xte6 = scaler.transform(Xte6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "0990f4ff-03ca-4e95-bd38-9261b39c1027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X.sales</th>\n",
       "      <th>cdate</th>\n",
       "      <th>fee1</th>\n",
       "      <th>fee2</th>\n",
       "      <th>fi1</th>\n",
       "      <th>fi2</th>\n",
       "      <th>fi3</th>\n",
       "      <th>fi4</th>\n",
       "      <th>fi5</th>\n",
       "      <th>fi6</th>\n",
       "      <th>...</th>\n",
       "      <th>FT0000</th>\n",
       "      <th>FT0001</th>\n",
       "      <th>FT0002</th>\n",
       "      <th>FT0003</th>\n",
       "      <th>FT0004</th>\n",
       "      <th>FT0005</th>\n",
       "      <th>FT0006</th>\n",
       "      <th>FT0007</th>\n",
       "      <th>FT0008</th>\n",
       "      <th>FT0009</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18012.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>140.476667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.377778</td>\n",
       "      <td>118.466667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.653869</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.312793</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42.0</td>\n",
       "      <td>18561.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>167.661376</td>\n",
       "      <td>3.0</td>\n",
       "      <td>205.847619</td>\n",
       "      <td>156.717460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014289</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.871419</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014287</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>18012.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.967856</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.003572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>18012.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.897519</td>\n",
       "      <td>0.077479</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18012.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>174.823704</td>\n",
       "      <td>17.0</td>\n",
       "      <td>127.768889</td>\n",
       "      <td>195.306667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6909</th>\n",
       "      <td>3.0</td>\n",
       "      <td>18593.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.988606</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.001266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6910</th>\n",
       "      <td>2.0</td>\n",
       "      <td>18012.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.971874</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.003125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6911</th>\n",
       "      <td>2.0</td>\n",
       "      <td>18024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>169.058333</td>\n",
       "      <td>32.0</td>\n",
       "      <td>47.142857</td>\n",
       "      <td>155.347619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.981631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6912</th>\n",
       "      <td>2.0</td>\n",
       "      <td>18790.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>139.563333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>188.173333</td>\n",
       "      <td>89.848889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005557</td>\n",
       "      <td>0.005558</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.297603</td>\n",
       "      <td>0.292359</td>\n",
       "      <td>0.005557</td>\n",
       "      <td>0.005557</td>\n",
       "      <td>0.371141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6913</th>\n",
       "      <td>4.0</td>\n",
       "      <td>18544.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>93.733333</td>\n",
       "      <td>14.0</td>\n",
       "      <td>39.481159</td>\n",
       "      <td>40.939130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6914 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      X.sales    cdate    fee1    fee2   fi1   fi2         fi3   fi4  \\\n",
       "0         1.0  18012.0   250.0   500.0  15.0  15.0  140.476667   1.0   \n",
       "1        42.0  18561.0   250.0   500.0  21.0  15.0  167.661376   3.0   \n",
       "2         3.0  18012.0   750.0  1000.0   0.0   0.0    0.000000   0.0   \n",
       "3         4.0  18012.0   750.0  1000.0   0.0   0.0    0.000000   0.0   \n",
       "4         1.0  18012.0   300.0   550.0  15.0  15.0  174.823704  17.0   \n",
       "...       ...      ...     ...     ...   ...   ...         ...   ...   \n",
       "6909      3.0  18593.0   750.0  1000.0   0.0   0.0    0.000000   0.0   \n",
       "6910      2.0  18012.0   750.0  1000.0   0.0   0.0    0.000000   0.0   \n",
       "6911      2.0  18024.0     0.0   250.0  14.0  15.0  169.058333  32.0   \n",
       "6912      2.0  18790.0   200.0   450.0  15.0  15.0  139.563333   0.0   \n",
       "6913      4.0  18544.0  1000.0  1250.0  23.0  15.0   93.733333  14.0   \n",
       "\n",
       "             fi5         fi6  ...    FT0000    FT0001    FT0002    FT0003  \\\n",
       "0      77.377778  118.466667  ...  0.004168  0.004167  0.653869  0.004167   \n",
       "1     205.847619  156.717460  ...  0.014289  0.014286  0.871419  0.014286   \n",
       "2       0.000000    0.000000  ...  0.003572  0.003572  0.003572  0.967856   \n",
       "3       0.000000    0.000000  ...  0.003126  0.003125  0.003125  0.003125   \n",
       "4     127.768889  195.306667  ...  0.050000  0.050000  0.050000  0.050000   \n",
       "...          ...         ...  ...       ...       ...       ...       ...   \n",
       "6909    0.000000    0.000000  ...  0.001266  0.001266  0.001266  0.001266   \n",
       "6910    0.000000    0.000000  ...  0.003125  0.003125  0.003125  0.971874   \n",
       "6911   47.142857  155.347619  ...  0.002041  0.002041  0.002041  0.002041   \n",
       "6912  188.173333   89.848889  ...  0.005556  0.005556  0.005557  0.005558   \n",
       "6913   39.481159   40.939130  ...  0.050000  0.050000  0.050000  0.050000   \n",
       "\n",
       "        FT0004    FT0005    FT0006    FT0007    FT0008    FT0009  \n",
       "0     0.312793  0.004167  0.004167  0.004167  0.004167  0.004167  \n",
       "1     0.014286  0.014288  0.014286  0.014287  0.014286  0.014286  \n",
       "2     0.003572  0.003572  0.003572  0.003572  0.003572  0.003572  \n",
       "3     0.003125  0.897519  0.077479  0.003125  0.003125  0.003125  \n",
       "4     0.050000  0.050000  0.050000  0.050000  0.550000  0.050000  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "6909  0.001266  0.001266  0.001266  0.988606  0.001266  0.001266  \n",
       "6910  0.003125  0.003125  0.003125  0.003125  0.003125  0.003125  \n",
       "6911  0.002041  0.002041  0.002041  0.002041  0.002041  0.981631  \n",
       "6912  0.005556  0.297603  0.292359  0.005557  0.005557  0.371141  \n",
       "6913  0.050000  0.050000  0.050000  0.050000  0.550000  0.050000  \n",
       "\n",
       "[6914 rows x 21 columns]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b082fb87-f886-4c27-b743-4241e040f560",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = create_mlp(Xtr6.shape[1], regress = False)\n",
    "#mlp = create_mlp(Xtr6.shape[1], regress = True)\n",
    "#opt = tf.keras.optimizers.Adam(learning_rate = 1e-3, decay = 1e-3/200)\n",
    "#mlp.compile(loss = \"mean_absolute_percentage_error\", optimizer = opt)\n",
    "#mlp.fit(x = Xtr6, y = Y, epochs = 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "8a9154bc-cb64-4856-b50c-5b983fd88ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00047509],\n",
       "       [ 0.00401763],\n",
       "       [ 0.00589722],\n",
       "       ...,\n",
       "       [-0.07609022],\n",
       "       [ 0.00385919],\n",
       "       [ 0.04010284]], dtype=float32)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p123= mlp.predict(Xte6)\n",
    "p123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "8b4c6683-eed0-4b6f-8f68-0b5198d7fd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.read_csv('data/pred.csv')\n",
    "predrf = pred.copy()\n",
    "predrf['total'] = mlp.predict(Xte6)\n",
    "predrf.to_csv('data/pred_mlp.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "349c6680-0622-40ea-857c-bc1bf735d09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = create_cnn(28,28,regress = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "7dbc2fa9-3a44-4b3e-b77b-6e4cf4a96644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06526939, -0.68779798, -0.23415346, ..., -0.39019883,\n",
       "         3.85719818, -0.31531257],\n",
       "       [-0.07386261, -0.77805771, -0.5305535 , ..., -0.18847481,\n",
       "         2.05947801, -0.10135478],\n",
       "       [ 0.02066274,  0.07121392, -1.2715536 , ...,  0.95491755,\n",
       "        -0.40249514, -0.31354228],\n",
       "       ...,\n",
       "       [-0.07386261, -0.77805773,  0.9514467 , ..., -0.40324898,\n",
       "        -0.41708366, -0.32916449],\n",
       "       [-0.07386261, -0.77805729, -0.5305535 , ..., -0.40235275,\n",
       "        -0.41619622,  2.01851713],\n",
       "       [-0.06526939, -0.77805773,  0.9514467 , ..., -0.40077064,\n",
       "        -0.4146296 , -0.32653573]])"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xte6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e7895d8-152f-403f-ba14-3234b8acaf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedInput = tf.keras.layers.concatenate([mlp.output,cnn.output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dee890d6-d7e1-43e3-a4cf-acf98ba37c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combinedInput = tf.keras.layers.concatenate([mlp.output,cnn.output])\n",
    "\n",
    "x = tf.keras.layers.Dense(4, activation=\"relu\")(combinedInput)\n",
    "x = tf.keras.layers.Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "# our final model will accept categorical/numerical data on the MLP\n",
    "# input and images on the CNN input, outputting a single value (the\n",
    "# predicted price of the house)\n",
    "model = tf.keras.Model(inputs=[mlp.input, cnn.input], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce263206-8a14-4ded-8bf8-48b8da53e075",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-1, decay=1e-1 / 100)\n",
    "model.compile(loss=\"mean_absolute_error\", optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ed10115-9c8a-4cf3-90eb-bfd7f45afe88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model...\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 3s 27ms/step - loss: 0.0250\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0198\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.0202\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 3s 27ms/step - loss: 0.0161\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.0162: 0s - loss: 0 - ETA: 0s - loss: 0\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0136\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.0141\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.0141\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0152\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.0132\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0127\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0109\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 3s 26ms/step - loss: 0.0111\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 2s 23ms/step - loss: 0.0107\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 3s 26ms/step - loss: 0.0116: 2s \n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0127\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.0109\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 3s 26ms/step - loss: 0.0107\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.0109\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0110\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.0117\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 2s 23ms/step - loss: 0.0116\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0102\n",
      "Epoch 24/50\n",
      "109/109 [==============================] - 2s 22ms/step - loss: 0.0108\n",
      "Epoch 25/50\n",
      "109/109 [==============================] - 3s 26ms/step - loss: 0.0104 \n",
      "Epoch 26/50\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.0106\n",
      "Epoch 27/50\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.0102\n",
      "Epoch 28/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0099\n",
      "Epoch 29/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0099\n",
      "Epoch 30/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0110\n",
      "Epoch 31/50\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.0105\n",
      "Epoch 32/50\n",
      "109/109 [==============================] - 3s 23ms/step - loss: 0.0098\n",
      "Epoch 33/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0103\n",
      "Epoch 34/50\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.0102\n",
      "Epoch 35/50\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.0102\n",
      "Epoch 36/50\n",
      "109/109 [==============================] - 3s 26ms/step - loss: 0.0113\n",
      "Epoch 37/50\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.0099\n",
      "Epoch 38/50\n",
      "109/109 [==============================] - 2s 23ms/step - loss: 0.0095\n",
      "Epoch 39/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0098\n",
      "Epoch 40/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0094\n",
      "Epoch 41/50\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.0097\n",
      "Epoch 42/50\n",
      "109/109 [==============================] - 3s 26ms/step - loss: 0.0098\n",
      "Epoch 43/50\n",
      "109/109 [==============================] - 3s 28ms/step - loss: 0.0101\n",
      "Epoch 44/50\n",
      "109/109 [==============================] - 3s 27ms/step - loss: 0.0102\n",
      "Epoch 45/50\n",
      "109/109 [==============================] - 3s 27ms/step - loss: 0.0098\n",
      "Epoch 46/50\n",
      "109/109 [==============================] - 3s 28ms/step - loss: 0.0095\n",
      "Epoch 47/50\n",
      "109/109 [==============================] - 3s 28ms/step - loss: 0.0092\n",
      "Epoch 48/50\n",
      "109/109 [==============================] - 3s 29ms/step - loss: 0.0092: 0s - loss: 0\n",
      "Epoch 49/50\n",
      "109/109 [==============================] - 3s 28ms/step - loss: 0.0095: \n",
      "Epoch 50/50\n",
      "109/109 [==============================] - 3s 27ms/step - loss: 0.0089\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training model...\")\n",
    "history = model.fit(x=[Xtr6, zz], y=Y,epochs=50, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9238710d-ee47-4d4f-9ecd-3cbf43b9d181",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldatr = pd.read_csv('data/Xtr_lda.csv')\n",
    "ldate = pd.read_csv('data/Xte_lda.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de63456b-b117-47cb-a01d-275f1a4f1d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training model...\n",
      "Epoch 1/10\n",
      "865/865 [==============================] - 29s 34ms/step - loss: 0.0094\n",
      "Epoch 2/10\n",
      "865/865 [==============================] - 29s 34ms/step - loss: 0.0090\n",
      "Epoch 3/10\n",
      "865/865 [==============================] - 30s 35ms/step - loss: 0.0089\n",
      "Epoch 4/10\n",
      "865/865 [==============================] - 32s 37ms/step - loss: 0.0090\n",
      "Epoch 5/10\n",
      "865/865 [==============================] - 32s 37ms/step - loss: 0.0089\n",
      "Epoch 6/10\n",
      "865/865 [==============================] - 32s 37ms/step - loss: 0.0087\n",
      "Epoch 7/10\n",
      "865/865 [==============================] - 32s 38ms/step - loss: 0.0087\n",
      "Epoch 8/10\n",
      "865/865 [==============================] - 32s 37ms/step - loss: 0.0087\n",
      "Epoch 9/10\n",
      "865/865 [==============================] - 30s 35ms/step - loss: 0.0085\n",
      "Epoch 10/10\n",
      "865/865 [==============================] - 29s 34ms/step - loss: 0.0085\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training model...\")\n",
    "history = model.fit(x=[ldatr, zz], y=Y,epochs=10, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "bcc8d598-6b44-484b-81ff-b185677d7079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0019289776"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predlda = model.predict([ldate,zzte])\n",
    "np.median(predlda)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "f4df1ec1-d1cb-40ef-8123-2ec7430fcac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.read_csv('data/pred.csv')\n",
    "predrf = pred.copy()\n",
    "predrf['total'] = model.predict([ldate,zzte])\n",
    "predrf.to_csv('data/pred_mlpcnnlda.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "8463007e-ec25-4a90-a1f5-cdb375cf9254",
   "metadata": {},
   "outputs": [],
   "source": [
    "predsss = model.predict([Xte6,zzte])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "4c5f7f4a-0d64-4586-a42d-e506a9e0ef02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00360027],\n",
       "       [0.00360027],\n",
       "       [0.00360027],\n",
       "       ...,\n",
       "       [0.00360027],\n",
       "       [0.00360027],\n",
       "       [0.00360027]], dtype=float32)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predsss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "df3b64cf-ae3e-46ee-97d7-87cb6a273bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.000046\n",
       "1       0.062762\n",
       "2       0.000132\n",
       "3       0.001665\n",
       "4       0.000837\n",
       "          ...   \n",
       "6909    0.000460\n",
       "6910    0.000084\n",
       "6911    0.000808\n",
       "6912    0.000142\n",
       "6913    0.000084\n",
       "Name: total, Length: 6914, dtype: float64"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "d1051969-41b1-400b-8b54-05a3ae1ba1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.60251046e-05],\n",
       "       [6.27615063e-02],\n",
       "       [1.32217573e-04],\n",
       "       ...,\n",
       "       [8.08368201e-04],\n",
       "       [1.42259414e-04],\n",
       "       [8.36820084e-05]])"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled = np.array(tr['total']).reshape(-1,1)\n",
    "scaled = scaler.fit_transform(scaled)\n",
    "scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "e536b957-937c-44f6-85f8-1f706418a58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benson\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\arraylike.py:364: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "C:\\Users\\Benson\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\lib\\function_base.py:2536: RuntimeWarning: invalid value encountered in subtract\n",
      "  X -= avg[:, None]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "proby = scaled\n",
    "stats.probplot(proby, plot = plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca4cf968-9e32-4058-9502-b3ffae9eac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "Xtr2 = pd.read_csv('data/Xtr6.csv')\n",
    "Xte2 = pd.read_csv('data/Xte6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "0a2e44e1-ceb2-4fac-967a-2cd3e0c08085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corrmat = Xtr2.corr()\n",
    "#plt.subplots(figsize(12,9))\n",
    "sns.heatmap(corrmat, vmax = 0.9, square = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "40977933-6af3-4723-a9c2-af768f2a9abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros(shape = 5,dtype = int)\n",
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9bd03719-d489-424e-96b9-6e6cd5dd843c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benson\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.638e+06, tolerance: 2.619e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Benson\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.914e+06, tolerance: 3.143e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Benson\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.667e+06, tolerance: 3.139e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Benson\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.077e+07, tolerance: 3.154e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Benson\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.667e+06, tolerance: 3.023e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Benson\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.995e+06, tolerance: 2.619e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso:  18.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Benson\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.590e+06, tolerance: 3.143e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Benson\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.294e+06, tolerance: 3.139e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Benson\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.206e+07, tolerance: 3.154e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Benson\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.876e+06, tolerance: 3.023e+03\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENet:  18.4\n",
      "KRR:  19.8\n",
      "GBoost:  8.4\n",
      "[13:38:11] WARNING: D:\\bld\\xgboost-split_1634712635879\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:38:13] WARNING: D:\\bld\\xgboost-split_1634712635879\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:38:15] WARNING: D:\\bld\\xgboost-split_1634712635879\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:38:18] WARNING: D:\\bld\\xgboost-split_1634712635879\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[13:38:20] WARNING: D:\\bld\\xgboost-split_1634712635879\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "XGB:  17.2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2319, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2319\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=11, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=11\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "LGB:  15.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xtr2,tr['total'], test_size = 0.1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#Validation function\n",
    "n_folds = 5\n",
    "\n",
    "X = scaler.fit_transform(Xtr2)\n",
    "y = tr['total']\n",
    "\n",
    "def mae_out(model):\n",
    "    kfold = KFold(n_splits = 5,shuffle = True, random_state = 1)\n",
    "    a = np.zeros(shape = 5,dtype = int)\n",
    "    i = 0\n",
    "    for train_index, test_index in kfold.split(Xtr2):\n",
    "        X_train,X_test = X[train_index],X[test_index]\n",
    "        y_train,y_test = y[train_index],y[test_index]\n",
    "        model.fit(X_train,y_train)\n",
    "        mae= mean_absolute_error(y_test,model.predict(X_test))\n",
    "        a[i] = mae\n",
    "        i = i+1\n",
    "    return(np.mean(a))\n",
    "\n",
    "\n",
    "\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha = 0.0005, random_state = 1))\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.05, n_estimators=720,\n",
    "                              max_bin = 55, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "\n",
    "print('lasso: ',mae_out(lasso))\n",
    "print('ENet: ',mae_out(ENet))\n",
    "print('KRR: ',mae_out(KRR))\n",
    "print('GBoost: ',mae_out(GBoost))\n",
    "print('XGB: ',mae_out(model_xgb))\n",
    "print('LGB: ',mae_out(model_lgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "98beeccb-b868-4f19-9a66-1aef81be9131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBoost:  12.34641072248929\n"
     ]
    }
   ],
   "source": [
    "def mae_tr(model):\n",
    "    model.fit(Xtr2,tr['total'])\n",
    "    mae= mean_absolute_error(tr['total'],model.predict(Xtr2))\n",
    "    return(mae)\n",
    "\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='absolute_error', random_state =5)\n",
    "\n",
    "print('GBoost: ',mae_out(GBoost))\n",
    "\n",
    "bestmae = mae_out(GBoost)\n",
    "for lr in range()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "b38fe4eb-abeb-4f54-9bcd-1b78caddb9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  1.25  mae:  11.32481931403809\n"
     ]
    }
   ],
   "source": [
    "lrlist = np.array([0.05,0.25,0.5,0.75,1,1.25,1.5,1.75,2])\n",
    "bestlr = 0.05\n",
    "for lr in np.nditer(lrlist):\n",
    "    GBoost = GradientBoostingRegressor(n_estimators=500, learning_rate=lr,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=35, \n",
    "                                   loss='absolute_error', random_state =5)\n",
    "    if lr==0.05:\n",
    "        bestmae = mae_out(GBoost)\n",
    "    elif bestmae>mae_out(GBoost):\n",
    "        bestlr = lr\n",
    "        bestmae = mae_out(GBoost)\n",
    "\n",
    "print('lr: ',bestlr, ' mae: ',bestmae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "8055e010-f959-4289-bf14-961f36a15b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nest:  500  mae:  11.32481931403809\n"
     ]
    }
   ],
   "source": [
    "nest = np.array([50,100,150,200,250,300,350,400,500,750,1000,1500,2000,3000,4000])\n",
    "bestnest = 50\n",
    "for n in np.nditer(nest):\n",
    "    GBoost = GradientBoostingRegressor(n_estimators=n, learning_rate=bestlr,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=35, \n",
    "                                   loss='absolute_error', random_state =5)\n",
    "    if n == 50:\n",
    "        bestmae = mae_out(GBoost)\n",
    "    elif bestmae>mae_out(GBoost):\n",
    "        bestnest = n\n",
    "        bestmae = mae_out(GBoost)\n",
    "\n",
    "print('nest: ',bestnest, ' mae: ',bestmae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "fe3d6959-c54c-4ed1-93f6-c83b06e93256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.985500</td>\n",
       "      <td>0.013338</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>2.000585e-04</td>\n",
       "      <td>100</td>\n",
       "      <td>{'n_estimators': 100}</td>\n",
       "      <td>0.009657</td>\n",
       "      <td>0.053700</td>\n",
       "      <td>0.017099</td>\n",
       "      <td>0.037795</td>\n",
       "      <td>0.013679</td>\n",
       "      <td>0.026386</td>\n",
       "      <td>0.016756</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.936700</td>\n",
       "      <td>0.011911</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>2.458467e-04</td>\n",
       "      <td>200</td>\n",
       "      <td>{'n_estimators': 200}</td>\n",
       "      <td>0.009684</td>\n",
       "      <td>0.053838</td>\n",
       "      <td>0.018395</td>\n",
       "      <td>0.037894</td>\n",
       "      <td>0.013703</td>\n",
       "      <td>0.026703</td>\n",
       "      <td>0.016669</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.878299</td>\n",
       "      <td>0.019050</td>\n",
       "      <td>0.003099</td>\n",
       "      <td>2.002487e-04</td>\n",
       "      <td>300</td>\n",
       "      <td>{'n_estimators': 300}</td>\n",
       "      <td>0.009650</td>\n",
       "      <td>0.055079</td>\n",
       "      <td>0.019419</td>\n",
       "      <td>0.038031</td>\n",
       "      <td>0.014372</td>\n",
       "      <td>0.027310</td>\n",
       "      <td>0.016897</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.842100</td>\n",
       "      <td>0.017554</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>2.008440e-04</td>\n",
       "      <td>400</td>\n",
       "      <td>{'n_estimators': 400}</td>\n",
       "      <td>0.016045</td>\n",
       "      <td>0.055660</td>\n",
       "      <td>0.017351</td>\n",
       "      <td>0.038797</td>\n",
       "      <td>0.013757</td>\n",
       "      <td>0.028322</td>\n",
       "      <td>0.016373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.792800</td>\n",
       "      <td>0.025097</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>1.994615e-04</td>\n",
       "      <td>500</td>\n",
       "      <td>{'n_estimators': 500}</td>\n",
       "      <td>0.009622</td>\n",
       "      <td>0.054481</td>\n",
       "      <td>0.018327</td>\n",
       "      <td>0.038396</td>\n",
       "      <td>0.013746</td>\n",
       "      <td>0.026914</td>\n",
       "      <td>0.016958</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.732300</td>\n",
       "      <td>0.049063</td>\n",
       "      <td>0.004999</td>\n",
       "      <td>3.162812e-04</td>\n",
       "      <td>600</td>\n",
       "      <td>{'n_estimators': 600}</td>\n",
       "      <td>0.012483</td>\n",
       "      <td>0.048694</td>\n",
       "      <td>0.018392</td>\n",
       "      <td>0.038067</td>\n",
       "      <td>0.013708</td>\n",
       "      <td>0.026269</td>\n",
       "      <td>0.014505</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.622600</td>\n",
       "      <td>0.039864</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>2.445617e-04</td>\n",
       "      <td>700</td>\n",
       "      <td>{'n_estimators': 700}</td>\n",
       "      <td>0.009706</td>\n",
       "      <td>0.055382</td>\n",
       "      <td>0.018189</td>\n",
       "      <td>0.040099</td>\n",
       "      <td>0.013801</td>\n",
       "      <td>0.027436</td>\n",
       "      <td>0.017476</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.608401</td>\n",
       "      <td>0.049532</td>\n",
       "      <td>0.006499</td>\n",
       "      <td>3.693565e-07</td>\n",
       "      <td>800</td>\n",
       "      <td>{'n_estimators': 800}</td>\n",
       "      <td>0.009646</td>\n",
       "      <td>0.051740</td>\n",
       "      <td>0.017458</td>\n",
       "      <td>0.044627</td>\n",
       "      <td>0.017740</td>\n",
       "      <td>0.028242</td>\n",
       "      <td>0.016691</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.564000</td>\n",
       "      <td>0.052674</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>7.072638e-07</td>\n",
       "      <td>900</td>\n",
       "      <td>{'n_estimators': 900}</td>\n",
       "      <td>0.009648</td>\n",
       "      <td>0.051585</td>\n",
       "      <td>0.017061</td>\n",
       "      <td>0.047150</td>\n",
       "      <td>0.013702</td>\n",
       "      <td>0.027829</td>\n",
       "      <td>0.017797</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.985500      0.013338         0.001600    2.000585e-04   \n",
       "1       1.936700      0.011911         0.002199    2.458467e-04   \n",
       "2       2.878299      0.019050         0.003099    2.002487e-04   \n",
       "3       3.842100      0.017554         0.003899    2.008440e-04   \n",
       "4       4.792800      0.025097         0.004399    1.994615e-04   \n",
       "5       5.732300      0.049063         0.004999    3.162812e-04   \n",
       "6       6.622600      0.039864         0.005800    2.445617e-04   \n",
       "7       7.608401      0.049532         0.006499    3.693565e-07   \n",
       "8       8.564000      0.052674         0.006999    7.072638e-07   \n",
       "\n",
       "  param_n_estimators                 params  split0_test_score  \\\n",
       "0                100  {'n_estimators': 100}           0.009657   \n",
       "1                200  {'n_estimators': 200}           0.009684   \n",
       "2                300  {'n_estimators': 300}           0.009650   \n",
       "3                400  {'n_estimators': 400}           0.016045   \n",
       "4                500  {'n_estimators': 500}           0.009622   \n",
       "5                600  {'n_estimators': 600}           0.012483   \n",
       "6                700  {'n_estimators': 700}           0.009706   \n",
       "7                800  {'n_estimators': 800}           0.009646   \n",
       "8                900  {'n_estimators': 900}           0.009648   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.053700           0.017099           0.037795           0.013679   \n",
       "1           0.053838           0.018395           0.037894           0.013703   \n",
       "2           0.055079           0.019419           0.038031           0.014372   \n",
       "3           0.055660           0.017351           0.038797           0.013757   \n",
       "4           0.054481           0.018327           0.038396           0.013746   \n",
       "5           0.048694           0.018392           0.038067           0.013708   \n",
       "6           0.055382           0.018189           0.040099           0.013801   \n",
       "7           0.051740           0.017458           0.044627           0.017740   \n",
       "8           0.051585           0.017061           0.047150           0.013702   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.026386        0.016756                8  \n",
       "1         0.026703        0.016669                7  \n",
       "2         0.027310        0.016897                5  \n",
       "3         0.028322        0.016373                1  \n",
       "4         0.026914        0.016958                6  \n",
       "5         0.026269        0.014505                9  \n",
       "6         0.027436        0.017476                4  \n",
       "7         0.028242        0.016691                2  \n",
       "8         0.027829        0.017797                3  "
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = pd.DataFrame(gsearch1.cv_results_)\n",
    "gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "f400e3c6-8e78-457c-a85d-9cc4f4b737a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=GradientBoostingRegressor(loss='absolute_error'),\n",
       "             param_grid={'learning_rate': [0.05, 0.25, 0.5, 0.75, 1, 1.25, 1.5,\n",
       "                                           1.75, 2],\n",
       "                         'n_estimators': range(200, 600, 100)})"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_test1 = {'n_estimators':range(200,600,100), 'learning_rate':[0.05,0.25,0.5,0.75,1,1.25,1.5,1.75,2]}\n",
    "gb = GradientBoostingRegressor(loss='absolute_error')\n",
    "gsearch1 = GridSearchCV(gb,param_test1)\n",
    "gsearch1.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "7b89e9f0-4754-4063-bf08-b9383c854450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.981333</td>\n",
       "      <td>0.016197</td>\n",
       "      <td>0.003099</td>\n",
       "      <td>4.891326e-04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 200}</td>\n",
       "      <td>0.015080</td>\n",
       "      <td>0.033569</td>\n",
       "      <td>0.005642</td>\n",
       "      <td>0.027288</td>\n",
       "      <td>0.009004</td>\n",
       "      <td>0.018117</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.962600</td>\n",
       "      <td>0.023355</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>2.004168e-04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 300}</td>\n",
       "      <td>0.015068</td>\n",
       "      <td>0.045789</td>\n",
       "      <td>0.014183</td>\n",
       "      <td>0.027540</td>\n",
       "      <td>0.009011</td>\n",
       "      <td>0.022318</td>\n",
       "      <td>0.013221</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.886200</td>\n",
       "      <td>0.041774</td>\n",
       "      <td>0.004299</td>\n",
       "      <td>2.452042e-04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>400</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 400}</td>\n",
       "      <td>0.015832</td>\n",
       "      <td>0.044676</td>\n",
       "      <td>0.005745</td>\n",
       "      <td>0.022780</td>\n",
       "      <td>0.008997</td>\n",
       "      <td>0.019606</td>\n",
       "      <td>0.013838</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.809100</td>\n",
       "      <td>0.040545</td>\n",
       "      <td>0.004899</td>\n",
       "      <td>2.004866e-04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 500}</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>0.033674</td>\n",
       "      <td>0.004676</td>\n",
       "      <td>0.023131</td>\n",
       "      <td>0.009076</td>\n",
       "      <td>0.017137</td>\n",
       "      <td>0.010331</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.918900</td>\n",
       "      <td>0.017687</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>6.810597e-07</td>\n",
       "      <td>0.25</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.25, 'n_estimators': 200}</td>\n",
       "      <td>0.028463</td>\n",
       "      <td>0.079059</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.061845</td>\n",
       "      <td>-0.001662</td>\n",
       "      <td>0.037361</td>\n",
       "      <td>0.029236</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.851999</td>\n",
       "      <td>0.014152</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>2.470656e-04</td>\n",
       "      <td>0.25</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.25, 'n_estimators': 300}</td>\n",
       "      <td>0.014563</td>\n",
       "      <td>0.073918</td>\n",
       "      <td>0.042899</td>\n",
       "      <td>0.063517</td>\n",
       "      <td>0.020817</td>\n",
       "      <td>0.043143</td>\n",
       "      <td>0.023141</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.780401</td>\n",
       "      <td>0.020568</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>2.002957e-04</td>\n",
       "      <td>0.25</td>\n",
       "      <td>400</td>\n",
       "      <td>{'learning_rate': 0.25, 'n_estimators': 400}</td>\n",
       "      <td>0.012590</td>\n",
       "      <td>0.070267</td>\n",
       "      <td>0.050124</td>\n",
       "      <td>0.040249</td>\n",
       "      <td>-0.000858</td>\n",
       "      <td>0.034474</td>\n",
       "      <td>0.025639</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.745800</td>\n",
       "      <td>0.018924</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>2.431402e-07</td>\n",
       "      <td>0.25</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.25, 'n_estimators': 500}</td>\n",
       "      <td>0.028465</td>\n",
       "      <td>0.066210</td>\n",
       "      <td>0.016678</td>\n",
       "      <td>0.040381</td>\n",
       "      <td>0.013841</td>\n",
       "      <td>0.033115</td>\n",
       "      <td>0.019034</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.909900</td>\n",
       "      <td>0.016249</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>1.998669e-04</td>\n",
       "      <td>0.5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 200}</td>\n",
       "      <td>0.058312</td>\n",
       "      <td>0.104767</td>\n",
       "      <td>0.017970</td>\n",
       "      <td>0.050560</td>\n",
       "      <td>0.031463</td>\n",
       "      <td>0.052614</td>\n",
       "      <td>0.029679</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.852000</td>\n",
       "      <td>0.029426</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>1.999162e-04</td>\n",
       "      <td>0.5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 300}</td>\n",
       "      <td>0.059628</td>\n",
       "      <td>0.073921</td>\n",
       "      <td>0.017938</td>\n",
       "      <td>0.114321</td>\n",
       "      <td>0.030990</td>\n",
       "      <td>0.059360</td>\n",
       "      <td>0.033922</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.827900</td>\n",
       "      <td>0.037268</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>5.955694e-07</td>\n",
       "      <td>0.5</td>\n",
       "      <td>400</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 400}</td>\n",
       "      <td>0.059436</td>\n",
       "      <td>0.120306</td>\n",
       "      <td>0.182108</td>\n",
       "      <td>0.060862</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.084760</td>\n",
       "      <td>0.061568</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.719300</td>\n",
       "      <td>0.041904</td>\n",
       "      <td>0.003999</td>\n",
       "      <td>8.920806e-07</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.5, 'n_estimators': 500}</td>\n",
       "      <td>0.057392</td>\n",
       "      <td>0.137304</td>\n",
       "      <td>0.061930</td>\n",
       "      <td>0.077010</td>\n",
       "      <td>0.031782</td>\n",
       "      <td>0.073084</td>\n",
       "      <td>0.035259</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.909300</td>\n",
       "      <td>0.017165</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>6.843901e-07</td>\n",
       "      <td>0.75</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 0.75, 'n_estimators': 200}</td>\n",
       "      <td>0.029278</td>\n",
       "      <td>0.077170</td>\n",
       "      <td>0.051744</td>\n",
       "      <td>0.055660</td>\n",
       "      <td>0.070146</td>\n",
       "      <td>0.056799</td>\n",
       "      <td>0.016598</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.863901</td>\n",
       "      <td>0.019030</td>\n",
       "      <td>0.002699</td>\n",
       "      <td>4.002818e-04</td>\n",
       "      <td>0.75</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 0.75, 'n_estimators': 300}</td>\n",
       "      <td>0.073714</td>\n",
       "      <td>0.092911</td>\n",
       "      <td>0.062472</td>\n",
       "      <td>-0.008938</td>\n",
       "      <td>-0.004465</td>\n",
       "      <td>0.043139</td>\n",
       "      <td>0.041866</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.808100</td>\n",
       "      <td>0.030578</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>2.448737e-04</td>\n",
       "      <td>0.75</td>\n",
       "      <td>400</td>\n",
       "      <td>{'learning_rate': 0.75, 'n_estimators': 400}</td>\n",
       "      <td>0.024047</td>\n",
       "      <td>0.066686</td>\n",
       "      <td>0.259899</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>0.087865</td>\n",
       "      <td>0.088744</td>\n",
       "      <td>0.090491</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.764000</td>\n",
       "      <td>0.030565</td>\n",
       "      <td>0.003999</td>\n",
       "      <td>4.422006e-07</td>\n",
       "      <td>0.75</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 0.75, 'n_estimators': 500}</td>\n",
       "      <td>0.050409</td>\n",
       "      <td>0.055970</td>\n",
       "      <td>0.047841</td>\n",
       "      <td>0.022664</td>\n",
       "      <td>-0.007608</td>\n",
       "      <td>0.033855</td>\n",
       "      <td>0.023678</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.915600</td>\n",
       "      <td>0.015870</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>5.309834e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 1, 'n_estimators': 200}</td>\n",
       "      <td>0.033216</td>\n",
       "      <td>0.140969</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.106296</td>\n",
       "      <td>0.047174</td>\n",
       "      <td>0.077898</td>\n",
       "      <td>0.039957</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.868400</td>\n",
       "      <td>0.053584</td>\n",
       "      <td>0.002699</td>\n",
       "      <td>2.453796e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 1, 'n_estimators': 300}</td>\n",
       "      <td>0.010168</td>\n",
       "      <td>0.108133</td>\n",
       "      <td>0.062581</td>\n",
       "      <td>0.093827</td>\n",
       "      <td>0.063608</td>\n",
       "      <td>0.067663</td>\n",
       "      <td>0.033676</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.780999</td>\n",
       "      <td>0.020268</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>1.996047e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "      <td>{'learning_rate': 1, 'n_estimators': 400}</td>\n",
       "      <td>0.037349</td>\n",
       "      <td>0.080841</td>\n",
       "      <td>0.043889</td>\n",
       "      <td>-0.045318</td>\n",
       "      <td>0.063619</td>\n",
       "      <td>0.036076</td>\n",
       "      <td>0.043474</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.786201</td>\n",
       "      <td>0.094618</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>3.747504e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 1, 'n_estimators': 500}</td>\n",
       "      <td>0.028964</td>\n",
       "      <td>0.037615</td>\n",
       "      <td>0.032301</td>\n",
       "      <td>0.007471</td>\n",
       "      <td>0.024102</td>\n",
       "      <td>0.026090</td>\n",
       "      <td>0.010298</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.968999</td>\n",
       "      <td>0.011211</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>1.999154e-04</td>\n",
       "      <td>1.25</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 1.25, 'n_estimators': 200}</td>\n",
       "      <td>0.046938</td>\n",
       "      <td>0.058123</td>\n",
       "      <td>0.107011</td>\n",
       "      <td>-0.149612</td>\n",
       "      <td>0.092738</td>\n",
       "      <td>0.031040</td>\n",
       "      <td>0.092951</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.952200</td>\n",
       "      <td>0.015085</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>2.004627e-04</td>\n",
       "      <td>1.25</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 1.25, 'n_estimators': 300}</td>\n",
       "      <td>0.041129</td>\n",
       "      <td>0.197341</td>\n",
       "      <td>0.061001</td>\n",
       "      <td>0.046885</td>\n",
       "      <td>-0.020804</td>\n",
       "      <td>0.065110</td>\n",
       "      <td>0.071820</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.926101</td>\n",
       "      <td>0.021564</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>2.000350e-04</td>\n",
       "      <td>1.25</td>\n",
       "      <td>400</td>\n",
       "      <td>{'learning_rate': 1.25, 'n_estimators': 400}</td>\n",
       "      <td>0.036261</td>\n",
       "      <td>0.097729</td>\n",
       "      <td>0.017257</td>\n",
       "      <td>0.081840</td>\n",
       "      <td>0.148290</td>\n",
       "      <td>0.076276</td>\n",
       "      <td>0.046393</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.895000</td>\n",
       "      <td>0.039832</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.999154e-04</td>\n",
       "      <td>1.25</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 1.25, 'n_estimators': 500}</td>\n",
       "      <td>0.053828</td>\n",
       "      <td>0.068787</td>\n",
       "      <td>0.157322</td>\n",
       "      <td>0.069283</td>\n",
       "      <td>0.007218</td>\n",
       "      <td>0.071287</td>\n",
       "      <td>0.048625</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.977800</td>\n",
       "      <td>0.014532</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>7.893059e-07</td>\n",
       "      <td>1.5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 1.5, 'n_estimators': 200}</td>\n",
       "      <td>0.196371</td>\n",
       "      <td>0.032449</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>-0.011177</td>\n",
       "      <td>0.082682</td>\n",
       "      <td>0.061080</td>\n",
       "      <td>0.074764</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.958800</td>\n",
       "      <td>0.012617</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>2.447367e-04</td>\n",
       "      <td>1.5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 1.5, 'n_estimators': 300}</td>\n",
       "      <td>0.088006</td>\n",
       "      <td>0.191587</td>\n",
       "      <td>-0.008808</td>\n",
       "      <td>-0.167455</td>\n",
       "      <td>0.010902</td>\n",
       "      <td>0.022846</td>\n",
       "      <td>0.118388</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.988600</td>\n",
       "      <td>0.025493</td>\n",
       "      <td>0.004099</td>\n",
       "      <td>2.003915e-04</td>\n",
       "      <td>1.5</td>\n",
       "      <td>400</td>\n",
       "      <td>{'learning_rate': 1.5, 'n_estimators': 400}</td>\n",
       "      <td>0.016942</td>\n",
       "      <td>0.237558</td>\n",
       "      <td>0.017646</td>\n",
       "      <td>0.071269</td>\n",
       "      <td>0.099722</td>\n",
       "      <td>0.088627</td>\n",
       "      <td>0.080971</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.953600</td>\n",
       "      <td>0.030168</td>\n",
       "      <td>0.004799</td>\n",
       "      <td>2.447954e-04</td>\n",
       "      <td>1.5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 1.5, 'n_estimators': 500}</td>\n",
       "      <td>-0.213403</td>\n",
       "      <td>0.067184</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>-0.012154</td>\n",
       "      <td>-0.003381</td>\n",
       "      <td>-0.028931</td>\n",
       "      <td>0.096251</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.998700</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.002799</td>\n",
       "      <td>2.453596e-04</td>\n",
       "      <td>1.75</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 1.75, 'n_estimators': 200}</td>\n",
       "      <td>0.011854</td>\n",
       "      <td>0.130345</td>\n",
       "      <td>0.133496</td>\n",
       "      <td>-2.020183</td>\n",
       "      <td>0.258020</td>\n",
       "      <td>-0.297294</td>\n",
       "      <td>0.864956</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.990600</td>\n",
       "      <td>0.013169</td>\n",
       "      <td>0.003699</td>\n",
       "      <td>2.451649e-04</td>\n",
       "      <td>1.75</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 1.75, 'n_estimators': 300}</td>\n",
       "      <td>0.128089</td>\n",
       "      <td>0.149423</td>\n",
       "      <td>0.159537</td>\n",
       "      <td>-0.239073</td>\n",
       "      <td>0.223709</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.164818</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3.971299</td>\n",
       "      <td>0.022382</td>\n",
       "      <td>0.004799</td>\n",
       "      <td>2.444451e-04</td>\n",
       "      <td>1.75</td>\n",
       "      <td>400</td>\n",
       "      <td>{'learning_rate': 1.75, 'n_estimators': 400}</td>\n",
       "      <td>0.061025</td>\n",
       "      <td>0.170444</td>\n",
       "      <td>-0.009078</td>\n",
       "      <td>-0.562047</td>\n",
       "      <td>0.058579</td>\n",
       "      <td>-0.056215</td>\n",
       "      <td>0.259378</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4.983901</td>\n",
       "      <td>0.017687</td>\n",
       "      <td>0.005699</td>\n",
       "      <td>3.997092e-04</td>\n",
       "      <td>1.75</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 1.75, 'n_estimators': 500}</td>\n",
       "      <td>0.122994</td>\n",
       "      <td>0.100124</td>\n",
       "      <td>0.164233</td>\n",
       "      <td>-0.143286</td>\n",
       "      <td>-0.067447</td>\n",
       "      <td>0.035324</td>\n",
       "      <td>0.119135</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.969700</td>\n",
       "      <td>0.012627</td>\n",
       "      <td>0.003899</td>\n",
       "      <td>1.999624e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>{'learning_rate': 2, 'n_estimators': 200}</td>\n",
       "      <td>-0.029546</td>\n",
       "      <td>-0.014666</td>\n",
       "      <td>0.047783</td>\n",
       "      <td>0.065309</td>\n",
       "      <td>-0.001212</td>\n",
       "      <td>0.013534</td>\n",
       "      <td>0.036667</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2.978300</td>\n",
       "      <td>0.010424</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>5.477710e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>300</td>\n",
       "      <td>{'learning_rate': 2, 'n_estimators': 300}</td>\n",
       "      <td>-0.027523</td>\n",
       "      <td>-0.014666</td>\n",
       "      <td>0.047783</td>\n",
       "      <td>0.019444</td>\n",
       "      <td>-0.001212</td>\n",
       "      <td>0.004765</td>\n",
       "      <td>0.026540</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3.969301</td>\n",
       "      <td>0.015911</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>7.067184e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>400</td>\n",
       "      <td>{'learning_rate': 2, 'n_estimators': 400}</td>\n",
       "      <td>-1.973199</td>\n",
       "      <td>-0.014666</td>\n",
       "      <td>0.047783</td>\n",
       "      <td>0.078607</td>\n",
       "      <td>-0.001212</td>\n",
       "      <td>-0.372537</td>\n",
       "      <td>0.801033</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4.927000</td>\n",
       "      <td>0.039740</td>\n",
       "      <td>0.008899</td>\n",
       "      <td>9.695004e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>{'learning_rate': 2, 'n_estimators': 500}</td>\n",
       "      <td>0.143653</td>\n",
       "      <td>-0.014666</td>\n",
       "      <td>0.047783</td>\n",
       "      <td>0.018498</td>\n",
       "      <td>-0.001212</td>\n",
       "      <td>0.038811</td>\n",
       "      <td>0.056474</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        1.981333      0.016197         0.003099    4.891326e-04   \n",
       "1        2.962600      0.023355         0.003599    2.004168e-04   \n",
       "2        3.886200      0.041774         0.004299    2.452042e-04   \n",
       "3        4.809100      0.040545         0.004899    2.004866e-04   \n",
       "4        1.918900      0.017687         0.001999    6.810597e-07   \n",
       "5        2.851999      0.014152         0.002802    2.470656e-04   \n",
       "6        3.780401      0.020568         0.003400    2.002957e-04   \n",
       "7        4.745800      0.018924         0.004000    2.431402e-07   \n",
       "8        1.909900      0.016249         0.001899    1.998669e-04   \n",
       "9        2.852000      0.029426         0.002600    1.999162e-04   \n",
       "10       3.827900      0.037268         0.002999    5.955694e-07   \n",
       "11       4.719300      0.041904         0.003999    8.920806e-07   \n",
       "12       1.909300      0.017165         0.002000    6.843901e-07   \n",
       "13       2.863901      0.019030         0.002699    4.002818e-04   \n",
       "14       3.808100      0.030578         0.003299    2.448737e-04   \n",
       "15       4.764000      0.030565         0.003999    4.422006e-07   \n",
       "16       1.915600      0.015870         0.002000    5.309834e-07   \n",
       "17       2.868400      0.053584         0.002699    2.453796e-04   \n",
       "18       3.780999      0.020268         0.003399    1.996047e-04   \n",
       "19       4.786201      0.094618         0.003899    3.747504e-04   \n",
       "20       1.968999      0.011211         0.002100    1.999154e-04   \n",
       "21       2.952200      0.015085         0.002899    2.004627e-04   \n",
       "22       3.926101      0.021564         0.003599    2.000350e-04   \n",
       "23       4.895000      0.039832         0.004400    1.999154e-04   \n",
       "24       1.977800      0.014532         0.002499    7.893059e-07   \n",
       "25       2.958800      0.012617         0.003300    2.447367e-04   \n",
       "26       3.988600      0.025493         0.004099    2.003915e-04   \n",
       "27       4.953600      0.030168         0.004799    2.447954e-04   \n",
       "28       1.998700      0.003906         0.002799    2.453596e-04   \n",
       "29       2.990600      0.013169         0.003699    2.451649e-04   \n",
       "30       3.971299      0.022382         0.004799    2.444451e-04   \n",
       "31       4.983901      0.017687         0.005699    3.997092e-04   \n",
       "32       1.969700      0.012627         0.003899    1.999624e-04   \n",
       "33       2.978300      0.010424         0.005499    5.477710e-04   \n",
       "34       3.969301      0.015911         0.007000    7.067184e-04   \n",
       "35       4.927000      0.039740         0.008899    9.695004e-04   \n",
       "\n",
       "   param_learning_rate param_n_estimators  \\\n",
       "0                 0.05                200   \n",
       "1                 0.05                300   \n",
       "2                 0.05                400   \n",
       "3                 0.05                500   \n",
       "4                 0.25                200   \n",
       "5                 0.25                300   \n",
       "6                 0.25                400   \n",
       "7                 0.25                500   \n",
       "8                  0.5                200   \n",
       "9                  0.5                300   \n",
       "10                 0.5                400   \n",
       "11                 0.5                500   \n",
       "12                0.75                200   \n",
       "13                0.75                300   \n",
       "14                0.75                400   \n",
       "15                0.75                500   \n",
       "16                   1                200   \n",
       "17                   1                300   \n",
       "18                   1                400   \n",
       "19                   1                500   \n",
       "20                1.25                200   \n",
       "21                1.25                300   \n",
       "22                1.25                400   \n",
       "23                1.25                500   \n",
       "24                 1.5                200   \n",
       "25                 1.5                300   \n",
       "26                 1.5                400   \n",
       "27                 1.5                500   \n",
       "28                1.75                200   \n",
       "29                1.75                300   \n",
       "30                1.75                400   \n",
       "31                1.75                500   \n",
       "32                   2                200   \n",
       "33                   2                300   \n",
       "34                   2                400   \n",
       "35                   2                500   \n",
       "\n",
       "                                          params  split0_test_score  \\\n",
       "0   {'learning_rate': 0.05, 'n_estimators': 200}           0.015080   \n",
       "1   {'learning_rate': 0.05, 'n_estimators': 300}           0.015068   \n",
       "2   {'learning_rate': 0.05, 'n_estimators': 400}           0.015832   \n",
       "3   {'learning_rate': 0.05, 'n_estimators': 500}           0.015127   \n",
       "4   {'learning_rate': 0.25, 'n_estimators': 200}           0.028463   \n",
       "5   {'learning_rate': 0.25, 'n_estimators': 300}           0.014563   \n",
       "6   {'learning_rate': 0.25, 'n_estimators': 400}           0.012590   \n",
       "7   {'learning_rate': 0.25, 'n_estimators': 500}           0.028465   \n",
       "8    {'learning_rate': 0.5, 'n_estimators': 200}           0.058312   \n",
       "9    {'learning_rate': 0.5, 'n_estimators': 300}           0.059628   \n",
       "10   {'learning_rate': 0.5, 'n_estimators': 400}           0.059436   \n",
       "11   {'learning_rate': 0.5, 'n_estimators': 500}           0.057392   \n",
       "12  {'learning_rate': 0.75, 'n_estimators': 200}           0.029278   \n",
       "13  {'learning_rate': 0.75, 'n_estimators': 300}           0.073714   \n",
       "14  {'learning_rate': 0.75, 'n_estimators': 400}           0.024047   \n",
       "15  {'learning_rate': 0.75, 'n_estimators': 500}           0.050409   \n",
       "16     {'learning_rate': 1, 'n_estimators': 200}           0.033216   \n",
       "17     {'learning_rate': 1, 'n_estimators': 300}           0.010168   \n",
       "18     {'learning_rate': 1, 'n_estimators': 400}           0.037349   \n",
       "19     {'learning_rate': 1, 'n_estimators': 500}           0.028964   \n",
       "20  {'learning_rate': 1.25, 'n_estimators': 200}           0.046938   \n",
       "21  {'learning_rate': 1.25, 'n_estimators': 300}           0.041129   \n",
       "22  {'learning_rate': 1.25, 'n_estimators': 400}           0.036261   \n",
       "23  {'learning_rate': 1.25, 'n_estimators': 500}           0.053828   \n",
       "24   {'learning_rate': 1.5, 'n_estimators': 200}           0.196371   \n",
       "25   {'learning_rate': 1.5, 'n_estimators': 300}           0.088006   \n",
       "26   {'learning_rate': 1.5, 'n_estimators': 400}           0.016942   \n",
       "27   {'learning_rate': 1.5, 'n_estimators': 500}          -0.213403   \n",
       "28  {'learning_rate': 1.75, 'n_estimators': 200}           0.011854   \n",
       "29  {'learning_rate': 1.75, 'n_estimators': 300}           0.128089   \n",
       "30  {'learning_rate': 1.75, 'n_estimators': 400}           0.061025   \n",
       "31  {'learning_rate': 1.75, 'n_estimators': 500}           0.122994   \n",
       "32     {'learning_rate': 2, 'n_estimators': 200}          -0.029546   \n",
       "33     {'learning_rate': 2, 'n_estimators': 300}          -0.027523   \n",
       "34     {'learning_rate': 2, 'n_estimators': 400}          -1.973199   \n",
       "35     {'learning_rate': 2, 'n_estimators': 500}           0.143653   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.033569           0.005642           0.027288   \n",
       "1            0.045789           0.014183           0.027540   \n",
       "2            0.044676           0.005745           0.022780   \n",
       "3            0.033674           0.004676           0.023131   \n",
       "4            0.079059           0.019100           0.061845   \n",
       "5            0.073918           0.042899           0.063517   \n",
       "6            0.070267           0.050124           0.040249   \n",
       "7            0.066210           0.016678           0.040381   \n",
       "8            0.104767           0.017970           0.050560   \n",
       "9            0.073921           0.017938           0.114321   \n",
       "10           0.120306           0.182108           0.060862   \n",
       "11           0.137304           0.061930           0.077010   \n",
       "12           0.077170           0.051744           0.055660   \n",
       "13           0.092911           0.062472          -0.008938   \n",
       "14           0.066686           0.259899           0.005222   \n",
       "15           0.055970           0.047841           0.022664   \n",
       "16           0.140969           0.061836           0.106296   \n",
       "17           0.108133           0.062581           0.093827   \n",
       "18           0.080841           0.043889          -0.045318   \n",
       "19           0.037615           0.032301           0.007471   \n",
       "20           0.058123           0.107011          -0.149612   \n",
       "21           0.197341           0.061001           0.046885   \n",
       "22           0.097729           0.017257           0.081840   \n",
       "23           0.068787           0.157322           0.069283   \n",
       "24           0.032449           0.005074          -0.011177   \n",
       "25           0.191587          -0.008808          -0.167455   \n",
       "26           0.237558           0.017646           0.071269   \n",
       "27           0.067184           0.017100          -0.012154   \n",
       "28           0.130345           0.133496          -2.020183   \n",
       "29           0.149423           0.159537          -0.239073   \n",
       "30           0.170444          -0.009078          -0.562047   \n",
       "31           0.100124           0.164233          -0.143286   \n",
       "32          -0.014666           0.047783           0.065309   \n",
       "33          -0.014666           0.047783           0.019444   \n",
       "34          -0.014666           0.047783           0.078607   \n",
       "35          -0.014666           0.047783           0.018498   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.009004         0.018117        0.010684               29  \n",
       "1            0.009011         0.022318        0.013221               27  \n",
       "2            0.008997         0.019606        0.013838               28  \n",
       "3            0.009076         0.017137        0.010331               30  \n",
       "4           -0.001662         0.037361        0.029236               18  \n",
       "5            0.020817         0.043143        0.023141               15  \n",
       "6           -0.000858         0.034474        0.025639               21  \n",
       "7            0.013841         0.033115        0.019034               23  \n",
       "8            0.031463         0.052614        0.029679               14  \n",
       "9            0.030990         0.059360        0.033922               12  \n",
       "10           0.001089         0.084760        0.061568                3  \n",
       "11           0.031782         0.073084        0.035259                7  \n",
       "12           0.070146         0.056799        0.016598               13  \n",
       "13          -0.004465         0.043139        0.041866               16  \n",
       "14           0.087865         0.088744        0.090491                1  \n",
       "15          -0.007608         0.033855        0.023678               22  \n",
       "16           0.047174         0.077898        0.039957                5  \n",
       "17           0.063608         0.067663        0.033676                9  \n",
       "18           0.063619         0.036076        0.043474               19  \n",
       "19           0.024102         0.026090        0.010298               25  \n",
       "20           0.092738         0.031040        0.092951               24  \n",
       "21          -0.020804         0.065110        0.071820               10  \n",
       "22           0.148290         0.076276        0.046393                6  \n",
       "23           0.007218         0.071287        0.048625                8  \n",
       "24           0.082682         0.061080        0.074764               11  \n",
       "25           0.010902         0.022846        0.118388               26  \n",
       "26           0.099722         0.088627        0.080971                2  \n",
       "27          -0.003381        -0.028931        0.096251               33  \n",
       "28           0.258020        -0.297294        0.864956               35  \n",
       "29           0.223709         0.084337        0.164818                4  \n",
       "30           0.058579        -0.056215        0.259378               34  \n",
       "31          -0.067447         0.035324        0.119135               20  \n",
       "32          -0.001212         0.013534        0.036667               31  \n",
       "33          -0.001212         0.004765        0.026540               32  \n",
       "34          -0.001212        -0.372537        0.801033               36  \n",
       "35          -0.001212         0.038811        0.056474               17  "
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs = pd.DataFrame(gsearch1.cv_results_)\n",
    "gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71de6b59-4f78-4301-981e-f898f64c3251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=GradientBoostingRegressor(learning_rate=0.75,\n",
       "                                                 loss='absolute_error',\n",
       "                                                 n_estimators=400),\n",
       "             param_grid={'max_depth': range(5, 16, 2),\n",
       "                         'min_samples_split': range(200, 1001, 200)})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_test2 = {'max_depth':range(5,16,2), 'min_samples_split':range(200,1001,200)}\n",
    "gb2 = GradientBoostingRegressor(n_estimators = 400, learning_rate = 0.75,loss='absolute_error')\n",
    "# GradientBoostingRegressor(n_estimators = 400, learning_rate = 0.75,max_depth = 13, min_samples_split = 200,loss='absolute_error')\n",
    "gsearch2 = GridSearchCV(gb2,param_test2)\n",
    "gsearch2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1adf13a8-8e49-4f8f-bffe-32bc09b5bd4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.976300</td>\n",
       "      <td>0.020635</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.997233e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 200}</td>\n",
       "      <td>-0.027027</td>\n",
       "      <td>0.114974</td>\n",
       "      <td>0.121019</td>\n",
       "      <td>0.069402</td>\n",
       "      <td>0.068009</td>\n",
       "      <td>0.069275</td>\n",
       "      <td>0.052994</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.927600</td>\n",
       "      <td>0.016406</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.996527e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>400</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 400}</td>\n",
       "      <td>0.150060</td>\n",
       "      <td>0.108152</td>\n",
       "      <td>0.109629</td>\n",
       "      <td>0.112724</td>\n",
       "      <td>0.107708</td>\n",
       "      <td>0.117655</td>\n",
       "      <td>0.016298</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.913700</td>\n",
       "      <td>0.018304</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>4.672031e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>600</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 600}</td>\n",
       "      <td>0.036617</td>\n",
       "      <td>0.151591</td>\n",
       "      <td>0.065702</td>\n",
       "      <td>0.089838</td>\n",
       "      <td>0.042129</td>\n",
       "      <td>0.077175</td>\n",
       "      <td>0.041720</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.895799</td>\n",
       "      <td>0.037434</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.999390e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>800</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 800}</td>\n",
       "      <td>0.073109</td>\n",
       "      <td>0.158742</td>\n",
       "      <td>0.126176</td>\n",
       "      <td>0.092763</td>\n",
       "      <td>0.062090</td>\n",
       "      <td>0.102576</td>\n",
       "      <td>0.035539</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.861500</td>\n",
       "      <td>0.024740</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.168008e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_split': 1000}</td>\n",
       "      <td>-0.015085</td>\n",
       "      <td>0.152847</td>\n",
       "      <td>0.129067</td>\n",
       "      <td>0.063736</td>\n",
       "      <td>0.110985</td>\n",
       "      <td>0.088310</td>\n",
       "      <td>0.059388</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.184200</td>\n",
       "      <td>0.027663</td>\n",
       "      <td>0.007401</td>\n",
       "      <td>2.003768e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_split': 200}</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.040350</td>\n",
       "      <td>0.106191</td>\n",
       "      <td>-0.014873</td>\n",
       "      <td>0.041674</td>\n",
       "      <td>0.034998</td>\n",
       "      <td>0.041812</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.090900</td>\n",
       "      <td>0.036839</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>5.917394e-07</td>\n",
       "      <td>7</td>\n",
       "      <td>400</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_split': 400}</td>\n",
       "      <td>0.020567</td>\n",
       "      <td>0.065764</td>\n",
       "      <td>0.072388</td>\n",
       "      <td>0.129819</td>\n",
       "      <td>0.086573</td>\n",
       "      <td>0.075022</td>\n",
       "      <td>0.035197</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.124500</td>\n",
       "      <td>0.086021</td>\n",
       "      <td>0.007401</td>\n",
       "      <td>1.998206e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>600</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_split': 600}</td>\n",
       "      <td>0.214389</td>\n",
       "      <td>0.089894</td>\n",
       "      <td>-0.007833</td>\n",
       "      <td>0.161594</td>\n",
       "      <td>0.139755</td>\n",
       "      <td>0.119560</td>\n",
       "      <td>0.075201</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.046100</td>\n",
       "      <td>0.010777</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>4.101908e-07</td>\n",
       "      <td>7</td>\n",
       "      <td>800</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_split': 800}</td>\n",
       "      <td>0.037810</td>\n",
       "      <td>0.175360</td>\n",
       "      <td>0.067908</td>\n",
       "      <td>-0.043263</td>\n",
       "      <td>0.141355</td>\n",
       "      <td>0.075834</td>\n",
       "      <td>0.077319</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.972900</td>\n",
       "      <td>0.037118</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>1.999620e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_split': 1000}</td>\n",
       "      <td>0.055833</td>\n",
       "      <td>0.141944</td>\n",
       "      <td>0.035934</td>\n",
       "      <td>0.071006</td>\n",
       "      <td>0.055628</td>\n",
       "      <td>0.072069</td>\n",
       "      <td>0.036669</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.356206</td>\n",
       "      <td>0.031369</td>\n",
       "      <td>0.009693</td>\n",
       "      <td>2.368645e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_split': 200}</td>\n",
       "      <td>-0.010557</td>\n",
       "      <td>0.296004</td>\n",
       "      <td>0.019689</td>\n",
       "      <td>0.170777</td>\n",
       "      <td>0.069125</td>\n",
       "      <td>0.109008</td>\n",
       "      <td>0.111935</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.279994</td>\n",
       "      <td>0.048625</td>\n",
       "      <td>0.009506</td>\n",
       "      <td>3.164349e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>400</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_split': 400}</td>\n",
       "      <td>0.113768</td>\n",
       "      <td>0.130487</td>\n",
       "      <td>0.118893</td>\n",
       "      <td>0.048430</td>\n",
       "      <td>0.057261</td>\n",
       "      <td>0.093768</td>\n",
       "      <td>0.033964</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.214000</td>\n",
       "      <td>0.072770</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>3.159790e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>600</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_split': 600}</td>\n",
       "      <td>0.111213</td>\n",
       "      <td>0.164507</td>\n",
       "      <td>0.038175</td>\n",
       "      <td>0.107966</td>\n",
       "      <td>0.103015</td>\n",
       "      <td>0.104975</td>\n",
       "      <td>0.040145</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10.094700</td>\n",
       "      <td>0.082338</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>2.447172e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>800</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_split': 800}</td>\n",
       "      <td>0.060006</td>\n",
       "      <td>0.134277</td>\n",
       "      <td>0.115420</td>\n",
       "      <td>0.079457</td>\n",
       "      <td>0.104048</td>\n",
       "      <td>0.098641</td>\n",
       "      <td>0.026235</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.016399</td>\n",
       "      <td>0.083110</td>\n",
       "      <td>0.009301</td>\n",
       "      <td>2.455187e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_split': 1000}</td>\n",
       "      <td>-0.021156</td>\n",
       "      <td>0.103455</td>\n",
       "      <td>0.115996</td>\n",
       "      <td>0.030807</td>\n",
       "      <td>0.078367</td>\n",
       "      <td>0.061494</td>\n",
       "      <td>0.050574</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12.553001</td>\n",
       "      <td>0.149262</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>5.096687e-04</td>\n",
       "      <td>11</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 11, 'min_samples_split': 200}</td>\n",
       "      <td>0.008828</td>\n",
       "      <td>0.374623</td>\n",
       "      <td>0.161072</td>\n",
       "      <td>-0.065011</td>\n",
       "      <td>0.059164</td>\n",
       "      <td>0.107735</td>\n",
       "      <td>0.152353</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12.432300</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>2.449123e-04</td>\n",
       "      <td>11</td>\n",
       "      <td>400</td>\n",
       "      <td>{'max_depth': 11, 'min_samples_split': 400}</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>0.141266</td>\n",
       "      <td>0.037304</td>\n",
       "      <td>0.058065</td>\n",
       "      <td>0.029883</td>\n",
       "      <td>0.053702</td>\n",
       "      <td>0.047322</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12.174700</td>\n",
       "      <td>0.117575</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>2.448346e-04</td>\n",
       "      <td>11</td>\n",
       "      <td>600</td>\n",
       "      <td>{'max_depth': 11, 'min_samples_split': 600}</td>\n",
       "      <td>0.088881</td>\n",
       "      <td>0.082924</td>\n",
       "      <td>0.202418</td>\n",
       "      <td>0.102688</td>\n",
       "      <td>0.057216</td>\n",
       "      <td>0.106826</td>\n",
       "      <td>0.050019</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>12.102301</td>\n",
       "      <td>0.139566</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>1.998431e-04</td>\n",
       "      <td>11</td>\n",
       "      <td>800</td>\n",
       "      <td>{'max_depth': 11, 'min_samples_split': 800}</td>\n",
       "      <td>0.020568</td>\n",
       "      <td>0.164161</td>\n",
       "      <td>0.040744</td>\n",
       "      <td>0.042810</td>\n",
       "      <td>0.130255</td>\n",
       "      <td>0.079708</td>\n",
       "      <td>0.056683</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11.992999</td>\n",
       "      <td>0.096893</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.907349e-07</td>\n",
       "      <td>11</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 11, 'min_samples_split': 1000}</td>\n",
       "      <td>0.039272</td>\n",
       "      <td>0.221768</td>\n",
       "      <td>0.191764</td>\n",
       "      <td>0.093122</td>\n",
       "      <td>-0.024327</td>\n",
       "      <td>0.104320</td>\n",
       "      <td>0.092029</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14.553107</td>\n",
       "      <td>0.139192</td>\n",
       "      <td>0.014993</td>\n",
       "      <td>1.182614e-05</td>\n",
       "      <td>13</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 13, 'min_samples_split': 200}</td>\n",
       "      <td>-0.023817</td>\n",
       "      <td>0.271820</td>\n",
       "      <td>0.287305</td>\n",
       "      <td>0.053696</td>\n",
       "      <td>0.203536</td>\n",
       "      <td>0.158508</td>\n",
       "      <td>0.123031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>14.219100</td>\n",
       "      <td>0.091679</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>2.000811e-04</td>\n",
       "      <td>13</td>\n",
       "      <td>400</td>\n",
       "      <td>{'max_depth': 13, 'min_samples_split': 400}</td>\n",
       "      <td>-0.129020</td>\n",
       "      <td>0.328473</td>\n",
       "      <td>0.292782</td>\n",
       "      <td>-0.265709</td>\n",
       "      <td>0.200442</td>\n",
       "      <td>0.085394</td>\n",
       "      <td>0.238571</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>14.040206</td>\n",
       "      <td>0.063193</td>\n",
       "      <td>0.014494</td>\n",
       "      <td>3.261617e-04</td>\n",
       "      <td>13</td>\n",
       "      <td>600</td>\n",
       "      <td>{'max_depth': 13, 'min_samples_split': 600}</td>\n",
       "      <td>0.056616</td>\n",
       "      <td>0.182854</td>\n",
       "      <td>0.089875</td>\n",
       "      <td>0.181330</td>\n",
       "      <td>0.066695</td>\n",
       "      <td>0.115474</td>\n",
       "      <td>0.055454</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13.980600</td>\n",
       "      <td>0.118176</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>2.453207e-04</td>\n",
       "      <td>13</td>\n",
       "      <td>800</td>\n",
       "      <td>{'max_depth': 13, 'min_samples_split': 800}</td>\n",
       "      <td>0.106450</td>\n",
       "      <td>0.216720</td>\n",
       "      <td>0.072135</td>\n",
       "      <td>0.265365</td>\n",
       "      <td>0.053919</td>\n",
       "      <td>0.142918</td>\n",
       "      <td>0.083308</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>13.563201</td>\n",
       "      <td>0.194694</td>\n",
       "      <td>0.014104</td>\n",
       "      <td>1.983151e-04</td>\n",
       "      <td>13</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 13, 'min_samples_split': 1000}</td>\n",
       "      <td>0.038362</td>\n",
       "      <td>0.046166</td>\n",
       "      <td>0.075574</td>\n",
       "      <td>0.098126</td>\n",
       "      <td>0.126835</td>\n",
       "      <td>0.077013</td>\n",
       "      <td>0.032789</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16.423301</td>\n",
       "      <td>0.143645</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>2.444058e-04</td>\n",
       "      <td>15</td>\n",
       "      <td>200</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 200}</td>\n",
       "      <td>0.106938</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.105517</td>\n",
       "      <td>-0.118102</td>\n",
       "      <td>0.144509</td>\n",
       "      <td>0.094572</td>\n",
       "      <td>0.116135</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>16.180606</td>\n",
       "      <td>0.219165</td>\n",
       "      <td>0.016893</td>\n",
       "      <td>1.972922e-04</td>\n",
       "      <td>15</td>\n",
       "      <td>400</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 400}</td>\n",
       "      <td>0.013628</td>\n",
       "      <td>0.277475</td>\n",
       "      <td>0.107029</td>\n",
       "      <td>0.144527</td>\n",
       "      <td>0.055034</td>\n",
       "      <td>0.119539</td>\n",
       "      <td>0.090667</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>15.906100</td>\n",
       "      <td>0.186590</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>2.453403e-04</td>\n",
       "      <td>15</td>\n",
       "      <td>600</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 600}</td>\n",
       "      <td>0.055226</td>\n",
       "      <td>0.232455</td>\n",
       "      <td>0.047860</td>\n",
       "      <td>0.229135</td>\n",
       "      <td>0.052371</td>\n",
       "      <td>0.123410</td>\n",
       "      <td>0.087718</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15.645799</td>\n",
       "      <td>0.156174</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>1.999390e-04</td>\n",
       "      <td>15</td>\n",
       "      <td>800</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 800}</td>\n",
       "      <td>0.075282</td>\n",
       "      <td>0.241588</td>\n",
       "      <td>0.056144</td>\n",
       "      <td>0.071915</td>\n",
       "      <td>0.140324</td>\n",
       "      <td>0.117050</td>\n",
       "      <td>0.068619</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>15.484000</td>\n",
       "      <td>0.096147</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>1.997471e-04</td>\n",
       "      <td>15</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_split': 1000}</td>\n",
       "      <td>0.101218</td>\n",
       "      <td>0.078762</td>\n",
       "      <td>0.142334</td>\n",
       "      <td>0.077699</td>\n",
       "      <td>0.090562</td>\n",
       "      <td>0.098115</td>\n",
       "      <td>0.023720</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        5.976300      0.020635         0.004900    1.997233e-04   \n",
       "1        5.927600      0.016406         0.005100    1.996527e-04   \n",
       "2        5.913700      0.018304         0.005000    4.672031e-07   \n",
       "3        5.895799      0.037434         0.004900    1.999390e-04   \n",
       "4        5.861500      0.024740         0.005000    1.168008e-07   \n",
       "5        8.184200      0.027663         0.007401    2.003768e-04   \n",
       "6        8.090900      0.036839         0.007500    5.917394e-07   \n",
       "7        8.124500      0.086021         0.007401    1.998206e-04   \n",
       "8        8.046100      0.010777         0.007500    4.101908e-07   \n",
       "9        7.972900      0.037118         0.007100    1.999620e-04   \n",
       "10      10.356206      0.031369         0.009693    2.368645e-04   \n",
       "11      10.279994      0.048625         0.009506    3.164349e-04   \n",
       "12      10.214000      0.072770         0.009500    3.159790e-04   \n",
       "13      10.094700      0.082338         0.009300    2.447172e-04   \n",
       "14      10.016399      0.083110         0.009301    2.455187e-04   \n",
       "15      12.553001      0.149262         0.012800    5.096687e-04   \n",
       "16      12.432300      0.111374         0.012300    2.449123e-04   \n",
       "17      12.174700      0.117575         0.012300    2.448346e-04   \n",
       "18      12.102301      0.139566         0.012100    1.998431e-04   \n",
       "19      11.992999      0.096893         0.012000    1.907349e-07   \n",
       "20      14.553107      0.139192         0.014993    1.182614e-05   \n",
       "21      14.219100      0.091679         0.014600    2.000811e-04   \n",
       "22      14.040206      0.063193         0.014494    3.261617e-04   \n",
       "23      13.980600      0.118176         0.014200    2.453207e-04   \n",
       "24      13.563201      0.194694         0.014104    1.983151e-04   \n",
       "25      16.423301      0.143645         0.017200    2.444058e-04   \n",
       "26      16.180606      0.219165         0.016893    1.972922e-04   \n",
       "27      15.906100      0.186590         0.016700    2.453403e-04   \n",
       "28      15.645799      0.156174         0.016600    1.999390e-04   \n",
       "29      15.484000      0.096147         0.016600    1.997471e-04   \n",
       "\n",
       "   param_max_depth param_min_samples_split  \\\n",
       "0                5                     200   \n",
       "1                5                     400   \n",
       "2                5                     600   \n",
       "3                5                     800   \n",
       "4                5                    1000   \n",
       "5                7                     200   \n",
       "6                7                     400   \n",
       "7                7                     600   \n",
       "8                7                     800   \n",
       "9                7                    1000   \n",
       "10               9                     200   \n",
       "11               9                     400   \n",
       "12               9                     600   \n",
       "13               9                     800   \n",
       "14               9                    1000   \n",
       "15              11                     200   \n",
       "16              11                     400   \n",
       "17              11                     600   \n",
       "18              11                     800   \n",
       "19              11                    1000   \n",
       "20              13                     200   \n",
       "21              13                     400   \n",
       "22              13                     600   \n",
       "23              13                     800   \n",
       "24              13                    1000   \n",
       "25              15                     200   \n",
       "26              15                     400   \n",
       "27              15                     600   \n",
       "28              15                     800   \n",
       "29              15                    1000   \n",
       "\n",
       "                                          params  split0_test_score  \\\n",
       "0     {'max_depth': 5, 'min_samples_split': 200}          -0.027027   \n",
       "1     {'max_depth': 5, 'min_samples_split': 400}           0.150060   \n",
       "2     {'max_depth': 5, 'min_samples_split': 600}           0.036617   \n",
       "3     {'max_depth': 5, 'min_samples_split': 800}           0.073109   \n",
       "4    {'max_depth': 5, 'min_samples_split': 1000}          -0.015085   \n",
       "5     {'max_depth': 7, 'min_samples_split': 200}           0.001647   \n",
       "6     {'max_depth': 7, 'min_samples_split': 400}           0.020567   \n",
       "7     {'max_depth': 7, 'min_samples_split': 600}           0.214389   \n",
       "8     {'max_depth': 7, 'min_samples_split': 800}           0.037810   \n",
       "9    {'max_depth': 7, 'min_samples_split': 1000}           0.055833   \n",
       "10    {'max_depth': 9, 'min_samples_split': 200}          -0.010557   \n",
       "11    {'max_depth': 9, 'min_samples_split': 400}           0.113768   \n",
       "12    {'max_depth': 9, 'min_samples_split': 600}           0.111213   \n",
       "13    {'max_depth': 9, 'min_samples_split': 800}           0.060006   \n",
       "14   {'max_depth': 9, 'min_samples_split': 1000}          -0.021156   \n",
       "15   {'max_depth': 11, 'min_samples_split': 200}           0.008828   \n",
       "16   {'max_depth': 11, 'min_samples_split': 400}           0.001992   \n",
       "17   {'max_depth': 11, 'min_samples_split': 600}           0.088881   \n",
       "18   {'max_depth': 11, 'min_samples_split': 800}           0.020568   \n",
       "19  {'max_depth': 11, 'min_samples_split': 1000}           0.039272   \n",
       "20   {'max_depth': 13, 'min_samples_split': 200}          -0.023817   \n",
       "21   {'max_depth': 13, 'min_samples_split': 400}          -0.129020   \n",
       "22   {'max_depth': 13, 'min_samples_split': 600}           0.056616   \n",
       "23   {'max_depth': 13, 'min_samples_split': 800}           0.106450   \n",
       "24  {'max_depth': 13, 'min_samples_split': 1000}           0.038362   \n",
       "25   {'max_depth': 15, 'min_samples_split': 200}           0.106938   \n",
       "26   {'max_depth': 15, 'min_samples_split': 400}           0.013628   \n",
       "27   {'max_depth': 15, 'min_samples_split': 600}           0.055226   \n",
       "28   {'max_depth': 15, 'min_samples_split': 800}           0.075282   \n",
       "29  {'max_depth': 15, 'min_samples_split': 1000}           0.101218   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.114974           0.121019           0.069402   \n",
       "1            0.108152           0.109629           0.112724   \n",
       "2            0.151591           0.065702           0.089838   \n",
       "3            0.158742           0.126176           0.092763   \n",
       "4            0.152847           0.129067           0.063736   \n",
       "5            0.040350           0.106191          -0.014873   \n",
       "6            0.065764           0.072388           0.129819   \n",
       "7            0.089894          -0.007833           0.161594   \n",
       "8            0.175360           0.067908          -0.043263   \n",
       "9            0.141944           0.035934           0.071006   \n",
       "10           0.296004           0.019689           0.170777   \n",
       "11           0.130487           0.118893           0.048430   \n",
       "12           0.164507           0.038175           0.107966   \n",
       "13           0.134277           0.115420           0.079457   \n",
       "14           0.103455           0.115996           0.030807   \n",
       "15           0.374623           0.161072          -0.065011   \n",
       "16           0.141266           0.037304           0.058065   \n",
       "17           0.082924           0.202418           0.102688   \n",
       "18           0.164161           0.040744           0.042810   \n",
       "19           0.221768           0.191764           0.093122   \n",
       "20           0.271820           0.287305           0.053696   \n",
       "21           0.328473           0.292782          -0.265709   \n",
       "22           0.182854           0.089875           0.181330   \n",
       "23           0.216720           0.072135           0.265365   \n",
       "24           0.046166           0.075574           0.098126   \n",
       "25           0.234000           0.105517          -0.118102   \n",
       "26           0.277475           0.107029           0.144527   \n",
       "27           0.232455           0.047860           0.229135   \n",
       "28           0.241588           0.056144           0.071915   \n",
       "29           0.078762           0.142334           0.077699   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.068009         0.069275        0.052994               27  \n",
       "1            0.107708         0.117655        0.016298                6  \n",
       "2            0.042129         0.077175        0.041720               22  \n",
       "3            0.062090         0.102576        0.035539               14  \n",
       "4            0.110985         0.088310        0.059388               19  \n",
       "5            0.041674         0.034998        0.041812               30  \n",
       "6            0.086573         0.075022        0.035197               25  \n",
       "7            0.139755         0.119560        0.075201                4  \n",
       "8            0.141355         0.075834        0.077319               24  \n",
       "9            0.055628         0.072069        0.036669               26  \n",
       "10           0.069125         0.109008        0.111935                9  \n",
       "11           0.057261         0.093768        0.033964               18  \n",
       "12           0.103015         0.104975        0.040145               12  \n",
       "13           0.104048         0.098641        0.026235               15  \n",
       "14           0.078367         0.061494        0.050574               28  \n",
       "15           0.059164         0.107735        0.152353               10  \n",
       "16           0.029883         0.053702        0.047322               29  \n",
       "17           0.057216         0.106826        0.050019               11  \n",
       "18           0.130255         0.079708        0.056683               21  \n",
       "19          -0.024327         0.104320        0.092029               13  \n",
       "20           0.203536         0.158508        0.123031                1  \n",
       "21           0.200442         0.085394        0.238571               20  \n",
       "22           0.066695         0.115474        0.055454                8  \n",
       "23           0.053919         0.142918        0.083308                2  \n",
       "24           0.126835         0.077013        0.032789               23  \n",
       "25           0.144509         0.094572        0.116135               17  \n",
       "26           0.055034         0.119539        0.090667                5  \n",
       "27           0.052371         0.123410        0.087718                3  \n",
       "28           0.140324         0.117050        0.068619                7  \n",
       "29           0.090562         0.098115        0.023720               16  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2 = pd.DataFrame(gsearch2.cv_results_)\n",
    "gs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb60143b-a44a-4e1a-8383-93fdaab9618c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=GradientBoostingRegressor(learning_rate=0.75,\n",
       "                                                 loss='absolute_error',\n",
       "                                                 max_depth=13,\n",
       "                                                 n_estimators=400),\n",
       "             param_grid={'min_samples_leaf': range(30, 71, 10),\n",
       "                         'min_samples_split': range(50, 300, 50)})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = {'min_samples_leaf':range(30,71,10), 'min_samples_split':range(50,300,50)}\n",
    "gb3 = GradientBoostingRegressor(n_estimators = 400, learning_rate = 0.75,max_depth = 13,loss='absolute_error')\n",
    "gsearch3 = GridSearchCV(gb3,param_test3)\n",
    "gsearch3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "164e515e-669b-451c-bc96-a58e51dedf3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.749017</td>\n",
       "      <td>0.048232</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>2.001288e-04</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>{'min_samples_leaf': 30, 'min_samples_split': 50}</td>\n",
       "      <td>0.144237</td>\n",
       "      <td>0.231891</td>\n",
       "      <td>0.116903</td>\n",
       "      <td>0.114104</td>\n",
       "      <td>0.242381</td>\n",
       "      <td>0.169903</td>\n",
       "      <td>0.055994</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.637500</td>\n",
       "      <td>0.028522</td>\n",
       "      <td>0.018701</td>\n",
       "      <td>2.446982e-04</td>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>{'min_samples_leaf': 30, 'min_samples_split': ...</td>\n",
       "      <td>0.175557</td>\n",
       "      <td>0.165445</td>\n",
       "      <td>0.099012</td>\n",
       "      <td>0.159973</td>\n",
       "      <td>0.147863</td>\n",
       "      <td>0.149570</td>\n",
       "      <td>0.026813</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.032101</td>\n",
       "      <td>0.055630</td>\n",
       "      <td>0.018099</td>\n",
       "      <td>1.989128e-04</td>\n",
       "      <td>30</td>\n",
       "      <td>150</td>\n",
       "      <td>{'min_samples_leaf': 30, 'min_samples_split': ...</td>\n",
       "      <td>0.192948</td>\n",
       "      <td>0.176930</td>\n",
       "      <td>0.056902</td>\n",
       "      <td>0.033756</td>\n",
       "      <td>0.099869</td>\n",
       "      <td>0.112081</td>\n",
       "      <td>0.063362</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.637394</td>\n",
       "      <td>0.037679</td>\n",
       "      <td>0.017506</td>\n",
       "      <td>3.263176e-04</td>\n",
       "      <td>30</td>\n",
       "      <td>200</td>\n",
       "      <td>{'min_samples_leaf': 30, 'min_samples_split': ...</td>\n",
       "      <td>0.170356</td>\n",
       "      <td>0.177364</td>\n",
       "      <td>0.127077</td>\n",
       "      <td>0.102368</td>\n",
       "      <td>0.192429</td>\n",
       "      <td>0.153919</td>\n",
       "      <td>0.033707</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.424400</td>\n",
       "      <td>0.035628</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>2.450680e-04</td>\n",
       "      <td>30</td>\n",
       "      <td>250</td>\n",
       "      <td>{'min_samples_leaf': 30, 'min_samples_split': ...</td>\n",
       "      <td>0.183195</td>\n",
       "      <td>0.180062</td>\n",
       "      <td>0.131931</td>\n",
       "      <td>0.115414</td>\n",
       "      <td>0.160992</td>\n",
       "      <td>0.154319</td>\n",
       "      <td>0.026668</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.791394</td>\n",
       "      <td>0.034594</td>\n",
       "      <td>0.019606</td>\n",
       "      <td>2.118828e-04</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>{'min_samples_leaf': 40, 'min_samples_split': 50}</td>\n",
       "      <td>0.073923</td>\n",
       "      <td>0.240715</td>\n",
       "      <td>0.069933</td>\n",
       "      <td>0.116140</td>\n",
       "      <td>0.046236</td>\n",
       "      <td>0.109389</td>\n",
       "      <td>0.069419</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13.311000</td>\n",
       "      <td>0.046635</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>1.998664e-04</td>\n",
       "      <td>40</td>\n",
       "      <td>100</td>\n",
       "      <td>{'min_samples_leaf': 40, 'min_samples_split': ...</td>\n",
       "      <td>0.095636</td>\n",
       "      <td>0.192234</td>\n",
       "      <td>0.125183</td>\n",
       "      <td>0.067103</td>\n",
       "      <td>0.094114</td>\n",
       "      <td>0.114854</td>\n",
       "      <td>0.042835</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.592900</td>\n",
       "      <td>0.041043</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>3.015783e-07</td>\n",
       "      <td>40</td>\n",
       "      <td>150</td>\n",
       "      <td>{'min_samples_leaf': 40, 'min_samples_split': ...</td>\n",
       "      <td>0.157583</td>\n",
       "      <td>0.208531</td>\n",
       "      <td>0.064004</td>\n",
       "      <td>0.022155</td>\n",
       "      <td>0.134266</td>\n",
       "      <td>0.117308</td>\n",
       "      <td>0.066523</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12.234105</td>\n",
       "      <td>0.061120</td>\n",
       "      <td>0.017795</td>\n",
       "      <td>4.047910e-04</td>\n",
       "      <td>40</td>\n",
       "      <td>200</td>\n",
       "      <td>{'min_samples_leaf': 40, 'min_samples_split': ...</td>\n",
       "      <td>0.083352</td>\n",
       "      <td>0.138460</td>\n",
       "      <td>0.068598</td>\n",
       "      <td>0.097431</td>\n",
       "      <td>0.070738</td>\n",
       "      <td>0.091716</td>\n",
       "      <td>0.025543</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.891201</td>\n",
       "      <td>0.051611</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>2.448729e-04</td>\n",
       "      <td>40</td>\n",
       "      <td>250</td>\n",
       "      <td>{'min_samples_leaf': 40, 'min_samples_split': ...</td>\n",
       "      <td>0.076917</td>\n",
       "      <td>0.177669</td>\n",
       "      <td>0.061720</td>\n",
       "      <td>0.157434</td>\n",
       "      <td>0.088994</td>\n",
       "      <td>0.112547</td>\n",
       "      <td>0.046181</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12.988994</td>\n",
       "      <td>0.058738</td>\n",
       "      <td>0.019606</td>\n",
       "      <td>1.972039e-04</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>{'min_samples_leaf': 50, 'min_samples_split': 50}</td>\n",
       "      <td>0.083744</td>\n",
       "      <td>0.164369</td>\n",
       "      <td>0.129310</td>\n",
       "      <td>0.076730</td>\n",
       "      <td>0.100435</td>\n",
       "      <td>0.110918</td>\n",
       "      <td>0.032287</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.953300</td>\n",
       "      <td>0.063495</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>2.002005e-04</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>{'min_samples_leaf': 50, 'min_samples_split': ...</td>\n",
       "      <td>0.116149</td>\n",
       "      <td>0.147472</td>\n",
       "      <td>0.093654</td>\n",
       "      <td>0.062768</td>\n",
       "      <td>0.088394</td>\n",
       "      <td>0.101687</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.253600</td>\n",
       "      <td>0.031163</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>4.002693e-04</td>\n",
       "      <td>50</td>\n",
       "      <td>150</td>\n",
       "      <td>{'min_samples_leaf': 50, 'min_samples_split': ...</td>\n",
       "      <td>0.063765</td>\n",
       "      <td>0.194140</td>\n",
       "      <td>0.057062</td>\n",
       "      <td>0.098168</td>\n",
       "      <td>0.122642</td>\n",
       "      <td>0.107156</td>\n",
       "      <td>0.049556</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11.855600</td>\n",
       "      <td>0.051927</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>2.451456e-04</td>\n",
       "      <td>50</td>\n",
       "      <td>200</td>\n",
       "      <td>{'min_samples_leaf': 50, 'min_samples_split': ...</td>\n",
       "      <td>0.094313</td>\n",
       "      <td>0.179236</td>\n",
       "      <td>0.074924</td>\n",
       "      <td>0.118292</td>\n",
       "      <td>0.070750</td>\n",
       "      <td>0.107503</td>\n",
       "      <td>0.039618</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11.529500</td>\n",
       "      <td>0.061684</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>1.997715e-04</td>\n",
       "      <td>50</td>\n",
       "      <td>250</td>\n",
       "      <td>{'min_samples_leaf': 50, 'min_samples_split': ...</td>\n",
       "      <td>0.080756</td>\n",
       "      <td>0.139393</td>\n",
       "      <td>0.080223</td>\n",
       "      <td>0.077279</td>\n",
       "      <td>0.099677</td>\n",
       "      <td>0.095466</td>\n",
       "      <td>0.023353</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12.435100</td>\n",
       "      <td>0.084468</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>2.456519e-04</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>{'min_samples_leaf': 60, 'min_samples_split': 50}</td>\n",
       "      <td>0.065396</td>\n",
       "      <td>0.165707</td>\n",
       "      <td>0.058459</td>\n",
       "      <td>0.098317</td>\n",
       "      <td>0.094894</td>\n",
       "      <td>0.096554</td>\n",
       "      <td>0.037974</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12.395100</td>\n",
       "      <td>0.050329</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>1.999858e-04</td>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>{'min_samples_leaf': 60, 'min_samples_split': ...</td>\n",
       "      <td>0.056167</td>\n",
       "      <td>0.125079</td>\n",
       "      <td>0.081867</td>\n",
       "      <td>0.077389</td>\n",
       "      <td>0.102573</td>\n",
       "      <td>0.088615</td>\n",
       "      <td>0.023447</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12.030799</td>\n",
       "      <td>0.058768</td>\n",
       "      <td>0.019301</td>\n",
       "      <td>2.452236e-04</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>{'min_samples_leaf': 60, 'min_samples_split': ...</td>\n",
       "      <td>0.062032</td>\n",
       "      <td>0.136690</td>\n",
       "      <td>0.050872</td>\n",
       "      <td>0.094679</td>\n",
       "      <td>0.116571</td>\n",
       "      <td>0.092169</td>\n",
       "      <td>0.032241</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11.541601</td>\n",
       "      <td>0.076959</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>2.004873e-04</td>\n",
       "      <td>60</td>\n",
       "      <td>200</td>\n",
       "      <td>{'min_samples_leaf': 60, 'min_samples_split': ...</td>\n",
       "      <td>0.078557</td>\n",
       "      <td>0.143576</td>\n",
       "      <td>0.064254</td>\n",
       "      <td>0.094673</td>\n",
       "      <td>0.093030</td>\n",
       "      <td>0.094818</td>\n",
       "      <td>0.026755</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11.246701</td>\n",
       "      <td>0.060781</td>\n",
       "      <td>0.017799</td>\n",
       "      <td>2.446229e-04</td>\n",
       "      <td>60</td>\n",
       "      <td>250</td>\n",
       "      <td>{'min_samples_leaf': 60, 'min_samples_split': ...</td>\n",
       "      <td>0.083639</td>\n",
       "      <td>0.151119</td>\n",
       "      <td>0.064515</td>\n",
       "      <td>0.110572</td>\n",
       "      <td>0.089084</td>\n",
       "      <td>0.099786</td>\n",
       "      <td>0.029566</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11.784800</td>\n",
       "      <td>0.050780</td>\n",
       "      <td>0.019601</td>\n",
       "      <td>1.994960e-04</td>\n",
       "      <td>70</td>\n",
       "      <td>50</td>\n",
       "      <td>{'min_samples_leaf': 70, 'min_samples_split': 50}</td>\n",
       "      <td>0.066420</td>\n",
       "      <td>0.099233</td>\n",
       "      <td>0.051342</td>\n",
       "      <td>0.081437</td>\n",
       "      <td>0.102631</td>\n",
       "      <td>0.080213</td>\n",
       "      <td>0.019440</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11.755088</td>\n",
       "      <td>0.094193</td>\n",
       "      <td>0.019313</td>\n",
       "      <td>2.426727e-04</td>\n",
       "      <td>70</td>\n",
       "      <td>100</td>\n",
       "      <td>{'min_samples_leaf': 70, 'min_samples_split': ...</td>\n",
       "      <td>0.058246</td>\n",
       "      <td>0.103548</td>\n",
       "      <td>0.073365</td>\n",
       "      <td>0.077827</td>\n",
       "      <td>0.139080</td>\n",
       "      <td>0.090413</td>\n",
       "      <td>0.028372</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11.591699</td>\n",
       "      <td>0.059189</td>\n",
       "      <td>0.019300</td>\n",
       "      <td>2.452238e-04</td>\n",
       "      <td>70</td>\n",
       "      <td>150</td>\n",
       "      <td>{'min_samples_leaf': 70, 'min_samples_split': ...</td>\n",
       "      <td>0.060772</td>\n",
       "      <td>0.104719</td>\n",
       "      <td>0.075018</td>\n",
       "      <td>0.068272</td>\n",
       "      <td>0.103526</td>\n",
       "      <td>0.082461</td>\n",
       "      <td>0.018255</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11.110500</td>\n",
       "      <td>0.071564</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>2.452040e-04</td>\n",
       "      <td>70</td>\n",
       "      <td>200</td>\n",
       "      <td>{'min_samples_leaf': 70, 'min_samples_split': ...</td>\n",
       "      <td>0.092932</td>\n",
       "      <td>0.105967</td>\n",
       "      <td>0.072765</td>\n",
       "      <td>0.054503</td>\n",
       "      <td>0.101430</td>\n",
       "      <td>0.085520</td>\n",
       "      <td>0.019240</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10.732600</td>\n",
       "      <td>0.125985</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>2.447950e-04</td>\n",
       "      <td>70</td>\n",
       "      <td>250</td>\n",
       "      <td>{'min_samples_leaf': 70, 'min_samples_split': ...</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.083825</td>\n",
       "      <td>0.087132</td>\n",
       "      <td>0.094021</td>\n",
       "      <td>0.104974</td>\n",
       "      <td>0.089591</td>\n",
       "      <td>0.009273</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       14.749017      0.048232         0.019900    2.001288e-04   \n",
       "1       13.637500      0.028522         0.018701    2.446982e-04   \n",
       "2       13.032101      0.055630         0.018099    1.989128e-04   \n",
       "3       12.637394      0.037679         0.017506    3.263176e-04   \n",
       "4       12.424400      0.035628         0.017200    2.450680e-04   \n",
       "5       13.791394      0.034594         0.019606    2.118828e-04   \n",
       "6       13.311000      0.046635         0.019400    1.998664e-04   \n",
       "7       12.592900      0.041043         0.018500    3.015783e-07   \n",
       "8       12.234105      0.061120         0.017795    4.047910e-04   \n",
       "9       11.891201      0.051611         0.017300    2.448729e-04   \n",
       "10      12.988994      0.058738         0.019606    1.972039e-04   \n",
       "11      12.953300      0.063495         0.019400    2.002005e-04   \n",
       "12      12.253600      0.031163         0.018800    4.002693e-04   \n",
       "13      11.855600      0.051927         0.018200    2.451456e-04   \n",
       "14      11.529500      0.061684         0.017600    1.997715e-04   \n",
       "15      12.435100      0.084468         0.019700    2.456519e-04   \n",
       "16      12.395100      0.050329         0.019600    1.999858e-04   \n",
       "17      12.030799      0.058768         0.019301    2.452236e-04   \n",
       "18      11.541601      0.076959         0.018400    2.004873e-04   \n",
       "19      11.246701      0.060781         0.017799    2.446229e-04   \n",
       "20      11.784800      0.050780         0.019601    1.994960e-04   \n",
       "21      11.755088      0.094193         0.019313    2.426727e-04   \n",
       "22      11.591699      0.059189         0.019300    2.452238e-04   \n",
       "23      11.110500      0.071564         0.018200    2.452040e-04   \n",
       "24      10.732600      0.125985         0.017700    2.447950e-04   \n",
       "\n",
       "   param_min_samples_leaf param_min_samples_split  \\\n",
       "0                      30                      50   \n",
       "1                      30                     100   \n",
       "2                      30                     150   \n",
       "3                      30                     200   \n",
       "4                      30                     250   \n",
       "5                      40                      50   \n",
       "6                      40                     100   \n",
       "7                      40                     150   \n",
       "8                      40                     200   \n",
       "9                      40                     250   \n",
       "10                     50                      50   \n",
       "11                     50                     100   \n",
       "12                     50                     150   \n",
       "13                     50                     200   \n",
       "14                     50                     250   \n",
       "15                     60                      50   \n",
       "16                     60                     100   \n",
       "17                     60                     150   \n",
       "18                     60                     200   \n",
       "19                     60                     250   \n",
       "20                     70                      50   \n",
       "21                     70                     100   \n",
       "22                     70                     150   \n",
       "23                     70                     200   \n",
       "24                     70                     250   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'min_samples_leaf': 30, 'min_samples_split': 50}           0.144237   \n",
       "1   {'min_samples_leaf': 30, 'min_samples_split': ...           0.175557   \n",
       "2   {'min_samples_leaf': 30, 'min_samples_split': ...           0.192948   \n",
       "3   {'min_samples_leaf': 30, 'min_samples_split': ...           0.170356   \n",
       "4   {'min_samples_leaf': 30, 'min_samples_split': ...           0.183195   \n",
       "5   {'min_samples_leaf': 40, 'min_samples_split': 50}           0.073923   \n",
       "6   {'min_samples_leaf': 40, 'min_samples_split': ...           0.095636   \n",
       "7   {'min_samples_leaf': 40, 'min_samples_split': ...           0.157583   \n",
       "8   {'min_samples_leaf': 40, 'min_samples_split': ...           0.083352   \n",
       "9   {'min_samples_leaf': 40, 'min_samples_split': ...           0.076917   \n",
       "10  {'min_samples_leaf': 50, 'min_samples_split': 50}           0.083744   \n",
       "11  {'min_samples_leaf': 50, 'min_samples_split': ...           0.116149   \n",
       "12  {'min_samples_leaf': 50, 'min_samples_split': ...           0.063765   \n",
       "13  {'min_samples_leaf': 50, 'min_samples_split': ...           0.094313   \n",
       "14  {'min_samples_leaf': 50, 'min_samples_split': ...           0.080756   \n",
       "15  {'min_samples_leaf': 60, 'min_samples_split': 50}           0.065396   \n",
       "16  {'min_samples_leaf': 60, 'min_samples_split': ...           0.056167   \n",
       "17  {'min_samples_leaf': 60, 'min_samples_split': ...           0.062032   \n",
       "18  {'min_samples_leaf': 60, 'min_samples_split': ...           0.078557   \n",
       "19  {'min_samples_leaf': 60, 'min_samples_split': ...           0.083639   \n",
       "20  {'min_samples_leaf': 70, 'min_samples_split': 50}           0.066420   \n",
       "21  {'min_samples_leaf': 70, 'min_samples_split': ...           0.058246   \n",
       "22  {'min_samples_leaf': 70, 'min_samples_split': ...           0.060772   \n",
       "23  {'min_samples_leaf': 70, 'min_samples_split': ...           0.092932   \n",
       "24  {'min_samples_leaf': 70, 'min_samples_split': ...           0.078000   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.231891           0.116903           0.114104   \n",
       "1            0.165445           0.099012           0.159973   \n",
       "2            0.176930           0.056902           0.033756   \n",
       "3            0.177364           0.127077           0.102368   \n",
       "4            0.180062           0.131931           0.115414   \n",
       "5            0.240715           0.069933           0.116140   \n",
       "6            0.192234           0.125183           0.067103   \n",
       "7            0.208531           0.064004           0.022155   \n",
       "8            0.138460           0.068598           0.097431   \n",
       "9            0.177669           0.061720           0.157434   \n",
       "10           0.164369           0.129310           0.076730   \n",
       "11           0.147472           0.093654           0.062768   \n",
       "12           0.194140           0.057062           0.098168   \n",
       "13           0.179236           0.074924           0.118292   \n",
       "14           0.139393           0.080223           0.077279   \n",
       "15           0.165707           0.058459           0.098317   \n",
       "16           0.125079           0.081867           0.077389   \n",
       "17           0.136690           0.050872           0.094679   \n",
       "18           0.143576           0.064254           0.094673   \n",
       "19           0.151119           0.064515           0.110572   \n",
       "20           0.099233           0.051342           0.081437   \n",
       "21           0.103548           0.073365           0.077827   \n",
       "22           0.104719           0.075018           0.068272   \n",
       "23           0.105967           0.072765           0.054503   \n",
       "24           0.083825           0.087132           0.094021   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.242381         0.169903        0.055994                1  \n",
       "1            0.147863         0.149570        0.026813                4  \n",
       "2            0.099869         0.112081        0.063362                8  \n",
       "3            0.192429         0.153919        0.033707                3  \n",
       "4            0.160992         0.154319        0.026668                2  \n",
       "5            0.046236         0.109389        0.069419               10  \n",
       "6            0.094114         0.114854        0.042835                6  \n",
       "7            0.134266         0.117308        0.066523                5  \n",
       "8            0.070738         0.091716        0.025543               19  \n",
       "9            0.088994         0.112547        0.046181                7  \n",
       "10           0.100435         0.110918        0.032287                9  \n",
       "11           0.088394         0.101687        0.028500               13  \n",
       "12           0.122642         0.107156        0.049556               12  \n",
       "13           0.070750         0.107503        0.039618               11  \n",
       "14           0.099677         0.095466        0.023353               16  \n",
       "15           0.094894         0.096554        0.037974               15  \n",
       "16           0.102573         0.088615        0.023447               22  \n",
       "17           0.116571         0.092169        0.032241               18  \n",
       "18           0.093030         0.094818        0.026755               17  \n",
       "19           0.089084         0.099786        0.029566               14  \n",
       "20           0.102631         0.080213        0.019440               25  \n",
       "21           0.139080         0.090413        0.028372               20  \n",
       "22           0.103526         0.082461        0.018255               24  \n",
       "23           0.101430         0.085520        0.019240               23  \n",
       "24           0.104974         0.089591        0.009273               21  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs3 = pd.DataFrame(gsearch3.cv_results_)\n",
    "gs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "052e641e-4a38-4c9b-a86a-666c85a8ef6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=GradientBoostingRegressor(learning_rate=0.75,\n",
       "                                                 loss='absolute_error',\n",
       "                                                 max_depth=13,\n",
       "                                                 min_samples_leaf=30,\n",
       "                                                 n_estimators=400),\n",
       "             param_grid={'max_features': range(5, 22, 2),\n",
       "                         'min_samples_split': range(20, 61, 10)})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test4 = {'max_features':range(5,22,2), 'min_samples_split':range(20,61,10)}\n",
    "gb4 = GradientBoostingRegressor(n_estimators = 400, learning_rate = 0.75,max_depth = 13,min_samples_leaf = 30,loss='absolute_error')\n",
    "gsearch4 = GridSearchCV(gb4,param_test4)\n",
    "gsearch4.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "398b0461-7dca-4f31-844f-b76037ec1edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.840935</td>\n",
       "      <td>0.045032</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>1.482036e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_features': 5, 'min_samples_split': 20}</td>\n",
       "      <td>0.279298</td>\n",
       "      <td>0.137664</td>\n",
       "      <td>0.231177</td>\n",
       "      <td>0.071693</td>\n",
       "      <td>0.155947</td>\n",
       "      <td>0.175156</td>\n",
       "      <td>0.072750</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.795099</td>\n",
       "      <td>0.061112</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>2.001538e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_features': 5, 'min_samples_split': 30}</td>\n",
       "      <td>0.171970</td>\n",
       "      <td>0.180735</td>\n",
       "      <td>0.142996</td>\n",
       "      <td>0.108361</td>\n",
       "      <td>0.206041</td>\n",
       "      <td>0.162021</td>\n",
       "      <td>0.033551</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.866700</td>\n",
       "      <td>0.086372</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>2.449900e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_features': 5, 'min_samples_split': 40}</td>\n",
       "      <td>0.108827</td>\n",
       "      <td>0.195997</td>\n",
       "      <td>0.145112</td>\n",
       "      <td>0.084844</td>\n",
       "      <td>0.106528</td>\n",
       "      <td>0.128262</td>\n",
       "      <td>0.039005</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.841000</td>\n",
       "      <td>0.082566</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>2.447173e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 5, 'min_samples_split': 50}</td>\n",
       "      <td>0.158150</td>\n",
       "      <td>0.233831</td>\n",
       "      <td>0.168044</td>\n",
       "      <td>0.049186</td>\n",
       "      <td>0.151127</td>\n",
       "      <td>0.152067</td>\n",
       "      <td>0.059267</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.842800</td>\n",
       "      <td>0.040739</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>3.746359e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_features': 5, 'min_samples_split': 60}</td>\n",
       "      <td>0.265140</td>\n",
       "      <td>0.197384</td>\n",
       "      <td>0.081775</td>\n",
       "      <td>0.112971</td>\n",
       "      <td>0.232618</td>\n",
       "      <td>0.177978</td>\n",
       "      <td>0.069915</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.769200</td>\n",
       "      <td>0.070845</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>2.002244e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_features': 7, 'min_samples_split': 20}</td>\n",
       "      <td>0.136932</td>\n",
       "      <td>0.165608</td>\n",
       "      <td>0.079034</td>\n",
       "      <td>0.145197</td>\n",
       "      <td>0.189129</td>\n",
       "      <td>0.143180</td>\n",
       "      <td>0.036803</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.792600</td>\n",
       "      <td>0.029737</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>1.998191e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_features': 7, 'min_samples_split': 30}</td>\n",
       "      <td>0.270094</td>\n",
       "      <td>0.242974</td>\n",
       "      <td>0.171519</td>\n",
       "      <td>0.186615</td>\n",
       "      <td>0.214635</td>\n",
       "      <td>0.217167</td>\n",
       "      <td>0.036030</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.764700</td>\n",
       "      <td>0.073404</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>1.999866e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_features': 7, 'min_samples_split': 40}</td>\n",
       "      <td>0.232672</td>\n",
       "      <td>0.102094</td>\n",
       "      <td>0.223320</td>\n",
       "      <td>0.123754</td>\n",
       "      <td>0.168009</td>\n",
       "      <td>0.169970</td>\n",
       "      <td>0.052009</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.745800</td>\n",
       "      <td>0.052959</td>\n",
       "      <td>0.020901</td>\n",
       "      <td>3.737692e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 7, 'min_samples_split': 50}</td>\n",
       "      <td>0.260801</td>\n",
       "      <td>0.175275</td>\n",
       "      <td>0.101682</td>\n",
       "      <td>0.064109</td>\n",
       "      <td>0.174569</td>\n",
       "      <td>0.155287</td>\n",
       "      <td>0.067958</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.724601</td>\n",
       "      <td>0.033882</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>2.452827e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_features': 7, 'min_samples_split': 60}</td>\n",
       "      <td>0.242187</td>\n",
       "      <td>0.229385</td>\n",
       "      <td>0.127572</td>\n",
       "      <td>0.155512</td>\n",
       "      <td>0.209318</td>\n",
       "      <td>0.192795</td>\n",
       "      <td>0.044035</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.661100</td>\n",
       "      <td>0.066702</td>\n",
       "      <td>0.020399</td>\n",
       "      <td>2.006544e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_features': 9, 'min_samples_split': 20}</td>\n",
       "      <td>0.180168</td>\n",
       "      <td>0.172226</td>\n",
       "      <td>0.062213</td>\n",
       "      <td>0.144689</td>\n",
       "      <td>0.103027</td>\n",
       "      <td>0.132465</td>\n",
       "      <td>0.044290</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8.674600</td>\n",
       "      <td>0.033572</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>2.005348e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_features': 9, 'min_samples_split': 30}</td>\n",
       "      <td>0.170207</td>\n",
       "      <td>0.237364</td>\n",
       "      <td>0.116158</td>\n",
       "      <td>0.049706</td>\n",
       "      <td>0.185393</td>\n",
       "      <td>0.151766</td>\n",
       "      <td>0.064003</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8.626700</td>\n",
       "      <td>0.033998</td>\n",
       "      <td>0.020600</td>\n",
       "      <td>3.741770e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_features': 9, 'min_samples_split': 40}</td>\n",
       "      <td>0.118393</td>\n",
       "      <td>0.168513</td>\n",
       "      <td>0.152208</td>\n",
       "      <td>-0.077973</td>\n",
       "      <td>0.093807</td>\n",
       "      <td>0.090990</td>\n",
       "      <td>0.088391</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8.698500</td>\n",
       "      <td>0.057282</td>\n",
       "      <td>0.020600</td>\n",
       "      <td>2.001287e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 9, 'min_samples_split': 50}</td>\n",
       "      <td>0.254127</td>\n",
       "      <td>0.200092</td>\n",
       "      <td>0.182426</td>\n",
       "      <td>0.079890</td>\n",
       "      <td>0.103486</td>\n",
       "      <td>0.164004</td>\n",
       "      <td>0.064034</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.802100</td>\n",
       "      <td>0.096014</td>\n",
       "      <td>0.021101</td>\n",
       "      <td>4.906413e-04</td>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_features': 9, 'min_samples_split': 60}</td>\n",
       "      <td>0.141062</td>\n",
       "      <td>0.165517</td>\n",
       "      <td>0.133269</td>\n",
       "      <td>0.160077</td>\n",
       "      <td>0.185429</td>\n",
       "      <td>0.157071</td>\n",
       "      <td>0.018479</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9.752500</td>\n",
       "      <td>0.090546</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>3.741261e-04</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_features': 11, 'min_samples_split': 20}</td>\n",
       "      <td>0.274224</td>\n",
       "      <td>0.192387</td>\n",
       "      <td>0.130154</td>\n",
       "      <td>0.110168</td>\n",
       "      <td>0.151876</td>\n",
       "      <td>0.171762</td>\n",
       "      <td>0.058042</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9.826947</td>\n",
       "      <td>0.022426</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>5.829715e-04</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_features': 11, 'min_samples_split': 30}</td>\n",
       "      <td>0.105436</td>\n",
       "      <td>0.126117</td>\n",
       "      <td>0.155596</td>\n",
       "      <td>0.122280</td>\n",
       "      <td>0.153797</td>\n",
       "      <td>0.132645</td>\n",
       "      <td>0.019311</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.748100</td>\n",
       "      <td>0.075691</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>2.451859e-04</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_features': 11, 'min_samples_split': 40}</td>\n",
       "      <td>0.202204</td>\n",
       "      <td>0.186812</td>\n",
       "      <td>0.193754</td>\n",
       "      <td>0.114186</td>\n",
       "      <td>0.204625</td>\n",
       "      <td>0.180316</td>\n",
       "      <td>0.033663</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.718400</td>\n",
       "      <td>0.047904</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>3.744449e-04</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 11, 'min_samples_split': 50}</td>\n",
       "      <td>0.192076</td>\n",
       "      <td>0.242212</td>\n",
       "      <td>0.105066</td>\n",
       "      <td>0.079139</td>\n",
       "      <td>0.180447</td>\n",
       "      <td>0.159788</td>\n",
       "      <td>0.059602</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9.717100</td>\n",
       "      <td>0.046496</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>2.451265e-04</td>\n",
       "      <td>11</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_features': 11, 'min_samples_split': 60}</td>\n",
       "      <td>0.159286</td>\n",
       "      <td>0.172427</td>\n",
       "      <td>0.175208</td>\n",
       "      <td>0.163030</td>\n",
       "      <td>0.233379</td>\n",
       "      <td>0.180666</td>\n",
       "      <td>0.026998</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10.689800</td>\n",
       "      <td>0.054377</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>2.449514e-04</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_features': 13, 'min_samples_split': 20}</td>\n",
       "      <td>0.236218</td>\n",
       "      <td>0.227418</td>\n",
       "      <td>0.125693</td>\n",
       "      <td>0.196195</td>\n",
       "      <td>0.164355</td>\n",
       "      <td>0.189976</td>\n",
       "      <td>0.040909</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10.684699</td>\n",
       "      <td>0.065242</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>2.451291e-04</td>\n",
       "      <td>13</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_features': 13, 'min_samples_split': 30}</td>\n",
       "      <td>0.105093</td>\n",
       "      <td>0.176166</td>\n",
       "      <td>0.138130</td>\n",
       "      <td>0.133043</td>\n",
       "      <td>0.140711</td>\n",
       "      <td>0.138628</td>\n",
       "      <td>0.022669</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10.714701</td>\n",
       "      <td>0.039467</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>4.623108e-07</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_features': 13, 'min_samples_split': 40}</td>\n",
       "      <td>0.114354</td>\n",
       "      <td>0.253530</td>\n",
       "      <td>0.141202</td>\n",
       "      <td>0.192599</td>\n",
       "      <td>0.169764</td>\n",
       "      <td>0.174290</td>\n",
       "      <td>0.047585</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10.643600</td>\n",
       "      <td>0.038874</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>2.445809e-04</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 13, 'min_samples_split': 50}</td>\n",
       "      <td>0.238717</td>\n",
       "      <td>0.197689</td>\n",
       "      <td>0.137068</td>\n",
       "      <td>0.091874</td>\n",
       "      <td>0.237630</td>\n",
       "      <td>0.180596</td>\n",
       "      <td>0.057774</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10.686100</td>\n",
       "      <td>0.034023</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>3.997327e-04</td>\n",
       "      <td>13</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_features': 13, 'min_samples_split': 60}</td>\n",
       "      <td>0.152916</td>\n",
       "      <td>0.222142</td>\n",
       "      <td>0.192422</td>\n",
       "      <td>0.164442</td>\n",
       "      <td>0.098900</td>\n",
       "      <td>0.166165</td>\n",
       "      <td>0.041294</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>11.679700</td>\n",
       "      <td>0.021440</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>3.739608e-04</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_features': 15, 'min_samples_split': 20}</td>\n",
       "      <td>0.096353</td>\n",
       "      <td>0.138444</td>\n",
       "      <td>0.193477</td>\n",
       "      <td>0.078312</td>\n",
       "      <td>0.132653</td>\n",
       "      <td>0.127848</td>\n",
       "      <td>0.039720</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>11.729500</td>\n",
       "      <td>0.039024</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>2.447185e-04</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_features': 15, 'min_samples_split': 30}</td>\n",
       "      <td>0.258191</td>\n",
       "      <td>0.130816</td>\n",
       "      <td>0.067039</td>\n",
       "      <td>0.117316</td>\n",
       "      <td>0.216558</td>\n",
       "      <td>0.157984</td>\n",
       "      <td>0.069477</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11.703300</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>1.997475e-04</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_features': 15, 'min_samples_split': 40}</td>\n",
       "      <td>0.275614</td>\n",
       "      <td>0.245522</td>\n",
       "      <td>0.093938</td>\n",
       "      <td>0.126944</td>\n",
       "      <td>0.108112</td>\n",
       "      <td>0.170026</td>\n",
       "      <td>0.075269</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>11.695400</td>\n",
       "      <td>0.041398</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>2.450491e-04</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 15, 'min_samples_split': 50}</td>\n",
       "      <td>0.209834</td>\n",
       "      <td>0.195322</td>\n",
       "      <td>0.119985</td>\n",
       "      <td>0.027129</td>\n",
       "      <td>0.091660</td>\n",
       "      <td>0.128786</td>\n",
       "      <td>0.067507</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>11.736000</td>\n",
       "      <td>0.029726</td>\n",
       "      <td>0.020301</td>\n",
       "      <td>2.450093e-04</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_features': 15, 'min_samples_split': 60}</td>\n",
       "      <td>0.199701</td>\n",
       "      <td>0.186022</td>\n",
       "      <td>0.175193</td>\n",
       "      <td>0.145652</td>\n",
       "      <td>0.209500</td>\n",
       "      <td>0.183214</td>\n",
       "      <td>0.022118</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>12.698400</td>\n",
       "      <td>0.067305</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>3.162813e-04</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_features': 17, 'min_samples_split': 20}</td>\n",
       "      <td>0.184664</td>\n",
       "      <td>0.105580</td>\n",
       "      <td>0.248256</td>\n",
       "      <td>0.081150</td>\n",
       "      <td>0.189683</td>\n",
       "      <td>0.161867</td>\n",
       "      <td>0.060729</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>12.667100</td>\n",
       "      <td>0.008250</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>3.161298e-04</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_features': 17, 'min_samples_split': 30}</td>\n",
       "      <td>0.181406</td>\n",
       "      <td>0.137853</td>\n",
       "      <td>0.182169</td>\n",
       "      <td>0.107833</td>\n",
       "      <td>0.132269</td>\n",
       "      <td>0.148306</td>\n",
       "      <td>0.029144</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>12.638100</td>\n",
       "      <td>0.066980</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>5.100801e-04</td>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_features': 17, 'min_samples_split': 40}</td>\n",
       "      <td>0.191889</td>\n",
       "      <td>0.214790</td>\n",
       "      <td>0.216478</td>\n",
       "      <td>0.081666</td>\n",
       "      <td>0.128631</td>\n",
       "      <td>0.166691</td>\n",
       "      <td>0.053113</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>12.645000</td>\n",
       "      <td>0.051892</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>3.504023e-07</td>\n",
       "      <td>17</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 17, 'min_samples_split': 50}</td>\n",
       "      <td>0.274434</td>\n",
       "      <td>0.223552</td>\n",
       "      <td>0.149403</td>\n",
       "      <td>-0.004488</td>\n",
       "      <td>0.193096</td>\n",
       "      <td>0.167199</td>\n",
       "      <td>0.095015</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>12.640099</td>\n",
       "      <td>0.036261</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>3.162052e-04</td>\n",
       "      <td>17</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_features': 17, 'min_samples_split': 60}</td>\n",
       "      <td>0.206538</td>\n",
       "      <td>0.189343</td>\n",
       "      <td>0.260047</td>\n",
       "      <td>0.054780</td>\n",
       "      <td>0.125509</td>\n",
       "      <td>0.167243</td>\n",
       "      <td>0.070760</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>13.658101</td>\n",
       "      <td>0.048122</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>8.714517e-07</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_features': 19, 'min_samples_split': 20}</td>\n",
       "      <td>0.245134</td>\n",
       "      <td>0.233168</td>\n",
       "      <td>0.084013</td>\n",
       "      <td>0.169375</td>\n",
       "      <td>0.215505</td>\n",
       "      <td>0.189439</td>\n",
       "      <td>0.058670</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>13.666700</td>\n",
       "      <td>0.023650</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>2.447564e-04</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_features': 19, 'min_samples_split': 30}</td>\n",
       "      <td>0.252284</td>\n",
       "      <td>0.234976</td>\n",
       "      <td>0.098409</td>\n",
       "      <td>0.121932</td>\n",
       "      <td>0.167414</td>\n",
       "      <td>0.175003</td>\n",
       "      <td>0.060514</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>13.635700</td>\n",
       "      <td>0.042232</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>4.471815e-04</td>\n",
       "      <td>19</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_features': 19, 'min_samples_split': 40}</td>\n",
       "      <td>0.190860</td>\n",
       "      <td>0.189858</td>\n",
       "      <td>0.168577</td>\n",
       "      <td>-0.017001</td>\n",
       "      <td>0.169362</td>\n",
       "      <td>0.140331</td>\n",
       "      <td>0.079247</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>13.672001</td>\n",
       "      <td>0.056854</td>\n",
       "      <td>0.019999</td>\n",
       "      <td>4.474482e-04</td>\n",
       "      <td>19</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 19, 'min_samples_split': 50}</td>\n",
       "      <td>0.266899</td>\n",
       "      <td>0.187802</td>\n",
       "      <td>0.147530</td>\n",
       "      <td>0.107618</td>\n",
       "      <td>0.250171</td>\n",
       "      <td>0.192004</td>\n",
       "      <td>0.060182</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>13.653399</td>\n",
       "      <td>0.045214</td>\n",
       "      <td>0.020006</td>\n",
       "      <td>4.539587e-04</td>\n",
       "      <td>19</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_features': 19, 'min_samples_split': 60}</td>\n",
       "      <td>0.205486</td>\n",
       "      <td>0.199335</td>\n",
       "      <td>0.116104</td>\n",
       "      <td>0.080532</td>\n",
       "      <td>0.198611</td>\n",
       "      <td>0.160014</td>\n",
       "      <td>0.051670</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>14.648394</td>\n",
       "      <td>0.038281</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>2.002001e-04</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_features': 21, 'min_samples_split': 20}</td>\n",
       "      <td>0.272787</td>\n",
       "      <td>0.198979</td>\n",
       "      <td>0.164646</td>\n",
       "      <td>0.093801</td>\n",
       "      <td>0.218715</td>\n",
       "      <td>0.189786</td>\n",
       "      <td>0.059424</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>14.661900</td>\n",
       "      <td>0.027931</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>2.445034e-04</td>\n",
       "      <td>21</td>\n",
       "      <td>30</td>\n",
       "      <td>{'max_features': 21, 'min_samples_split': 30}</td>\n",
       "      <td>0.143641</td>\n",
       "      <td>0.213823</td>\n",
       "      <td>0.167914</td>\n",
       "      <td>0.091600</td>\n",
       "      <td>0.165055</td>\n",
       "      <td>0.156407</td>\n",
       "      <td>0.039665</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>14.689400</td>\n",
       "      <td>0.034752</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>8.844012e-07</td>\n",
       "      <td>21</td>\n",
       "      <td>40</td>\n",
       "      <td>{'max_features': 21, 'min_samples_split': 40}</td>\n",
       "      <td>0.200916</td>\n",
       "      <td>0.190515</td>\n",
       "      <td>0.157953</td>\n",
       "      <td>0.150086</td>\n",
       "      <td>0.196875</td>\n",
       "      <td>0.179269</td>\n",
       "      <td>0.021029</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>14.676400</td>\n",
       "      <td>0.030435</td>\n",
       "      <td>0.019699</td>\n",
       "      <td>2.447175e-04</td>\n",
       "      <td>21</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_features': 21, 'min_samples_split': 50}</td>\n",
       "      <td>0.203119</td>\n",
       "      <td>0.247919</td>\n",
       "      <td>0.211925</td>\n",
       "      <td>0.104660</td>\n",
       "      <td>0.204902</td>\n",
       "      <td>0.194505</td>\n",
       "      <td>0.047772</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>14.681000</td>\n",
       "      <td>0.050656</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>4.909339e-07</td>\n",
       "      <td>21</td>\n",
       "      <td>60</td>\n",
       "      <td>{'max_features': 21, 'min_samples_split': 60}</td>\n",
       "      <td>0.237706</td>\n",
       "      <td>0.211184</td>\n",
       "      <td>0.124571</td>\n",
       "      <td>0.121005</td>\n",
       "      <td>0.265108</td>\n",
       "      <td>0.191915</td>\n",
       "      <td>0.058973</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        6.840935      0.045032         0.021500    1.482036e-06   \n",
       "1        6.795099      0.061112         0.021400    2.001538e-04   \n",
       "2        6.866700      0.086372         0.021300    2.449900e-04   \n",
       "3        6.841000      0.082566         0.021300    2.447173e-04   \n",
       "4        6.842800      0.040739         0.021400    3.746359e-04   \n",
       "5        7.769200      0.070845         0.020900    2.002244e-04   \n",
       "6        7.792600      0.029737         0.020900    1.998191e-04   \n",
       "7        7.764700      0.073404         0.020900    1.999866e-04   \n",
       "8        7.745800      0.052959         0.020901    3.737692e-04   \n",
       "9        7.724601      0.033882         0.020700    2.452827e-04   \n",
       "10       8.661100      0.066702         0.020399    2.006544e-04   \n",
       "11       8.674600      0.033572         0.020400    2.005348e-04   \n",
       "12       8.626700      0.033998         0.020600    3.741770e-04   \n",
       "13       8.698500      0.057282         0.020600    2.001287e-04   \n",
       "14       8.802100      0.096014         0.021101    4.906413e-04   \n",
       "15       9.752500      0.090546         0.020900    3.741261e-04   \n",
       "16       9.826947      0.022426         0.020900    5.829715e-04   \n",
       "17       9.748100      0.075691         0.020300    2.451859e-04   \n",
       "18       9.718400      0.047904         0.020400    3.744449e-04   \n",
       "19       9.717100      0.046496         0.020300    2.451265e-04   \n",
       "20      10.689800      0.054377         0.020300    2.449514e-04   \n",
       "21      10.684699      0.065242         0.020200    2.451291e-04   \n",
       "22      10.714701      0.039467         0.020500    4.623108e-07   \n",
       "23      10.643600      0.038874         0.020200    2.445809e-04   \n",
       "24      10.686100      0.034023         0.020300    3.997327e-04   \n",
       "25      11.679700      0.021440         0.020400    3.739608e-04   \n",
       "26      11.729500      0.039024         0.020200    2.447185e-04   \n",
       "27      11.703300      0.049774         0.020100    1.997475e-04   \n",
       "28      11.695400      0.041398         0.020200    2.450491e-04   \n",
       "29      11.736000      0.029726         0.020301    2.450093e-04   \n",
       "30      12.698400      0.067305         0.020000    3.162813e-04   \n",
       "31      12.667100      0.008250         0.020000    3.161298e-04   \n",
       "32      12.638100      0.066980         0.020200    5.100801e-04   \n",
       "33      12.645000      0.051892         0.020000    3.504023e-07   \n",
       "34      12.640099      0.036261         0.020000    3.162052e-04   \n",
       "35      13.658101      0.048122         0.020000    8.714517e-07   \n",
       "36      13.666700      0.023650         0.019800    2.447564e-04   \n",
       "37      13.635700      0.042232         0.020000    4.471815e-04   \n",
       "38      13.672001      0.056854         0.019999    4.474482e-04   \n",
       "39      13.653399      0.045214         0.020006    4.539587e-04   \n",
       "40      14.648394      0.038281         0.019600    2.002001e-04   \n",
       "41      14.661900      0.027931         0.019800    2.445034e-04   \n",
       "42      14.689400      0.034752         0.019500    8.844012e-07   \n",
       "43      14.676400      0.030435         0.019699    2.447175e-04   \n",
       "44      14.681000      0.050656         0.020000    4.909339e-07   \n",
       "\n",
       "   param_max_features param_min_samples_split  \\\n",
       "0                   5                      20   \n",
       "1                   5                      30   \n",
       "2                   5                      40   \n",
       "3                   5                      50   \n",
       "4                   5                      60   \n",
       "5                   7                      20   \n",
       "6                   7                      30   \n",
       "7                   7                      40   \n",
       "8                   7                      50   \n",
       "9                   7                      60   \n",
       "10                  9                      20   \n",
       "11                  9                      30   \n",
       "12                  9                      40   \n",
       "13                  9                      50   \n",
       "14                  9                      60   \n",
       "15                 11                      20   \n",
       "16                 11                      30   \n",
       "17                 11                      40   \n",
       "18                 11                      50   \n",
       "19                 11                      60   \n",
       "20                 13                      20   \n",
       "21                 13                      30   \n",
       "22                 13                      40   \n",
       "23                 13                      50   \n",
       "24                 13                      60   \n",
       "25                 15                      20   \n",
       "26                 15                      30   \n",
       "27                 15                      40   \n",
       "28                 15                      50   \n",
       "29                 15                      60   \n",
       "30                 17                      20   \n",
       "31                 17                      30   \n",
       "32                 17                      40   \n",
       "33                 17                      50   \n",
       "34                 17                      60   \n",
       "35                 19                      20   \n",
       "36                 19                      30   \n",
       "37                 19                      40   \n",
       "38                 19                      50   \n",
       "39                 19                      60   \n",
       "40                 21                      20   \n",
       "41                 21                      30   \n",
       "42                 21                      40   \n",
       "43                 21                      50   \n",
       "44                 21                      60   \n",
       "\n",
       "                                           params  split0_test_score  \\\n",
       "0    {'max_features': 5, 'min_samples_split': 20}           0.279298   \n",
       "1    {'max_features': 5, 'min_samples_split': 30}           0.171970   \n",
       "2    {'max_features': 5, 'min_samples_split': 40}           0.108827   \n",
       "3    {'max_features': 5, 'min_samples_split': 50}           0.158150   \n",
       "4    {'max_features': 5, 'min_samples_split': 60}           0.265140   \n",
       "5    {'max_features': 7, 'min_samples_split': 20}           0.136932   \n",
       "6    {'max_features': 7, 'min_samples_split': 30}           0.270094   \n",
       "7    {'max_features': 7, 'min_samples_split': 40}           0.232672   \n",
       "8    {'max_features': 7, 'min_samples_split': 50}           0.260801   \n",
       "9    {'max_features': 7, 'min_samples_split': 60}           0.242187   \n",
       "10   {'max_features': 9, 'min_samples_split': 20}           0.180168   \n",
       "11   {'max_features': 9, 'min_samples_split': 30}           0.170207   \n",
       "12   {'max_features': 9, 'min_samples_split': 40}           0.118393   \n",
       "13   {'max_features': 9, 'min_samples_split': 50}           0.254127   \n",
       "14   {'max_features': 9, 'min_samples_split': 60}           0.141062   \n",
       "15  {'max_features': 11, 'min_samples_split': 20}           0.274224   \n",
       "16  {'max_features': 11, 'min_samples_split': 30}           0.105436   \n",
       "17  {'max_features': 11, 'min_samples_split': 40}           0.202204   \n",
       "18  {'max_features': 11, 'min_samples_split': 50}           0.192076   \n",
       "19  {'max_features': 11, 'min_samples_split': 60}           0.159286   \n",
       "20  {'max_features': 13, 'min_samples_split': 20}           0.236218   \n",
       "21  {'max_features': 13, 'min_samples_split': 30}           0.105093   \n",
       "22  {'max_features': 13, 'min_samples_split': 40}           0.114354   \n",
       "23  {'max_features': 13, 'min_samples_split': 50}           0.238717   \n",
       "24  {'max_features': 13, 'min_samples_split': 60}           0.152916   \n",
       "25  {'max_features': 15, 'min_samples_split': 20}           0.096353   \n",
       "26  {'max_features': 15, 'min_samples_split': 30}           0.258191   \n",
       "27  {'max_features': 15, 'min_samples_split': 40}           0.275614   \n",
       "28  {'max_features': 15, 'min_samples_split': 50}           0.209834   \n",
       "29  {'max_features': 15, 'min_samples_split': 60}           0.199701   \n",
       "30  {'max_features': 17, 'min_samples_split': 20}           0.184664   \n",
       "31  {'max_features': 17, 'min_samples_split': 30}           0.181406   \n",
       "32  {'max_features': 17, 'min_samples_split': 40}           0.191889   \n",
       "33  {'max_features': 17, 'min_samples_split': 50}           0.274434   \n",
       "34  {'max_features': 17, 'min_samples_split': 60}           0.206538   \n",
       "35  {'max_features': 19, 'min_samples_split': 20}           0.245134   \n",
       "36  {'max_features': 19, 'min_samples_split': 30}           0.252284   \n",
       "37  {'max_features': 19, 'min_samples_split': 40}           0.190860   \n",
       "38  {'max_features': 19, 'min_samples_split': 50}           0.266899   \n",
       "39  {'max_features': 19, 'min_samples_split': 60}           0.205486   \n",
       "40  {'max_features': 21, 'min_samples_split': 20}           0.272787   \n",
       "41  {'max_features': 21, 'min_samples_split': 30}           0.143641   \n",
       "42  {'max_features': 21, 'min_samples_split': 40}           0.200916   \n",
       "43  {'max_features': 21, 'min_samples_split': 50}           0.203119   \n",
       "44  {'max_features': 21, 'min_samples_split': 60}           0.237706   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.137664           0.231177           0.071693   \n",
       "1            0.180735           0.142996           0.108361   \n",
       "2            0.195997           0.145112           0.084844   \n",
       "3            0.233831           0.168044           0.049186   \n",
       "4            0.197384           0.081775           0.112971   \n",
       "5            0.165608           0.079034           0.145197   \n",
       "6            0.242974           0.171519           0.186615   \n",
       "7            0.102094           0.223320           0.123754   \n",
       "8            0.175275           0.101682           0.064109   \n",
       "9            0.229385           0.127572           0.155512   \n",
       "10           0.172226           0.062213           0.144689   \n",
       "11           0.237364           0.116158           0.049706   \n",
       "12           0.168513           0.152208          -0.077973   \n",
       "13           0.200092           0.182426           0.079890   \n",
       "14           0.165517           0.133269           0.160077   \n",
       "15           0.192387           0.130154           0.110168   \n",
       "16           0.126117           0.155596           0.122280   \n",
       "17           0.186812           0.193754           0.114186   \n",
       "18           0.242212           0.105066           0.079139   \n",
       "19           0.172427           0.175208           0.163030   \n",
       "20           0.227418           0.125693           0.196195   \n",
       "21           0.176166           0.138130           0.133043   \n",
       "22           0.253530           0.141202           0.192599   \n",
       "23           0.197689           0.137068           0.091874   \n",
       "24           0.222142           0.192422           0.164442   \n",
       "25           0.138444           0.193477           0.078312   \n",
       "26           0.130816           0.067039           0.117316   \n",
       "27           0.245522           0.093938           0.126944   \n",
       "28           0.195322           0.119985           0.027129   \n",
       "29           0.186022           0.175193           0.145652   \n",
       "30           0.105580           0.248256           0.081150   \n",
       "31           0.137853           0.182169           0.107833   \n",
       "32           0.214790           0.216478           0.081666   \n",
       "33           0.223552           0.149403          -0.004488   \n",
       "34           0.189343           0.260047           0.054780   \n",
       "35           0.233168           0.084013           0.169375   \n",
       "36           0.234976           0.098409           0.121932   \n",
       "37           0.189858           0.168577          -0.017001   \n",
       "38           0.187802           0.147530           0.107618   \n",
       "39           0.199335           0.116104           0.080532   \n",
       "40           0.198979           0.164646           0.093801   \n",
       "41           0.213823           0.167914           0.091600   \n",
       "42           0.190515           0.157953           0.150086   \n",
       "43           0.247919           0.211925           0.104660   \n",
       "44           0.211184           0.124571           0.121005   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.155947         0.175156        0.072750               15  \n",
       "1            0.206041         0.162021        0.033551               26  \n",
       "2            0.106528         0.128262        0.039005               43  \n",
       "3            0.151127         0.152067        0.059267               34  \n",
       "4            0.232618         0.177978        0.069915               14  \n",
       "5            0.189129         0.143180        0.036803               37  \n",
       "6            0.214635         0.217167        0.036030                1  \n",
       "7            0.168009         0.169970        0.052009               20  \n",
       "8            0.174569         0.155287        0.067958               33  \n",
       "9            0.209318         0.192795        0.044035                3  \n",
       "10           0.103027         0.132465        0.044290               41  \n",
       "11           0.185393         0.151766        0.064003               35  \n",
       "12           0.093807         0.090990        0.088391               45  \n",
       "13           0.103486         0.164004        0.064034               25  \n",
       "14           0.185429         0.157071        0.018479               31  \n",
       "15           0.151876         0.171762        0.058042               18  \n",
       "16           0.153797         0.132645        0.019311               40  \n",
       "17           0.204625         0.180316        0.033663               12  \n",
       "18           0.180447         0.159788        0.059602               29  \n",
       "19           0.233379         0.180666        0.026998               10  \n",
       "20           0.164355         0.189976        0.040909                6  \n",
       "21           0.140711         0.138628        0.022669               39  \n",
       "22           0.169764         0.174290        0.047585               17  \n",
       "23           0.237630         0.180596        0.057774               11  \n",
       "24           0.098900         0.166165        0.041294               24  \n",
       "25           0.132653         0.127848        0.039720               44  \n",
       "26           0.216558         0.157984        0.069477               30  \n",
       "27           0.108112         0.170026        0.075269               19  \n",
       "28           0.091660         0.128786        0.067507               42  \n",
       "29           0.209500         0.183214        0.022118                9  \n",
       "30           0.189683         0.161867        0.060729               27  \n",
       "31           0.132269         0.148306        0.029144               36  \n",
       "32           0.128631         0.166691        0.053113               23  \n",
       "33           0.193096         0.167199        0.095015               22  \n",
       "34           0.125509         0.167243        0.070760               21  \n",
       "35           0.215505         0.189439        0.058670                8  \n",
       "36           0.167414         0.175003        0.060514               16  \n",
       "37           0.169362         0.140331        0.079247               38  \n",
       "38           0.250171         0.192004        0.060182                4  \n",
       "39           0.198611         0.160014        0.051670               28  \n",
       "40           0.218715         0.189786        0.059424                7  \n",
       "41           0.165055         0.156407        0.039665               32  \n",
       "42           0.196875         0.179269        0.021029               13  \n",
       "43           0.204902         0.194505        0.047772                2  \n",
       "44           0.265108         0.191915        0.058973                5  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs4 = pd.DataFrame(gsearch4.cv_results_)\n",
    "gs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "068243ad-71d5-4c96-b67b-fd34bd9d2991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=GradientBoostingRegressor(learning_rate=0.75,\n",
       "                                                 loss='absolute_error',\n",
       "                                                 max_depth=13, max_features=7,\n",
       "                                                 min_samples_leaf=30,\n",
       "                                                 min_samples_split=30,\n",
       "                                                 n_estimators=400),\n",
       "             param_grid={'subsample': [0.6, 0.7, 0.75, 0.8, 0.85, 0.9]})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test5 = {'subsample':[0.6,0.7,0.75,0.8,0.85,0.9]}\n",
    "gb5 = GradientBoostingRegressor(n_estimators = 400, learning_rate = 0.75,max_depth = 13,min_samples_leaf = 30,max_features = 7, min_samples_split = 30,loss='absolute_error')\n",
    "gsearch5 = GridSearchCV(gb5,param_test5)\n",
    "gsearch5.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f501d3b0-4c50-40c2-ae26-bcd2cfc922cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.917201</td>\n",
       "      <td>0.061240</td>\n",
       "      <td>0.022199</td>\n",
       "      <td>2.438616e-04</td>\n",
       "      <td>0.6</td>\n",
       "      <td>{'subsample': 0.6}</td>\n",
       "      <td>0.063028</td>\n",
       "      <td>0.104487</td>\n",
       "      <td>0.173064</td>\n",
       "      <td>0.102636</td>\n",
       "      <td>0.088138</td>\n",
       "      <td>0.106271</td>\n",
       "      <td>0.036542</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.570300</td>\n",
       "      <td>0.041746</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>6.143617e-07</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'subsample': 0.7}</td>\n",
       "      <td>0.117906</td>\n",
       "      <td>0.097235</td>\n",
       "      <td>0.104968</td>\n",
       "      <td>0.148800</td>\n",
       "      <td>0.071381</td>\n",
       "      <td>0.108058</td>\n",
       "      <td>0.025412</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.851300</td>\n",
       "      <td>0.048843</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>5.098003e-04</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'subsample': 0.75}</td>\n",
       "      <td>0.189353</td>\n",
       "      <td>0.239105</td>\n",
       "      <td>0.125509</td>\n",
       "      <td>0.105625</td>\n",
       "      <td>0.184367</td>\n",
       "      <td>0.168792</td>\n",
       "      <td>0.047902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.147000</td>\n",
       "      <td>0.051851</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>2.009872e-04</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'subsample': 0.8}</td>\n",
       "      <td>0.154764</td>\n",
       "      <td>0.139866</td>\n",
       "      <td>0.062889</td>\n",
       "      <td>0.098254</td>\n",
       "      <td>0.199970</td>\n",
       "      <td>0.131148</td>\n",
       "      <td>0.047141</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.399799</td>\n",
       "      <td>0.024355</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>3.159788e-04</td>\n",
       "      <td>0.85</td>\n",
       "      <td>{'subsample': 0.85}</td>\n",
       "      <td>0.223698</td>\n",
       "      <td>0.173551</td>\n",
       "      <td>0.254244</td>\n",
       "      <td>0.018854</td>\n",
       "      <td>0.095426</td>\n",
       "      <td>0.153155</td>\n",
       "      <td>0.086001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.546600</td>\n",
       "      <td>0.021425</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>1.999147e-04</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'subsample': 0.9}</td>\n",
       "      <td>0.138746</td>\n",
       "      <td>0.160988</td>\n",
       "      <td>0.166305</td>\n",
       "      <td>0.012624</td>\n",
       "      <td>0.094953</td>\n",
       "      <td>0.114723</td>\n",
       "      <td>0.056909</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       5.917201      0.061240         0.022199    2.438616e-04   \n",
       "1       6.570300      0.041746         0.022500    6.143617e-07   \n",
       "2       6.851300      0.048843         0.022700    5.098003e-04   \n",
       "3       7.147000      0.051851         0.022400    2.009872e-04   \n",
       "4       7.399799      0.024355         0.022500    3.159788e-04   \n",
       "5       7.546600      0.021425         0.021900    1.999147e-04   \n",
       "\n",
       "  param_subsample               params  split0_test_score  split1_test_score  \\\n",
       "0             0.6   {'subsample': 0.6}           0.063028           0.104487   \n",
       "1             0.7   {'subsample': 0.7}           0.117906           0.097235   \n",
       "2            0.75  {'subsample': 0.75}           0.189353           0.239105   \n",
       "3             0.8   {'subsample': 0.8}           0.154764           0.139866   \n",
       "4            0.85  {'subsample': 0.85}           0.223698           0.173551   \n",
       "5             0.9   {'subsample': 0.9}           0.138746           0.160988   \n",
       "\n",
       "   split2_test_score  split3_test_score  split4_test_score  mean_test_score  \\\n",
       "0           0.173064           0.102636           0.088138         0.106271   \n",
       "1           0.104968           0.148800           0.071381         0.108058   \n",
       "2           0.125509           0.105625           0.184367         0.168792   \n",
       "3           0.062889           0.098254           0.199970         0.131148   \n",
       "4           0.254244           0.018854           0.095426         0.153155   \n",
       "5           0.166305           0.012624           0.094953         0.114723   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.036542                6  \n",
       "1        0.025412                5  \n",
       "2        0.047902                1  \n",
       "3        0.047141                3  \n",
       "4        0.086001                2  \n",
       "5        0.056909                4  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs5 = pd.DataFrame(gsearch5.cv_results_)\n",
    "gs5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c7fa4872-62cf-4e15-ae40-4171c4c93ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.01476581, 81.90744259,  0.11577598, ...,  1.45063095,\n",
       "        0.45144119,  0.65536851])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(n_estimators = 400, learning_rate = 0.75,max_depth = 13,\n",
    "                          min_samples_leaf = 30,max_features = 7, min_samples_split = 30,\n",
    "                          loss='absolute_error',subsample = 0.75).fit(Xtr2,tr['total'])\n",
    "model.predict(Xte2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "02a94744-af0b-4e13-aa30-e7958132a206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7e79f1a9cb10504dd2fc569d84f2a346</td>\n",
       "      <td>2.014766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4a2f52a31466509462042dacd3d66de7</td>\n",
       "      <td>81.907443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f22f6ec19360a7bcc7e0f6c76912c88b</td>\n",
       "      <td>0.115776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6382e9933644b1751511264ec8194ef5</td>\n",
       "      <td>-0.665334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>638c2f2961777b10009d7fdebae561bc</td>\n",
       "      <td>-0.173393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6909</th>\n",
       "      <td>62eb6ce056e943070967d8835a204551</td>\n",
       "      <td>1.128803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6910</th>\n",
       "      <td>6a5a9ef25ea4889cef2b14a272ba958c</td>\n",
       "      <td>0.000754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6911</th>\n",
       "      <td>6c8edfdb7aec834d73e4b8d36ec0736d</td>\n",
       "      <td>1.450631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6912</th>\n",
       "      <td>c4618bb91765903dad4451933ee396ea</td>\n",
       "      <td>0.451441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6913</th>\n",
       "      <td>3b665129694904b2024dc7cd8230babe</td>\n",
       "      <td>0.655369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6914 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id      total\n",
       "0     7e79f1a9cb10504dd2fc569d84f2a346   2.014766\n",
       "1     4a2f52a31466509462042dacd3d66de7  81.907443\n",
       "2     f22f6ec19360a7bcc7e0f6c76912c88b   0.115776\n",
       "3     6382e9933644b1751511264ec8194ef5  -0.665334\n",
       "4     638c2f2961777b10009d7fdebae561bc  -0.173393\n",
       "...                                ...        ...\n",
       "6909  62eb6ce056e943070967d8835a204551   1.128803\n",
       "6910  6a5a9ef25ea4889cef2b14a272ba958c   0.000754\n",
       "6911  6c8edfdb7aec834d73e4b8d36ec0736d   1.450631\n",
       "6912  c4618bb91765903dad4451933ee396ea   0.451441\n",
       "6913  3b665129694904b2024dc7cd8230babe   0.655369\n",
       "\n",
       "[6914 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred5 = pd.read_csv('data/pred.csv')\n",
    "pred5['total'] = model.predict(Xte2)\n",
    "pred5.to_csv('data/pred_gb.csv', index = False)\n",
    "pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab9df439-c8ad-4630-9ad6-9667a3852ae2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'a44a5f4c5e13910205404271e750e7bc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2784/1806200377.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtsvdte\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/tsvd-te.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m model = GradientBoostingRegressor(n_estimators = 400, learning_rate = 0.75,max_depth = 13,\n\u001b[0m\u001b[0;32m      5\u001b[0m                           \u001b[0mmin_samples_leaf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                           loss='absolute_error',subsample = 0.75).fit(tsvdtr,tr['total'])\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    484\u001b[0m         \u001b[1;31m# trees use different types for X and y, checking them separately.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    487\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"coo\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    574\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 576\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    577\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 956\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m    957\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    736\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 738\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    739\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m                 raise ValueError(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1992\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNpDtype\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1993\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1994\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1995\u001b[0m     def __array_wrap__(\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'a44a5f4c5e13910205404271e750e7bc'"
     ]
    }
   ],
   "source": [
    "tsvdtr = pd.read_csv('data/tsvd-tr.csv')\n",
    "tsvdte = pd.read_csv('data/tsvd-te.csv')\n",
    "\n",
    "model = GradientBoostingRegressor(n_estimators = 400, learning_rate = 0.75,max_depth = 13,\n",
    "                          min_samples_leaf = 30,max_features = 7, min_samples_split = 30,\n",
    "                          loss='absolute_error',subsample = 0.75).fit(tsvdtr,tr['total'])\n",
    "pred5 = pd.read_csv('data/pred.csv')\n",
    "pred5['total'] = model.predict(tsvdte)\n",
    "pred5.to_csv('data/pred_gb_svd.csv', index = False)\n",
    "pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "65e82b60-79a0-4f3a-9bc8-0ee1fc288ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr3 =Xtr2.copy()\n",
    "Xte3 = Xte2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a6fc3ff0-26c6-446e-bef3-24df11c67e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr3['FT0000'] = tsvdtr['FT0000']\n",
    "Xtr3['FT0001'] = tsvdtr['FT0001']\n",
    "Xtr3['FT0002'] = tsvdtr['FT0002']\n",
    "Xtr3['FT0003'] = tsvdtr['FT0003']\n",
    "Xtr3['FT0004'] = tsvdtr['FT0004']\n",
    "Xtr3['FT0005'] = tsvdtr['FT0005']\n",
    "Xtr3['FT0006'] = tsvdtr['FT0006']\n",
    "Xtr3['FT0007'] = tsvdtr['FT0007']\n",
    "Xtr3['FT0008'] = tsvdtr['FT0008']\n",
    "Xtr3['FT0009'] = tsvdtr['FT0009']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "000f3a04-76fd-40b8-a543-38c0276438d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte3['FT0000'] = tsvdte['FT0000']\n",
    "Xte3['FT0001'] = tsvdte['FT0001']\n",
    "Xte3['FT0002'] = tsvdte['FT0002']\n",
    "Xte3['FT0003'] = tsvdte['FT0003']\n",
    "Xte3['FT0004'] = tsvdte['FT0004']\n",
    "Xte3['FT0005'] = tsvdte['FT0005']\n",
    "Xte3['FT0006'] = tsvdte['FT0006']\n",
    "Xte3['FT0007'] = tsvdte['FT0007']\n",
    "Xte3['FT0008'] = tsvdte['FT0008']\n",
    "Xte3['FT0009'] = tsvdte['FT0009']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f093c07c-1f6f-467d-8552-1a78e16f5888",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte3.to_csv('data/Xte_tsvd.csv', index = False)\n",
    "Xtr3.to_csv('data/Xtr_tsvd.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5440a97e-03ca-430e-9a94-f9aa8876e755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7e79f1a9cb10504dd2fc569d84f2a346</td>\n",
       "      <td>0.201492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4a2f52a31466509462042dacd3d66de7</td>\n",
       "      <td>-4.213729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f22f6ec19360a7bcc7e0f6c76912c88b</td>\n",
       "      <td>0.115521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6382e9933644b1751511264ec8194ef5</td>\n",
       "      <td>-0.088799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>638c2f2961777b10009d7fdebae561bc</td>\n",
       "      <td>1.156317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6909</th>\n",
       "      <td>62eb6ce056e943070967d8835a204551</td>\n",
       "      <td>0.861648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6910</th>\n",
       "      <td>6a5a9ef25ea4889cef2b14a272ba958c</td>\n",
       "      <td>-0.315091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6911</th>\n",
       "      <td>6c8edfdb7aec834d73e4b8d36ec0736d</td>\n",
       "      <td>0.183275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6912</th>\n",
       "      <td>c4618bb91765903dad4451933ee396ea</td>\n",
       "      <td>0.517505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6913</th>\n",
       "      <td>3b665129694904b2024dc7cd8230babe</td>\n",
       "      <td>0.311332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6914 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id     total\n",
       "0     7e79f1a9cb10504dd2fc569d84f2a346  0.201492\n",
       "1     4a2f52a31466509462042dacd3d66de7 -4.213729\n",
       "2     f22f6ec19360a7bcc7e0f6c76912c88b  0.115521\n",
       "3     6382e9933644b1751511264ec8194ef5 -0.088799\n",
       "4     638c2f2961777b10009d7fdebae561bc  1.156317\n",
       "...                                ...       ...\n",
       "6909  62eb6ce056e943070967d8835a204551  0.861648\n",
       "6910  6a5a9ef25ea4889cef2b14a272ba958c -0.315091\n",
       "6911  6c8edfdb7aec834d73e4b8d36ec0736d  0.183275\n",
       "6912  c4618bb91765903dad4451933ee396ea  0.517505\n",
       "6913  3b665129694904b2024dc7cd8230babe  0.311332\n",
       "\n",
       "[6914 rows x 2 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(n_estimators = 400, learning_rate = 0.75,max_depth = 13,\n",
    "                          min_samples_leaf = 30,max_features = 7, min_samples_split = 30,\n",
    "                          loss='absolute_error',subsample = 0.75).fit(Xtr3,tr['total'])\n",
    "pred5 = pd.read_csv('data/pred.csv')\n",
    "pred5['total'] = model.predict(Xte3)\n",
    "pred5.to_csv('data/pred_gb_svd.csv', index = False)\n",
    "pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "91373968-cb55-42b8-a34d-83d918bd50bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7e79f1a9cb10504dd2fc569d84f2a346</td>\n",
       "      <td>0.198558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4a2f52a31466509462042dacd3d66de7</td>\n",
       "      <td>6.008456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f22f6ec19360a7bcc7e0f6c76912c88b</td>\n",
       "      <td>0.269988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6382e9933644b1751511264ec8194ef5</td>\n",
       "      <td>0.477923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>638c2f2961777b10009d7fdebae561bc</td>\n",
       "      <td>1.445434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6909</th>\n",
       "      <td>62eb6ce056e943070967d8835a204551</td>\n",
       "      <td>1.165767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6910</th>\n",
       "      <td>6a5a9ef25ea4889cef2b14a272ba958c</td>\n",
       "      <td>0.122157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6911</th>\n",
       "      <td>6c8edfdb7aec834d73e4b8d36ec0736d</td>\n",
       "      <td>1.049804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6912</th>\n",
       "      <td>c4618bb91765903dad4451933ee396ea</td>\n",
       "      <td>0.708014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6913</th>\n",
       "      <td>3b665129694904b2024dc7cd8230babe</td>\n",
       "      <td>-0.060757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6914 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id     total\n",
       "0     7e79f1a9cb10504dd2fc569d84f2a346  0.198558\n",
       "1     4a2f52a31466509462042dacd3d66de7  6.008456\n",
       "2     f22f6ec19360a7bcc7e0f6c76912c88b  0.269988\n",
       "3     6382e9933644b1751511264ec8194ef5  0.477923\n",
       "4     638c2f2961777b10009d7fdebae561bc  1.445434\n",
       "...                                ...       ...\n",
       "6909  62eb6ce056e943070967d8835a204551  1.165767\n",
       "6910  6a5a9ef25ea4889cef2b14a272ba958c  0.122157\n",
       "6911  6c8edfdb7aec834d73e4b8d36ec0736d  1.049804\n",
       "6912  c4618bb91765903dad4451933ee396ea  0.708014\n",
       "6913  3b665129694904b2024dc7cd8230babe -0.060757\n",
       "\n",
       "[6914 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldatr = pd.read_csv('data/Xtr_lda.csv')\n",
    "ldate = pd.read_csv('data/Xte_lda.csv')\n",
    "\n",
    "model = GradientBoostingRegressor(n_estimators = 400, learning_rate = 0.75,max_depth = 13,\n",
    "                          min_samples_leaf = 30,max_features = 7, min_samples_split = 30,\n",
    "                          loss='absolute_error',subsample = 0.75).fit(ldatr,tr['total'])\n",
    "pred5 = pd.read_csv('data/pred.csv')\n",
    "pred5['total'] = model.predict(ldate)\n",
    "pred5.to_csv('data/pred_gb_lda.csv', index = False)\n",
    "pred5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640ecd04-48f1-4920-9413-18b843a7c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "f8f066cd-76ad-4711-99f2-c60133fc3f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.057060\n",
       "1       0.044032\n",
       "2       0.060109\n",
       "3       0.078806\n",
       "4       0.149271\n",
       "          ...   \n",
       "6909    0.184663\n",
       "6910    0.100795\n",
       "6911    0.211626\n",
       "6912    0.115224\n",
       "6913    0.163427\n",
       "Name: total, Length: 6914, dtype: float64"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "model5 = SGDRegressor(loss = 'epsilon_insensitive', alpha = 0, epsilon = 0).fit(Xtr6, tr['total'])\n",
    "pred5 = pred.copy()\n",
    "pred5['total'] = model5.predict(Xte6)\n",
    "pred5.to_csv('data/pred_sgd.csv', index = False)\n",
    "pred5['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "aa39bd7f-f540-42c2-a7ac-5c8ea811c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldatr\n",
    "ldatr1 = ldatr[['X.sales','cdate','fee1','fee2']].copy()\n",
    "ldate1 = ldate[['X.sales','cdate','fee1','fee2']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "a6920df2-a952-4ca9-a7ce-95f024fc9349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.247992\n",
       "1       60.662479\n",
       "2        0.950926\n",
       "3        0.856886\n",
       "4        0.969652\n",
       "          ...    \n",
       "6909     1.661083\n",
       "6910     0.643355\n",
       "6911     1.637939\n",
       "6912    -0.165792\n",
       "6913    -1.927840\n",
       "Name: total, Length: 6914, dtype: float32"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "xgb_reg = xgboost.XGBRegressor()\n",
    "xgb_reg.fit(ldatr1,tr['total'])\n",
    "\n",
    "pred8 = pred.copy()\n",
    "pred8['total'] = xgb_reg.predict(ldate1)\n",
    "#pred8.to_csv('data/pred_xgblda.csv', index = False)\n",
    "np.median(pred8['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "d3c03195-cbe2-4ad4-bf6a-ea4d3361d858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64335465"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(pred8['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "29f478e0-bfcd-4a5d-a055-ce53b2b07db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(tr['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d7141cb7-6a76-408b-b026-e6e8c3ba5a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two things\n",
    "\n",
    "# bug \n",
    "\n",
    "# classification didnt work very well\n",
    "\n",
    "# look at tensorflow tutorial keras regression\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
